{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fake_2 = fake.detach()\n",
    "\n",
    "#Usar o fixed_noise para salvar as imagens!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System properties and libs currently in use\n",
    "- We have developed using python 3.5.x, pytorch 0.2.1\n",
    "- No significant attention was given to backwards compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__Python VERSION: 3.5.3 |Anaconda 4.4.0 (64-bit)| (default, Mar  6 2017, 11:58:13) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
      "__pyTorch VERSION: 0.2.0_4\n",
      "__CUDA VERSION\n",
      "__CUDNN VERSION: 6021\n",
      "__Number CUDA Devices: 1\n",
      "__Devices\n",
      "Active CUDA Device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "print('Active CUDA Device: GPU', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities\n",
    "- Saving images and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_images(netG, fixed_noise, outputDir,epoch):\n",
    "    '''\n",
    "    Generates a batch of images from the given 'noise'.\n",
    "    Saves 64 of the generated samples to 'outputDir' system path.\n",
    "    Inputs are the network (netG), a 'noise' input, system path to which images will be saved (outputDir) and current 'epoch'.\n",
    "    '''\n",
    "    assert isinstance(fixed_noise,torch.autograd.variable.Variable)\n",
    "    netG.eval()\n",
    "    fake = netG(noise)\n",
    "    netG.train()\n",
    "    vutils.save_image(fake.data[0:64,:,:,:],'%s/fake_samples_epoch_%03d.png' % (outputDir, epoch), nrow=8)\n",
    "\n",
    "def save_models(netG, netD, outputDir, epoch):\n",
    "    '''\n",
    "    Saves model state dictionary for generator and discriminator networks.\n",
    "    Inputs are the networks (netG, netD), the system path in which to save(outputDir) and the current 'epoch'.\n",
    "    '''\n",
    "    torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (outputDir, epoch))\n",
    "    torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (outputDir, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_samples(samples):\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    gs = gridspec.GridSpec(5, 5)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "    for i, sample in enumerate(samples[:25]):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_images2(g_net,fixed_noise,epoch):\n",
    "    g_net.eval()\n",
    "    fake_data = g_net(fixed_noise)\n",
    "    g_net.train()\n",
    "    fig = plot_samples(fake_data.data.cpu().numpy())\n",
    "    plt.savefig(outputDir + '/dcgan_img_{:04d}.png'.format(epoch, bbox_inches='tight'))\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using CUDA. If it is not what you want, manually set this as False!\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "cudnn.benchmark = True\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"You are using CUDA. If it is not what you want, manually set this as False!\")\n",
    "print(use_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Directory\n",
    "This is where images will be saved to.\n",
    "\n",
    "If directory does not exist, it is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS error: [Errno 17] File exists: 'outputdir_train_classifier_lotufo_final'\n"
     ]
    }
   ],
   "source": [
    "outputDir = 'outputdir_train_classifier_lotufo_final'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset definition and hyperparameter setting\n",
    "- Changing dataset name alters network architecture parameters\n",
    "- Currently supporting few datasets\n",
    "- Hyperparameters defined according to Radford et al. (2015)\n",
    "\n",
    "Valores típicos são\n",
    "\n",
    "nc = 3,\n",
    "\n",
    "ngpu = 1,\n",
    "\n",
    "nz = 100,\n",
    "\n",
    "ngf = 64,\n",
    "\n",
    "ndf = 64,\n",
    "\n",
    "n_extra_d = 0,\n",
    "\n",
    "n_extra_g = 1,\n",
    "\n",
    "imageSize = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "chosen_dataset = 'MNIST'\n",
    "\n",
    "datasets = {\n",
    "    'MNIST': torchvision.datasets.MNIST,\n",
    "    'CIFAR10': torchvision.datasets.CIFAR10,\n",
    "    'ANIME': '/home/gabriel/Redes Neurais/Projeto_Final_GANS/Tutorial_2/dataset/min_anime-faces',\n",
    "}\n",
    "\n",
    "dataset = datasets[chosen_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "possible_parameters = {\n",
    "    'MNIST': {\n",
    "        'ndf': 64,\n",
    "        'ngf': 64,\n",
    "        'nz': 100,\n",
    "        'nc': 1,\n",
    "        'imageSize': 28,\n",
    "        'n_classes' : 10,\n",
    "        'ngpu': 1,\n",
    "    },\n",
    "    'CIFAR10': {\n",
    "        'ndf': 64,\n",
    "        'ngf': 64,\n",
    "        'nz': 100,\n",
    "        'nc': 3,\n",
    "        'imageSize' : 64,\n",
    "        'n_classes' : 10,\n",
    "        'ngpu' : 1,\n",
    "    },\n",
    "    'ANIME': {\n",
    "        'nc' : 3,\n",
    "        'ngpu' : 1,\n",
    "        'nz' : 100,\n",
    "        'ngf' : 64,\n",
    "        'ndf' : 64,\n",
    "        'imageSize' : 64,\n",
    "        'n_classes' : 1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngf = possible_parameters[chosen_dataset]['ngf']\n",
    "ndf = possible_parameters[chosen_dataset]['ndf']\n",
    "nz = possible_parameters[chosen_dataset]['nz']\n",
    "nc = possible_parameters[chosen_dataset]['nc']\n",
    "imageSize = possible_parameters[chosen_dataset]['imageSize']\n",
    "n_classes = possible_parameters[chosen_dataset]['n_classes']\n",
    "ngpu = possible_parameters[chosen_dataset]['ngpu']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader length: 938\n",
      "Dataset: <torchvision.datasets.mnist.MNIST object at 0x7ff6c0fea630>\n"
     ]
    }
   ],
   "source": [
    "if dataset == 'ANIME':\n",
    "    dataset = torchvision.datasets.ImageFolder(\n",
    "        root='/home/gabriel/Redes Neurais/Projeto_Final_GANS/Tutorial_2/dataset/min_anime-faces',\n",
    "        transform=transforms.Compose([\n",
    "                transforms.Scale((imageSize, imageSize)),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "    )\n",
    "else:\n",
    "    transform = transforms.Compose([\n",
    "                    transforms.Scale((imageSize, imageSize)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)), # bring images to (-1,1)\n",
    "                ]) \n",
    "    dataset_done = dataset('./datasets', train=True, download=True, transform=transform)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset_done, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "print('Dataloader length:', len(dataloader))\n",
    "print(\"Dataset:\", dataloader.dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição dos modelos\n",
    "- Model is a DCGAN\n",
    "- Images are sized (nc, 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netD_DCGAN(nn.Module):\n",
    "    def __init__(self, ngpu, nz, nc, ndf, n_classes):\n",
    "        super(_netD_DCGAN, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.conv1 = nn.Conv2d(in_channels = nc, out_channels = ndf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(in_channels = ndf, out_channels = ndf*2, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch2 = nn.BatchNorm2d(ndf * 2)\n",
    "        self.conv3 = nn.Conv2d(in_channels = ndf*2, out_channels = ndf*4, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch3 = nn.BatchNorm2d(ndf * 4)\n",
    "        self.conv4 = nn.Conv2d(in_channels = ndf*4, out_channels = ndf*8, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch4 = nn.BatchNorm2d(ndf * 8)\n",
    "        \n",
    "        #self.final_conv = nn.Conv2d(in_channels=ndf*8, out_channels=n_classes+1,kernel_size=4,stride=1,padding=0,bias=False)\n",
    "        self.final_conv = nn.Conv2d(in_channels=ndf*8, out_channels=1,kernel_size=4,stride=1,padding=0,bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch2(self.conv2(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch3(self.conv3(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch4(self.conv4(x)), 0.2, inplace=True)\n",
    "        x = self.final_conv(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        #x = x.view(-1, 1).squeeze(1)\n",
    "\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netG_DCGAN(nn.Module):\n",
    "    def __init__(self, ngpu, nz, nc , ngf):\n",
    "        super(_netG_DCGAN, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.convt1 = nn.ConvTranspose2d(in_channels=nz, out_channels=ngf * 8, kernel_size=4, stride=1, padding=0, bias=False)\n",
    "        self.batch1 = nn.BatchNorm2d(ngf*8)\n",
    "        self.convt2 = nn.ConvTranspose2d(in_channels=ngf * 8, out_channels=ngf * 4, kernel_size=4, stride=1, padding=0, bias=False)\n",
    "        self.batch2 = nn.BatchNorm2d(ngf*4)\n",
    "        self.convt3 = nn.ConvTranspose2d(in_channels=ngf * 4, out_channels=ngf * 2, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch3 = nn.BatchNorm2d(ngf*2)\n",
    "        self.convt4 = nn.ConvTranspose2d(in_channels=ngf*2, out_channels=ngf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch4 = nn.BatchNorm2d(ngf)\n",
    "        \n",
    "        self.final_convt = nn.ConvTranspose2d(in_channels=ngf, out_channels=nc, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print('1', x.size())\n",
    "        x = F.leaky_relu(self.batch1(self.convt1(x)), 0.2, inplace=True)\n",
    "        print('2', x.size())\n",
    "        \n",
    "        x = F.leaky_relu(self.batch2(self.convt2(x)), 0.2, inplace=True)\n",
    "        print('3', x.size())\n",
    "        \n",
    "        x = F.leaky_relu(self.batch3(self.convt3(x)), 0.2, inplace=True)\n",
    "        print('4', x.size())\n",
    "        \n",
    "        x = F.leaky_relu(self.batch4(self.convt4(x)), 0.2, inplace=True)\n",
    "        print('5', x.size())\n",
    "        \n",
    "        x = self.final_convt(x)\n",
    "        print('6', x.size())\n",
    "        \n",
    "        \n",
    "        x = F.tanh(x)\n",
    "        print('7', x.size())\n",
    "        \n",
    "        return (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netG_DCGAN_MNIST(nn.Module):\n",
    "    def __init__(self, nz, nc, ngf=64):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(nz, ngf * 4, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # state size. (ngf*4) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # state size. (ngf*2) x 7 x 7\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # state size. (ngf) x 14 x 14\n",
    "            nn.ConvTranspose2d(ngf, nc, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.Tanh()\n",
    "            \n",
    "            # state size. (nc) x 28 x 28\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netD_DCGAN_MNIST(nn.Module):\n",
    "    def __init__(self, nc, ndf=64):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 28 x 28\n",
    "            nn.Conv2d(nc, ndf, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. (ndf) x 14 x 14\n",
    "            nn.Conv2d(ndf, ndf * 2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. (ndf*2) x 7 x 7\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. (ndf*4) x 4 x 4\n",
    "            nn.Conv2d(ndf * 4, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output.view(-1, 1).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#netG = _netG_DCGAN(ngpu, nz, nc, ngf = 28)\n",
    "netG = _netG_DCGAN_MNIST(nz=nz, nc=nc, ngf=64)\n",
    "#netD = _netD_DCGAN(ngpu, nz, nc, ndf, n_classes)\n",
    "netD = _netD_DCGAN_MNIST(nc=nc, ndf=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializador de pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_netG_DCGAN_MNIST (\n",
      "  (main): Sequential (\n",
      "    (0): ConvTranspose2d(100, 256, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU (inplace)\n",
      "    (3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): ReLU (inplace)\n",
      "    (6): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (8): ReLU (inplace)\n",
      "    (9): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): Tanh ()\n",
      "  )\n",
      ") \n",
      " _netD_DCGAN_MNIST (\n",
      "  (main): Sequential (\n",
      "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU (0.2, inplace)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (4): LeakyReLU (0.2, inplace)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (7): LeakyReLU (0.2, inplace)\n",
      "    (8): Conv2d(256, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (9): Sigmoid ()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)\n",
    "print(netG, '\\n', netD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses\n",
    "- Binary Cross-Entropy is used to differentiate real and fake images\n",
    "- Class loss should be Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste se as redes estão funcionando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed for G creating an image = 0.071854 seconds.\n",
      "test_output G size torch.Size([64, 1, 28, 28])\n",
      "Time elapsed for D analysing fake image = 0.039540 seconds.\n"
     ]
    }
   ],
   "source": [
    "test_input_G = torch.randn(64,100,1,1)\n",
    "test_input_G = Variable(test_input_G)\n",
    "begin = time.time()\n",
    "test_output_G = netG(test_input_G)\n",
    "end = time.time()\n",
    "print('Time elapsed for G creating an image = {0:.6f} seconds.'.format(end-begin))\n",
    "print('test_output G size', test_output_G.size())\n",
    "begin = time.time()\n",
    "test_output_D = netD(test_output_G)\n",
    "end = time.time()\n",
    "print('Time elapsed for D analysing fake image = {0:.6f} seconds.'.format(end-begin))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste das camadas da rede do Lotufo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output_G = netG(test_input_G)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "28 -> 14 -> 7 -> 4 -> 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sizes of the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label = torch.FloatTensor(batch_size)\n",
    "print(label.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input images size: torch.Size([64, 3, 28, 28])\n",
      "Code size: torch.Size([64, 100, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# make our input tensors\n",
    "d_input = torch.FloatTensor(batch_size, 3, imageSize, imageSize)\n",
    "print('Input images size:', d_input.size())\n",
    "#nz its the latent dimension\n",
    "noise = torch.FloatTensor(batch_size, nz, 1, 1)\n",
    "fixed_noise = torch.FloatTensor(batch_size, nz, 1, 1).normal_(0, 1)\n",
    "print('Code size:', noise.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label size: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "#label = torch.LongTensor(batch_size,n_classes)\n",
    "label = torch.LongTensor(batch_size)\n",
    "print('Label size:', label.size())\n",
    "#fake_label = 10\n",
    "fake_label = 0\n",
    "real_label = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcast to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    netD.cuda()\n",
    "    netG.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    d_input,label = d_input.cuda(), label.cuda()\n",
    "    noise, fixed_noise = noise.cuda(), fixed_noise.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning tensors into Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "d_input = Variable(d_input)\n",
    "label = Variable(label)\n",
    "noise = Variable(noise)\n",
    "fixed_noise = Variable(fixed_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer Parameters\n",
    "- Following the lead of Radford et al., 2015:\n",
    "\n",
    "    <b>\n",
    "    1. beta1 = 0.5\n",
    "    2. beta2 = 0.999\n",
    "    3. lr = 0.0002\n",
    "    </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta1, beta2 = 0.5, 0.999\n",
    "lr = 2.0e-4\n",
    "optimizerD = optim.Adam(netD.parameters(), lr = lr, betas = (beta1, beta2))\n",
    "#optimizerD = optim.Adam(netD_parallel.parameters(), lr = lr, betas = (beta1, beta2))\n",
    "\n",
    "optimizerG = optim.Adam(netG.parameters(), lr = lr, betas = (beta1, beta2))\n",
    "#optimizerG = optim.Adam(netG_parallel.parameters(), lr = lr, betas = (beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator output size: torch.Size([64, 1, 28, 28])\n",
      "Discriminator output size: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "test_input_G = torch.randn(64, 100, 1, 1)\n",
    "test_input_G = Variable(test_input_G)\n",
    "test_output_G = netG(test_input_G.cuda())\n",
    "print('Generator output size:', test_output_G.size())\n",
    "then = time.time()\n",
    "test_output_D = netD(test_output_G)\n",
    "now = time.time()\n",
    "print('Discriminator output size:', test_output_D.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Treinamento "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#print(np.random.random_sample())\n",
    "#real_labelSmooth = 0.2\n",
    "#print(real_labelSmooth)\n",
    "#target = torch.from_numpy(np.random.randint(0, n_classes, batch_size)).type(torch.LongTensor).cuda()\n",
    "#print(target.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_gan(num_epochs, dataloader, netD, netG, outputDir, label, noise,\n",
    "              real_labelSmooth=0, epoch_interval=20, D_steps=1, G_steps=1):\n",
    "    \n",
    "    # This validation is subjective. WGAN-GP uses 100 steps on the critic (netD).\n",
    "    assert D_steps < 5, \"Keep it low, D_steps is too high.\"\n",
    "    assert G_steps < 3, \"Keep it low, G_steps is too high.\"\n",
    "    #assert batch_size % D_steps == 0, \"Use batch_size multiple of D_steps.\"\n",
    "    real_label = 1\n",
    "    size = int(len(dataloader.dataset)/dataloader.batch_size)\n",
    "    print('Lets train!')\n",
    "    loss_D = []\n",
    "    loss_G = []\n",
    "    for epoch in range(num_epochs):\n",
    "        start_iter = time.time()  \n",
    "        D_x = 0\n",
    "        D_G_z1 = 0\n",
    "        D_G_z2 = 0\n",
    "        errD_acum = 0\n",
    "        errG_acum = 0\n",
    "\n",
    "        for batch, data in enumerate(dataloader, 0):\n",
    "            if (epoch == 0 and batch == 0):\n",
    "                fig = plot_samples(data[0][0:data[0].size(0),:,:,:].cpu().numpy())\n",
    "                plt.savefig(outputDir + '/real_samples.png.png'.format(epoch, bbox_inches='tight'))\n",
    "                plt.close(fig)\n",
    "                #vutils.save_image(data[0][0:data[0].size(0),:,:,:], '%s/real_samples.png' % outputDir, nrow=8)\n",
    "            for step in range(D_steps):\n",
    "                #############################################################\n",
    "                # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "                # 1A - Train the detective network in the Real Dataset\n",
    "                #############################################################\n",
    "                netD.zero_grad()\n",
    "                start = step*(int(data[0].size()[0]/D_steps))\n",
    "                end = (step+1)*int(data[0].size()[0]/D_steps)\n",
    "                #real_cpu = data[0][start:end]\n",
    "                #if use_gpu:\n",
    "                    #real_cpu = real_cpu.cuda()\n",
    "                #d_input.resize_as_(data[0][start:end]).copy_(data[0][start:end])\n",
    "                d_input.data.resize_(data[0][start:end].size()).copy_(data[0][start:end])\n",
    "                \n",
    "                batch_size = data[0][start:end].size(0)\n",
    "                #batch_size = real_cpu.size(0)\n",
    "                \n",
    "                #label.data.resize_(batch_size).fill_(real_label - d_labelSmooth) # use smooth label for discriminator\n",
    "                label.data.resize_(batch_size).fill_(real_label)\n",
    "\n",
    "                \n",
    "                #  if np.random.random_sample() > real_labelSmooth:        \n",
    "                #target = data[1][start:end].long().cuda()\n",
    "                #else:\n",
    "                #     target = torch.from_numpy(np.random.randint(0, n_classes, batch_size)).type(torch.LongTensor).cuda()\n",
    "                \n",
    "                #d_input, label = Variable(real_cpu), Variable(target)\n",
    "                \n",
    "                output = netD(d_input)\n",
    "                #print('output size',output.size())\n",
    "                errD_real = criterion(output.squeeze(),label.float())\n",
    "                #errD_real = criterion(output,label)\n",
    "                \n",
    "                errD_real.backward()\n",
    "                \n",
    "                D_x += output.data.mean()\n",
    "                \n",
    "                #######################################################\n",
    "                # 1B - Train the detective network in the False Dataset\n",
    "                #######################################################\n",
    "                \n",
    "                noise = Variable(torch.FloatTensor(batch_size, nz, 1, 1).normal_(0,1).cuda())\n",
    "                fake = netG(noise)\n",
    "                \n",
    "                #print('fake',fake.size())\n",
    "                #label = Variable(torch.ones(batch_size).long().fill_(fake_label).cuda())\n",
    "                label.data.resize_(batch_size).fill_(fake_label)\n",
    "                \n",
    "                output = netD(fake.detach()) # \".detach()\" to avoid backprop through G\n",
    "                \n",
    "                errD_fake = criterion(output.squeeze(), label.float())\n",
    "                errD_fake.backward() # gradients for fake and real data will be accumulated\n",
    "                \n",
    "                D_G_z1 += output.data.mean()\n",
    "                errD_acum += errD_real.data[0] + errD_fake.data[0]\n",
    "                optimizerD.step() # .step() can be called once the gradients are computed\n",
    "\n",
    "            for step in range(G_steps):\n",
    "                ####################################################################################\n",
    "                # (2) Update G network: maximize log(D(G(z)))\n",
    "                # Train the faker with the output from the Detective (but don't train the Detective)\n",
    "                ####################################################################################\n",
    "                \n",
    "                netG.zero_grad()\n",
    "                #tudo 1\n",
    "                #label = Variable(torch.from_numpy(np.random.randint(0, n_classes, batch_size)).type(torch.LongTensor).cuda())\n",
    "                #label = Variable(torch.ones(batch_size).long().fill_(real_label).cuda())\n",
    "                label.data.resize_(batch_size).fill_(real_label)\n",
    "                \n",
    "                output = netD(fake)\n",
    "                errG = criterion(output.squeeze(), label.float())\n",
    "                errG.backward()\n",
    "                \n",
    "                D_G_z2 += output.data.mean()\n",
    "                errG_acum += errG.data[0]\n",
    "                optimizerG.step()\n",
    "                #del input, noise, label, output\n",
    "\n",
    "        print('epoch = ',epoch)\n",
    "\n",
    "        end_iter = time.time()        \n",
    "\n",
    "        print('[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z1)): %.4f D(G(z2)) %.4f Time Elapsed %.2f s'\n",
    "            % (epoch, num_epochs, (errD_acum/D_steps)/size, (errG_acum/G_steps)/size, D_x, D_G_z1, D_G_z2, end_iter-start_iter))\n",
    "\n",
    "        loss_D.append((errD_acum/D_steps)/size)\n",
    "        loss_G.append((errG_acum/G_steps)/size)\n",
    "        #Save a grid with the pictures from the dataset, up until 64\n",
    "        #save_images(netG = netG, fixed_noise=  fixed_noise, outputDir = outputDir, epoch = epoch)\n",
    "        print('printing')\n",
    "        save_images2(netG,fixed_noise,epoch)\n",
    "\n",
    "        if epoch % epoch_interval == 0:\n",
    "            # do checkpointing\n",
    "            save_models(netG = netG, netD = netD, outputDir = outputDir, epoch = epoch)\n",
    "    return(loss_D,loss_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets train!\n",
      "epoch =  0\n",
      "[0/100] Loss_D: 0.2830 Loss_G: 4.3040 D(x): 857.3953 D(G(z1)): 90.1812 D(G(z2)) 43.7846 Time Elapsed 13.19 s\n",
      "printing\n",
      "epoch =  1\n",
      "[1/100] Loss_D: 0.4771 Loss_G: 2.8465 D(x): 796.6783 D(G(z1)): 140.4279 D(G(z2)) 114.1726 Time Elapsed 12.15 s\n",
      "printing\n",
      "epoch =  2\n",
      "[2/100] Loss_D: 0.4347 Loss_G: 2.7888 D(x): 795.9810 D(G(z1)): 141.1598 D(G(z2)) 112.5392 Time Elapsed 12.49 s\n",
      "printing\n",
      "epoch =  3\n",
      "[3/100] Loss_D: 0.4060 Loss_G: 2.9243 D(x): 802.3320 D(G(z1)): 135.3940 D(G(z2)) 101.3496 Time Elapsed 12.86 s\n",
      "printing\n",
      "epoch =  4\n",
      "[4/100] Loss_D: 0.3852 Loss_G: 3.0075 D(x): 807.7244 D(G(z1)): 130.2276 D(G(z2)) 94.6850 Time Elapsed 13.03 s\n",
      "printing\n",
      "epoch =  5\n",
      "[5/100] Loss_D: 0.3957 Loss_G: 3.0315 D(x): 803.5543 D(G(z1)): 133.8866 D(G(z2)) 95.5364 Time Elapsed 13.03 s\n",
      "printing\n",
      "epoch =  6\n",
      "[6/100] Loss_D: 0.3693 Loss_G: 3.1649 D(x): 810.9027 D(G(z1)): 126.5039 D(G(z2)) 87.6134 Time Elapsed 12.99 s\n",
      "printing\n",
      "epoch =  7\n",
      "[7/100] Loss_D: 0.3976 Loss_G: 3.1138 D(x): 802.0075 D(G(z1)): 135.0220 D(G(z2)) 93.6840 Time Elapsed 12.94 s\n",
      "printing\n",
      "epoch =  8\n",
      "[8/100] Loss_D: 0.3779 Loss_G: 3.2494 D(x): 810.2679 D(G(z1)): 127.7688 D(G(z2)) 84.6443 Time Elapsed 13.16 s\n",
      "printing\n",
      "epoch =  9\n",
      "[9/100] Loss_D: 0.3291 Loss_G: 3.4287 D(x): 823.6377 D(G(z1)): 113.8362 D(G(z2)) 74.7384 Time Elapsed 13.03 s\n",
      "printing\n",
      "epoch =  10\n",
      "[10/100] Loss_D: 0.3463 Loss_G: 3.3933 D(x): 818.9377 D(G(z1)): 119.0103 D(G(z2)) 79.8440 Time Elapsed 13.07 s\n",
      "printing\n",
      "epoch =  11\n",
      "[11/100] Loss_D: 0.3626 Loss_G: 3.4193 D(x): 816.4913 D(G(z1)): 120.9866 D(G(z2)) 81.3424 Time Elapsed 13.04 s\n",
      "printing\n",
      "epoch =  12\n",
      "[12/100] Loss_D: 0.3409 Loss_G: 3.4614 D(x): 822.7769 D(G(z1)): 114.9809 D(G(z2)) 75.1855 Time Elapsed 13.01 s\n",
      "printing\n",
      "epoch =  13\n",
      "[13/100] Loss_D: 0.3316 Loss_G: 3.5360 D(x): 825.8292 D(G(z1)): 112.1535 D(G(z2)) 74.9698 Time Elapsed 12.96 s\n",
      "printing\n",
      "epoch =  14\n",
      "[14/100] Loss_D: 0.3390 Loss_G: 3.5554 D(x): 823.5840 D(G(z1)): 114.1653 D(G(z2)) 73.6450 Time Elapsed 13.00 s\n",
      "printing\n",
      "epoch =  15\n",
      "[15/100] Loss_D: 0.3258 Loss_G: 3.6089 D(x): 829.2201 D(G(z1)): 108.6572 D(G(z2)) 71.2040 Time Elapsed 13.03 s\n",
      "printing\n",
      "epoch =  16\n",
      "[16/100] Loss_D: 0.3081 Loss_G: 3.7257 D(x): 833.9964 D(G(z1)): 104.2729 D(G(z2)) 66.6214 Time Elapsed 13.06 s\n",
      "printing\n",
      "epoch =  17\n",
      "[17/100] Loss_D: 0.3085 Loss_G: 3.7178 D(x): 834.2793 D(G(z1)): 103.0932 D(G(z2)) 67.3216 Time Elapsed 12.90 s\n",
      "printing\n",
      "epoch =  18\n",
      "[18/100] Loss_D: 0.2953 Loss_G: 3.7955 D(x): 836.9087 D(G(z1)): 101.1795 D(G(z2)) 62.2766 Time Elapsed 13.08 s\n",
      "printing\n",
      "epoch =  19\n",
      "[19/100] Loss_D: 0.3232 Loss_G: 3.7696 D(x): 832.9321 D(G(z1)): 104.8608 D(G(z2)) 65.9069 Time Elapsed 12.98 s\n",
      "printing\n",
      "epoch =  20\n",
      "[20/100] Loss_D: 0.3029 Loss_G: 3.7992 D(x): 836.5114 D(G(z1)): 101.3051 D(G(z2)) 62.8027 Time Elapsed 13.07 s\n",
      "printing\n",
      "epoch =  21\n",
      "[21/100] Loss_D: 0.3313 Loss_G: 3.8301 D(x): 830.2798 D(G(z1)): 107.9841 D(G(z2)) 66.9369 Time Elapsed 13.16 s\n",
      "printing\n",
      "epoch =  22\n",
      "[22/100] Loss_D: 0.2641 Loss_G: 3.9072 D(x): 845.8283 D(G(z1)): 91.8831 D(G(z2)) 55.0791 Time Elapsed 12.92 s\n",
      "printing\n",
      "epoch =  23\n",
      "[23/100] Loss_D: 0.2993 Loss_G: 3.9777 D(x): 840.3735 D(G(z1)): 97.6002 D(G(z2)) 59.6225 Time Elapsed 12.96 s\n",
      "printing\n",
      "epoch =  24\n",
      "[24/100] Loss_D: 0.2936 Loss_G: 3.9773 D(x): 842.1815 D(G(z1)): 95.4400 D(G(z2)) 57.8865 Time Elapsed 13.00 s\n",
      "printing\n",
      "epoch =  25\n",
      "[25/100] Loss_D: 0.2722 Loss_G: 4.0943 D(x): 847.8573 D(G(z1)): 90.6733 D(G(z2)) 54.1393 Time Elapsed 13.28 s\n",
      "printing\n",
      "epoch =  26\n",
      "[26/100] Loss_D: 0.2732 Loss_G: 4.0598 D(x): 845.9040 D(G(z1)): 91.6441 D(G(z2)) 55.0025 Time Elapsed 13.25 s\n",
      "printing\n",
      "epoch =  27\n",
      "[27/100] Loss_D: 0.2642 Loss_G: 4.0843 D(x): 850.5671 D(G(z1)): 87.6192 D(G(z2)) 53.6535 Time Elapsed 13.17 s\n",
      "printing\n",
      "epoch =  28\n",
      "[28/100] Loss_D: 0.2869 Loss_G: 4.1711 D(x): 846.2519 D(G(z1)): 91.7100 D(G(z2)) 56.8789 Time Elapsed 13.31 s\n",
      "printing\n",
      "epoch =  29\n",
      "[29/100] Loss_D: 0.2878 Loss_G: 4.0709 D(x): 844.9274 D(G(z1)): 93.0370 D(G(z2)) 55.9973 Time Elapsed 13.15 s\n",
      "printing\n",
      "epoch =  30\n",
      "[30/100] Loss_D: 0.2494 Loss_G: 4.1880 D(x): 853.3785 D(G(z1)): 84.2988 D(G(z2)) 50.3688 Time Elapsed 13.23 s\n",
      "printing\n",
      "epoch =  31\n",
      "[31/100] Loss_D: 0.2818 Loss_G: 4.1474 D(x): 847.6279 D(G(z1)): 90.8175 D(G(z2)) 55.6520 Time Elapsed 13.04 s\n",
      "printing\n",
      "epoch =  32\n",
      "[32/100] Loss_D: 0.2469 Loss_G: 4.2492 D(x): 854.6063 D(G(z1)): 83.1789 D(G(z2)) 50.1010 Time Elapsed 13.28 s\n",
      "printing\n",
      "epoch =  33\n",
      "[33/100] Loss_D: 0.2747 Loss_G: 4.2098 D(x): 847.7759 D(G(z1)): 90.5461 D(G(z2)) 54.0667 Time Elapsed 13.27 s\n",
      "printing\n",
      "epoch =  34\n",
      "[34/100] Loss_D: 0.2608 Loss_G: 4.2880 D(x): 853.5955 D(G(z1)): 84.2915 D(G(z2)) 49.4054 Time Elapsed 13.15 s\n",
      "printing\n",
      "epoch =  35\n",
      "[35/100] Loss_D: 0.2595 Loss_G: 4.2622 D(x): 853.5606 D(G(z1)): 84.3840 D(G(z2)) 49.1312 Time Elapsed 13.31 s\n",
      "printing\n",
      "epoch =  36\n",
      "[36/100] Loss_D: 0.2956 Loss_G: 4.2159 D(x): 843.5598 D(G(z1)): 94.4145 D(G(z2)) 54.3471 Time Elapsed 13.07 s\n",
      "printing\n",
      "epoch =  37\n",
      "[37/100] Loss_D: 0.2528 Loss_G: 4.2662 D(x): 854.6806 D(G(z1)): 83.4409 D(G(z2)) 50.1323 Time Elapsed 13.10 s\n",
      "printing\n",
      "epoch =  38\n",
      "[38/100] Loss_D: 0.2568 Loss_G: 4.3321 D(x): 854.2699 D(G(z1)): 83.5991 D(G(z2)) 49.4496 Time Elapsed 13.19 s\n",
      "printing\n",
      "epoch =  39\n",
      "[39/100] Loss_D: 0.2548 Loss_G: 4.3506 D(x): 854.5144 D(G(z1)): 83.5306 D(G(z2)) 49.8394 Time Elapsed 13.10 s\n",
      "printing\n",
      "epoch =  40\n",
      "[40/100] Loss_D: 0.2536 Loss_G: 4.3242 D(x): 854.7565 D(G(z1)): 83.3953 D(G(z2)) 47.5329 Time Elapsed 12.96 s\n",
      "printing\n",
      "epoch =  41\n",
      "[41/100] Loss_D: 0.2248 Loss_G: 4.4926 D(x): 864.8482 D(G(z1)): 73.1194 D(G(z2)) 44.5197 Time Elapsed 13.15 s\n",
      "printing\n",
      "epoch =  42\n",
      "[42/100] Loss_D: 0.2541 Loss_G: 4.4150 D(x): 857.3935 D(G(z1)): 80.7384 D(G(z2)) 47.2946 Time Elapsed 13.29 s\n",
      "printing\n",
      "epoch =  43\n",
      "[43/100] Loss_D: 0.2403 Loss_G: 4.4709 D(x): 861.3578 D(G(z1)): 76.7057 D(G(z2)) 43.8198 Time Elapsed 13.14 s\n",
      "printing\n",
      "epoch =  44\n",
      "[44/100] Loss_D: 0.2327 Loss_G: 4.4744 D(x): 861.0218 D(G(z1)): 76.9322 D(G(z2)) 45.0859 Time Elapsed 13.18 s\n",
      "printing\n",
      "epoch =  45\n",
      "[45/100] Loss_D: 0.2804 Loss_G: 4.4473 D(x): 854.3194 D(G(z1)): 83.6338 D(G(z2)) 49.5135 Time Elapsed 13.23 s\n",
      "printing\n",
      "epoch =  46\n",
      "[46/100] Loss_D: 0.2341 Loss_G: 4.4674 D(x): 860.6089 D(G(z1)): 77.5109 D(G(z2)) 46.6298 Time Elapsed 13.18 s\n",
      "printing\n",
      "epoch =  47\n",
      "[47/100] Loss_D: 0.1916 Loss_G: 4.5598 D(x): 870.3124 D(G(z1)): 67.6502 D(G(z2)) 38.0266 Time Elapsed 13.25 s\n",
      "printing\n",
      "epoch =  48\n",
      "[48/100] Loss_D: 0.2622 Loss_G: 4.5134 D(x): 854.6422 D(G(z1)): 83.6034 D(G(z2)) 47.8321 Time Elapsed 13.14 s\n",
      "printing\n",
      "epoch =  49\n",
      "[49/100] Loss_D: 0.2399 Loss_G: 4.5444 D(x): 861.6533 D(G(z1)): 76.1285 D(G(z2)) 44.6517 Time Elapsed 13.11 s\n",
      "printing\n",
      "epoch =  50\n",
      "[50/100] Loss_D: 0.2391 Loss_G: 4.5364 D(x): 861.1235 D(G(z1)): 76.8591 D(G(z2)) 45.2445 Time Elapsed 13.24 s\n",
      "printing\n",
      "epoch =  51\n",
      "[51/100] Loss_D: 0.2325 Loss_G: 4.5508 D(x): 862.9281 D(G(z1)): 75.3342 D(G(z2)) 43.4252 Time Elapsed 13.07 s\n",
      "printing\n",
      "epoch =  52\n",
      "[52/100] Loss_D: 0.2663 Loss_G: 4.5439 D(x): 856.0642 D(G(z1)): 81.9756 D(G(z2)) 47.6028 Time Elapsed 13.12 s\n",
      "printing\n",
      "epoch =  53\n",
      "[53/100] Loss_D: 0.2172 Loss_G: 4.6602 D(x): 866.2595 D(G(z1)): 71.6695 D(G(z2)) 41.9419 Time Elapsed 13.10 s\n",
      "printing\n",
      "epoch =  54\n",
      "[54/100] Loss_D: 0.2552 Loss_G: 4.6597 D(x): 859.4322 D(G(z1)): 78.5245 D(G(z2)) 44.0128 Time Elapsed 13.33 s\n",
      "printing\n",
      "epoch =  55\n",
      "[55/100] Loss_D: 0.2386 Loss_G: 4.5179 D(x): 859.8758 D(G(z1)): 78.4142 D(G(z2)) 43.5423 Time Elapsed 13.16 s\n",
      "printing\n",
      "epoch =  56\n",
      "[56/100] Loss_D: 0.2076 Loss_G: 4.6833 D(x): 867.9850 D(G(z1)): 69.9358 D(G(z2)) 36.7237 Time Elapsed 13.05 s\n",
      "printing\n",
      "epoch =  57\n",
      "[57/100] Loss_D: 0.2608 Loss_G: 4.6852 D(x): 862.3272 D(G(z1)): 75.6813 D(G(z2)) 43.3134 Time Elapsed 13.17 s\n",
      "printing\n",
      "epoch =  58\n",
      "[58/100] Loss_D: 0.2018 Loss_G: 4.7080 D(x): 870.8045 D(G(z1)): 67.1934 D(G(z2)) 37.0772 Time Elapsed 13.10 s\n",
      "printing\n",
      "epoch =  59\n",
      "[59/100] Loss_D: 0.2218 Loss_G: 4.7208 D(x): 865.7251 D(G(z1)): 72.2965 D(G(z2)) 37.7983 Time Elapsed 13.12 s\n",
      "printing\n",
      "epoch =  60\n",
      "[60/100] Loss_D: 0.2267 Loss_G: 4.6911 D(x): 863.8177 D(G(z1)): 74.2826 D(G(z2)) 41.9004 Time Elapsed 13.01 s\n",
      "printing\n",
      "epoch =  61\n",
      "[61/100] Loss_D: 0.2349 Loss_G: 4.6780 D(x): 863.2273 D(G(z1)): 74.7973 D(G(z2)) 41.1910 Time Elapsed 12.99 s\n",
      "printing\n",
      "epoch =  62\n",
      "[62/100] Loss_D: 0.2292 Loss_G: 4.8123 D(x): 864.7777 D(G(z1)): 73.2590 D(G(z2)) 39.9328 Time Elapsed 13.31 s\n",
      "printing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  63\n",
      "[63/100] Loss_D: 0.1926 Loss_G: 4.8202 D(x): 873.3527 D(G(z1)): 64.9311 D(G(z2)) 35.0673 Time Elapsed 13.27 s\n",
      "printing\n",
      "epoch =  64\n",
      "[64/100] Loss_D: 0.2175 Loss_G: 4.8488 D(x): 867.6881 D(G(z1)): 70.2555 D(G(z2)) 38.0786 Time Elapsed 13.15 s\n",
      "printing\n",
      "epoch =  65\n",
      "[65/100] Loss_D: 0.2148 Loss_G: 4.8666 D(x): 867.9814 D(G(z1)): 69.8678 D(G(z2)) 38.8239 Time Elapsed 13.05 s\n",
      "printing\n",
      "epoch =  66\n",
      "[66/100] Loss_D: 0.2278 Loss_G: 4.7722 D(x): 868.8744 D(G(z1)): 69.8565 D(G(z2)) 38.5368 Time Elapsed 13.25 s\n",
      "printing\n",
      "epoch =  67\n",
      "[67/100] Loss_D: 0.2345 Loss_G: 4.7951 D(x): 863.5964 D(G(z1)): 74.0022 D(G(z2)) 39.5472 Time Elapsed 13.35 s\n",
      "printing\n",
      "epoch =  68\n",
      "[68/100] Loss_D: 0.1993 Loss_G: 4.9317 D(x): 874.1501 D(G(z1)): 63.7339 D(G(z2)) 34.1374 Time Elapsed 13.35 s\n",
      "printing\n",
      "epoch =  69\n",
      "[69/100] Loss_D: 0.2357 Loss_G: 4.7959 D(x): 867.0160 D(G(z1)): 71.0965 D(G(z2)) 39.5114 Time Elapsed 13.39 s\n",
      "printing\n",
      "epoch =  70\n",
      "[70/100] Loss_D: 0.2124 Loss_G: 4.7621 D(x): 867.9887 D(G(z1)): 70.2711 D(G(z2)) 38.6421 Time Elapsed 13.31 s\n",
      "printing\n",
      "epoch =  71\n",
      "[71/100] Loss_D: 0.2363 Loss_G: 4.7995 D(x): 866.1285 D(G(z1)): 71.7816 D(G(z2)) 39.2555 Time Elapsed 13.33 s\n",
      "printing\n",
      "epoch =  72\n",
      "[72/100] Loss_D: 0.2364 Loss_G: 4.7983 D(x): 865.3533 D(G(z1)): 72.7069 D(G(z2)) 37.4097 Time Elapsed 13.04 s\n",
      "printing\n",
      "epoch =  73\n",
      "[73/100] Loss_D: 0.1758 Loss_G: 4.9871 D(x): 877.5625 D(G(z1)): 60.2857 D(G(z2)) 31.4085 Time Elapsed 13.29 s\n",
      "printing\n",
      "epoch =  74\n",
      "[74/100] Loss_D: 0.2364 Loss_G: 4.8919 D(x): 863.0228 D(G(z1)): 75.5474 D(G(z2)) 38.9576 Time Elapsed 13.39 s\n",
      "printing\n",
      "epoch =  75\n",
      "[75/100] Loss_D: 0.2093 Loss_G: 4.8677 D(x): 868.4419 D(G(z1)): 69.4172 D(G(z2)) 34.3968 Time Elapsed 13.22 s\n",
      "printing\n",
      "epoch =  76\n",
      "[76/100] Loss_D: 0.2231 Loss_G: 4.9593 D(x): 868.3953 D(G(z1)): 69.7225 D(G(z2)) 36.1819 Time Elapsed 13.40 s\n",
      "printing\n",
      "epoch =  77\n",
      "[77/100] Loss_D: 0.2123 Loss_G: 4.9285 D(x): 869.2307 D(G(z1)): 68.9258 D(G(z2)) 35.6407 Time Elapsed 13.43 s\n",
      "printing\n",
      "epoch =  78\n",
      "[78/100] Loss_D: 0.1978 Loss_G: 4.9712 D(x): 872.0675 D(G(z1)): 65.7732 D(G(z2)) 33.1382 Time Elapsed 13.26 s\n",
      "printing\n",
      "epoch =  79\n",
      "[79/100] Loss_D: 0.2086 Loss_G: 5.0015 D(x): 873.6102 D(G(z1)): 64.3258 D(G(z2)) 33.6245 Time Elapsed 13.46 s\n",
      "printing\n",
      "epoch =  80\n",
      "[80/100] Loss_D: 0.1946 Loss_G: 5.0600 D(x): 872.7320 D(G(z1)): 65.3077 D(G(z2)) 34.9183 Time Elapsed 13.26 s\n",
      "printing\n",
      "epoch =  81\n",
      "[81/100] Loss_D: 0.2245 Loss_G: 5.0222 D(x): 871.1729 D(G(z1)): 67.0095 D(G(z2)) 36.0859 Time Elapsed 13.11 s\n",
      "printing\n",
      "epoch =  82\n",
      "[82/100] Loss_D: 0.1886 Loss_G: 5.0355 D(x): 875.7632 D(G(z1)): 62.2009 D(G(z2)) 31.5825 Time Elapsed 13.23 s\n",
      "printing\n",
      "epoch =  83\n",
      "[83/100] Loss_D: 0.1867 Loss_G: 5.1056 D(x): 877.9460 D(G(z1)): 60.2292 D(G(z2)) 30.9908 Time Elapsed 13.04 s\n",
      "printing\n",
      "epoch =  84\n",
      "[84/100] Loss_D: 0.2382 Loss_G: 5.0006 D(x): 866.0760 D(G(z1)): 72.1067 D(G(z2)) 38.7188 Time Elapsed 13.04 s\n",
      "printing\n",
      "epoch =  85\n",
      "[85/100] Loss_D: 0.2063 Loss_G: 5.0650 D(x): 873.1969 D(G(z1)): 64.7518 D(G(z2)) 33.5016 Time Elapsed 13.27 s\n",
      "printing\n",
      "epoch =  86\n",
      "[86/100] Loss_D: 0.1899 Loss_G: 5.0541 D(x): 877.8612 D(G(z1)): 60.0521 D(G(z2)) 30.2750 Time Elapsed 13.16 s\n",
      "printing\n",
      "epoch =  87\n",
      "[87/100] Loss_D: 0.1792 Loss_G: 5.2660 D(x): 878.9807 D(G(z1)): 59.2052 D(G(z2)) 29.7763 Time Elapsed 13.09 s\n",
      "printing\n",
      "epoch =  88\n",
      "[88/100] Loss_D: 0.2111 Loss_G: 5.0938 D(x): 869.8780 D(G(z1)): 68.2438 D(G(z2)) 33.3500 Time Elapsed 13.24 s\n",
      "printing\n",
      "epoch =  89\n",
      "[89/100] Loss_D: 0.1465 Loss_G: 5.3127 D(x): 886.5252 D(G(z1)): 51.4927 D(G(z2)) 25.0793 Time Elapsed 13.26 s\n",
      "printing\n",
      "epoch =  90\n",
      "[90/100] Loss_D: 0.1981 Loss_G: 5.2550 D(x): 873.8224 D(G(z1)): 64.3691 D(G(z2)) 34.4189 Time Elapsed 13.25 s\n",
      "printing\n",
      "epoch =  91\n",
      "[91/100] Loss_D: 0.1816 Loss_G: 5.2430 D(x): 879.4646 D(G(z1)): 58.4169 D(G(z2)) 31.6134 Time Elapsed 13.38 s\n",
      "printing\n",
      "epoch =  92\n",
      "[92/100] Loss_D: 0.2062 Loss_G: 5.2297 D(x): 876.0179 D(G(z1)): 62.1287 D(G(z2)) 33.5039 Time Elapsed 13.18 s\n",
      "printing\n",
      "epoch =  93\n",
      "[93/100] Loss_D: 0.2037 Loss_G: 5.1682 D(x): 874.3549 D(G(z1)): 63.7638 D(G(z2)) 32.9173 Time Elapsed 13.22 s\n",
      "printing\n",
      "epoch =  94\n",
      "[94/100] Loss_D: 0.1506 Loss_G: 5.3528 D(x): 888.5882 D(G(z1)): 49.3477 D(G(z2)) 26.3487 Time Elapsed 13.10 s\n",
      "printing\n",
      "epoch =  95\n",
      "[95/100] Loss_D: 0.1935 Loss_G: 5.2550 D(x): 877.0073 D(G(z1)): 61.0840 D(G(z2)) 30.0744 Time Elapsed 13.14 s\n",
      "printing\n",
      "epoch =  96\n",
      "[96/100] Loss_D: 0.1974 Loss_G: 5.3203 D(x): 880.5689 D(G(z1)): 57.5601 D(G(z2)) 28.3781 Time Elapsed 13.27 s\n",
      "printing\n",
      "epoch =  97\n",
      "[97/100] Loss_D: 0.1822 Loss_G: 5.3655 D(x): 879.2363 D(G(z1)): 58.8758 D(G(z2)) 30.3612 Time Elapsed 13.49 s\n",
      "printing\n",
      "epoch =  98\n",
      "[98/100] Loss_D: 0.2026 Loss_G: 5.2674 D(x): 874.9289 D(G(z1)): 63.1562 D(G(z2)) 33.8455 Time Elapsed 13.12 s\n",
      "printing\n",
      "epoch =  99\n",
      "[99/100] Loss_D: 0.1455 Loss_G: 5.3645 D(x): 888.9562 D(G(z1)): 48.8875 D(G(z2)) 24.6590 Time Elapsed 13.19 s\n",
      "printing\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "real_labelSmooth = 0.2\n",
    "\n",
    "loss_D,loss_G = train_gan(num_epochs, dataloader, netD,netG, outputDir,label,noise, real_labelSmooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(loss,label):\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(range(0,num_epochs),loss, label = label)\n",
    "    #plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "plot_graph(loss_D,'loss_D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(loss_G,'loss_G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histories():\n",
    "    x = range(len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_plot(num_epochs,save_interval,outputDir):\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 18))\n",
    "\n",
    "    for i, fn in enumerate(range(0, num_epochs, save_interval)):\n",
    "        fig.add_subplot(4, 3, i+1)\n",
    "        image_fn = outputDir + '/dcgan_img_{:04d}.png'.format(fn)\n",
    "\n",
    "        img = plt.imread(image_fn)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title('{} iterations'.format(fn+1))\n",
    "        \n",
    "final_plot(num_epochs=num_epochs, save_interval=5,outputDir = outputDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 1\n",
    "entrada1 = torch.randn(64,100,1,1)\n",
    "entrada1 = Variable(entrada1)\n",
    "convt = nn.ConvTranspose2d(in_channels=nz, out_channels=ngf * 8, kernel_size=(4,4), stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "entrada2 = convt(entrada1)\n",
    "print(entrada2.size())\n",
    "plt.imshow(entrada2.data.numpy()[0,0,:,:],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 1\n",
    "\n",
    "for i in range(40):\n",
    "    entrada1 = torch.randn(10,100,32,32)\n",
    "\n",
    "    entrada1 = Variable(entrada1)\n",
    "    #convt = nn.ConvTranspose2d(in_channels=nz, out_channels=ngf * 8, kernel_size=(4,4), stride=stride, padding=1, bias=False)\n",
    "    convt = nn.Conv2d(in_channels=nz, out_channels=ngf * 8, kernel_size=(3,3), stride = i+1, padding = 1)\n",
    "\n",
    "\n",
    "    entrada2 = convt(entrada1)\n",
    "    #print('Para padding = ',i, 'A dimensao gerada é = ',entrada2.size())\n",
    "    print('Para stride = ',i+1, 'A dimensao gerada é = ',entrada2.size())\n",
    "    #plt.imshow(entrada2.data.numpy()[0,0,:,:],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
