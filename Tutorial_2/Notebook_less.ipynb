{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch as tc\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import sys,os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import models\n",
    "from models import weights_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using CUDA. If it is not what you want, manually set this as False!\n"
     ]
    }
   ],
   "source": [
    "#Libera as funcionalidades da biblioteca cudnn\n",
    "cudnn.benchmark = True\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "#use_gpu = False\n",
    "if use_gpu:\n",
    "    print(\"You are using CUDA. If it is not what you want, manually set this as False!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nc = 3\n",
    "ngpu = 1\n",
    "nz = 100\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "n_extra_d = 0\n",
    "n_extra_g = 1 # Aqui a jogada é que o gerador deve ser mais poderoso q o detetive\n",
    "imageSize = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gabriel/Redes Neurais/Projeto_Final_GANS/Tutorial_2/images\r\n"
     ]
    }
   ],
   "source": [
    "!cd images && pwd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setando as transformações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'images/images2/': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls images/images2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anime-faces  min_anime-faces  teste\r\n"
     ]
    }
   ],
   "source": [
    "!ls dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dset.ImageFolder(\n",
    "    root='/home/gabriel/Redes Neurais/Projeto_Final_GANS/Tutorial_2/dataset/min_anime-faces',\n",
    "    transform=transforms.Compose([\n",
    "            transforms.Scale((imageSize, imageSize)),\n",
    "            # transforms.CenterCrop(opt.imageSize),\n",
    "            transforms.ToTensor(),\n",
    "            #transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)), # bring images to (-1,1)\n",
    "        ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setando o Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "num_workers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dataloader = tc.utils.data.DataLoader(dataset, batch_size=64, shuffle=True, num_workers=1)\n",
    "#126 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setando o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netD_1(nn.Module):\n",
    "    def __init__(self, ngpu, nz, nc, ndf,  n_extra_layers_d):\n",
    "        super(_netD_1, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        main = nn.Sequential(\n",
    "            # input is (nc) x 96 x 96\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False), # 5,3,1 for 96x96\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "        )\n",
    "\n",
    "        # Extra layers\n",
    "        for t in range(n_extra_layers_d):\n",
    "            main.add_module('extra-layers-{0}.{1}.conv'.format(t, ndf * 8),\n",
    "                            nn.Conv2d(ndf * 8, ndf * 8, 3, 1, 1, bias=False))\n",
    "            main.add_module('extra-layers-{0}.{1}.batchnorm'.format(t, ndf * 8),\n",
    "                            nn.BatchNorm2d(ndf * 8))\n",
    "            main.add_module('extra-layers-{0}.{1}.relu'.format(t, ndf * 8),\n",
    "                            nn.LeakyReLU(0.2, inplace=True))\n",
    "\n",
    "\n",
    "        main.add_module('final_layers.conv', nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False))\n",
    "        main.add_module('final_layers.sigmoid', nn.Sigmoid())\n",
    "        # state size. 1 x 1 x 1\n",
    "        self.main = main\n",
    "\n",
    "    def forward(self, input):\n",
    "        gpu_ids = None\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            gpu_ids = range(self.ngpu)\n",
    "        output = nn.parallel.data_parallel(self.main, input, gpu_ids)\n",
    "        return output.view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DCGAN model, fully convolutional architecture\n",
    "class _netG_1(nn.Module):\n",
    "    def __init__(self, ngpu, nz, nc , ngf, n_extra_layers_g):\n",
    "        super(_netG_1, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        #self.nz = nz\n",
    "        #self.nc = nc\n",
    "        #self.ngf = ngf\n",
    "        main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            # state size. nz x 1 x 1\n",
    "            nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "        )\n",
    "\n",
    "        # Extra layers\n",
    "        for t in range(n_extra_layers_g):\n",
    "            main.add_module('extra-layers-{0}.{1}.conv'.format(t, ngf),\n",
    "                            nn.Conv2d(ngf, ngf, 3, 1, 1, bias=False))\n",
    "            main.add_module('extra-layers-{0}.{1}.batchnorm'.format(t, ngf),\n",
    "                            nn.BatchNorm2d(ngf))\n",
    "            main.add_module('extra-layers-{0}.{1}.relu'.format(t, ngf),\n",
    "                            nn.LeakyReLU(0.2, inplace=True))\n",
    "\n",
    "        main.add_module('final_layer.deconv', \n",
    "        \t             nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False)) # 5,3,1 for 96x96\n",
    "        main.add_module('final_layer.tanh', \n",
    "        \t             nn.Tanh())\n",
    "            # state size. (nc) x 96 x 96\n",
    "\n",
    "        self.main = main\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        gpu_ids = None\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            gpu_ids = range(self.ngpu)\n",
    "        return nn.parallel.data_parallel(self.main, input, gpu_ids), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netG = _netG_1(ngpu, nz, nc, ngf, n_extra_g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_netG_1 (\n",
      "  (main): Sequential (\n",
      "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): LeakyReLU (0.2, inplace)\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): LeakyReLU (0.2, inplace)\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (8): LeakyReLU (0.2, inplace)\n",
      "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (11): LeakyReLU (0.2, inplace)\n",
      "    (extra-layers-0.64.conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (extra-layers-0.64.batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (extra-layers-0.64.relu): LeakyReLU (0.2, inplace)\n",
      "    (final_layer.deconv): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (final_layer.tanh): Tanh ()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netD = _netD_1(ngpu, nz, nc, ndf, n_extra_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_netD_1 (\n",
      "  (main): Sequential (\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU (0.2, inplace)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (4): LeakyReLU (0.2, inplace)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (7): LeakyReLU (0.2, inplace)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (10): LeakyReLU (0.2, inplace)\n",
      "    (final_layers.conv): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (final_layers.sigmoid): Sigmoid ()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(netD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando pesos pré-treinados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "#Parece ser um inicializador de pesos hardcoded\n",
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)\n",
    "print(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load=False\n",
    "if load:\n",
    "    netD.load_state_dict(tc.load('path_d'))\n",
    "    netG.load_state_dict(torch.load('path_G'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametros de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "criterion_MSE = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 64, 64])\n",
      "torch.Size([64, 100, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input = torch.FloatTensor(batch_size, 3, imageSize, imageSize)\n",
    "print(input.size())\n",
    "noise = torch.FloatTensor(batch_size, nz, 1, 1)\n",
    "print(noise.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parser.add_argument('--binary', action='store_true', help='z from bernoulli distribution, with prob=0.5')\n",
    "binary=False\n",
    "#Ele testa pergunta se vc quer que o seu Z venha da distribuição bernoulli\n",
    "if binary:\n",
    "    bernoulli_prob = torch.FloatTensor(batch_size, nz, 1, 1).fill_(0.5)\n",
    "    fixed_noise = torch.bernoulli(bernoulli_prob)\n",
    "else:\n",
    "    fixed_noise = torch.FloatTensor(batch_size, nz, 1, 1).normal_(0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = torch.FloatTensor(batch_size)\n",
    "real_label = 1\n",
    "fake_label = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcast para CUDA, se quiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    netD.cuda()\n",
    "    netG.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    criterion_MSE = criterion_MSE.cuda()\n",
    "    input,label = input.cuda(), label.cuda()\n",
    "    noise, fixed_noise = noise.cuda(), fixed_noise.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformando tudo em variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "input = Variable(input)\n",
    "label = Variable(label)\n",
    "noise = Variable(noise)\n",
    "fixed_noise = Variable(fixed_noise)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setando o optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta1, beta2 = 0.9,0.999\n",
    "lr = 2.0e-4\n",
    "optimizerD = optim.Adam(netD.parameters(), lr = lr, betas = (beta1, beta2))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr = lr, betas = (beta1, beta2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando o diretório vazio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS error: [Errno 17] File exists: 'outputdir'\n"
     ]
    }
   ],
   "source": [
    "outputDir = 'outputdir'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([64, 3, 64, 64])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "print(type(input))\n",
    "print(input.size())\n",
    "print(label.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_both_networks(num_epochs, dataloader, netD, netG, d_labelSmooth, outputDir, model_option =1,binary = False):\n",
    "    use_gpu = tc.cuda.is_available()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            start_iter = time.time()\n",
    "            ############################\n",
    "            # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "            ###########################\n",
    "            # train with real\n",
    "            netD.zero_grad()\n",
    "            real_cpu, _ = data\n",
    "            batch_size = real_cpu.size(0)\n",
    "            input.data.resize_(real_cpu.size()).copy_(real_cpu)\n",
    "            label.data.resize_(batch_size).fill_(real_label - d_labelSmooth) # use smooth label for discriminator\n",
    "\n",
    "            output = netD(input)\n",
    "            errD_real = criterion(output, label)\n",
    "            errD_real.backward()\n",
    "            D_x = output.data.mean()\n",
    "            # train with fake\n",
    "            noise.data.resize_(batch_size, nz, 1, 1)\n",
    "            if binary:\n",
    "                bernoulli_prob.resize_(noise.data.size())\n",
    "                noise.data.copy_(2*(torch.bernoulli(bernoulli_prob)-0.5))\n",
    "            else:\n",
    "                noise.data.normal_(0, 1)\n",
    "            fake,z_prediction = netG(noise)\n",
    "            label.data.fill_(fake_label)\n",
    "            output = netD(fake.detach()) # add \".detach()\" to avoid backprop through G\n",
    "            errD_fake = criterion(output, label)\n",
    "            errD_fake.backward() # gradients for fake/real will be accumulated\n",
    "            D_G_z1 = output.data.mean()\n",
    "            errD = errD_real + errD_fake\n",
    "            optimizerD.step() # .step() can be called once the gradients are computed\n",
    "\n",
    "            ############################\n",
    "            # (2) Update G network: maximize log(D(G(z)))\n",
    "            ###########################\n",
    "            netG.zero_grad()\n",
    "            label.data.fill_(real_label) # fake labels are real for generator cost\n",
    "            output = netD(fake)\n",
    "            errG = criterion(output, label)\n",
    "            errG.backward(retain_variables=True) # True if backward through the graph for the second time\n",
    "            if model_option == 2: # with z predictor\n",
    "                errG_z = criterion_MSE(z_prediction, noise)\n",
    "                errG_z.backward()\n",
    "            D_G_z2 = output.data.mean()\n",
    "            optimizerG.step()\n",
    "\n",
    "            end_iter = time.time()\n",
    "            print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f Elapsed %.2f s'\n",
    "                  % (epoch, num_epochs, i, len(dataloader),\n",
    "                     errD.data[0], errG.data[0], D_x, D_G_z1, D_G_z2, end_iter-start_iter))\n",
    "            if i % 100 == 0:\n",
    "                # the first 64 samples from the mini-batch are saved.\n",
    "                vutils.save_image(real_cpu[0:64,:,:,:],\n",
    "                        '%s/real_samples.png' % outputDir, nrow=8)\n",
    "                fake,_ = netG(fixed_noise)\n",
    "                vutils.save_image(fake.data[0:64,:,:,:],\n",
    "                        '%s/fake_samples_epoch_%03d.png' % (outputDir, epoch), nrow=8)\n",
    "        if epoch % 1 == 0:\n",
    "            # do checkpointing\n",
    "            torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (outputDir, epoch))\n",
    "            torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (outputDir, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torch/nn/functional.py:767: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
      "/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torch/autograd/__init__.py:92: UserWarning: retain_variables option is deprecated and will be removed in 0.3. Use retain_graph instead.\n",
      "  warnings.warn(\"retain_variables option is deprecated and will be removed in 0.3. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/100][0/472] Loss_D: 0.5550 Loss_G: 6.0013 D(x): 0.7179 D(G(z)): 0.0050 / 0.0028 Elapsed 0.07 s\n",
      "[0/100][1/472] Loss_D: 0.5488 Loss_G: 5.4888 D(x): 0.7544 D(G(z)): 0.0061 / 0.0046 Elapsed 0.07 s\n",
      "[0/100][2/472] Loss_D: 0.5627 Loss_G: 5.5027 D(x): 0.8589 D(G(z)): 0.0102 / 0.0044 Elapsed 0.10 s\n",
      "[0/100][3/472] Loss_D: 0.5516 Loss_G: 5.8319 D(x): 0.8198 D(G(z)): 0.0087 / 0.0032 Elapsed 0.08 s\n",
      "[0/100][4/472] Loss_D: 0.5457 Loss_G: 5.8564 D(x): 0.7788 D(G(z)): 0.0080 / 0.0033 Elapsed 0.09 s\n",
      "[0/100][5/472] Loss_D: 0.5566 Loss_G: 5.4754 D(x): 0.7172 D(G(z)): 0.0064 / 0.0047 Elapsed 0.09 s\n",
      "[0/100][6/472] Loss_D: 0.5507 Loss_G: 5.4311 D(x): 0.8287 D(G(z)): 0.0094 / 0.0049 Elapsed 0.08 s\n",
      "[0/100][7/472] Loss_D: 0.5712 Loss_G: 5.9228 D(x): 0.8849 D(G(z)): 0.0110 / 0.0031 Elapsed 0.10 s\n",
      "[0/100][8/472] Loss_D: 0.5439 Loss_G: 6.6266 D(x): 0.8285 D(G(z)): 0.0059 / 0.0014 Elapsed 0.08 s\n",
      "[0/100][9/472] Loss_D: 0.6500 Loss_G: 5.7425 D(x): 0.5990 D(G(z)): 0.0031 / 0.0035 Elapsed 0.10 s\n",
      "[0/100][10/472] Loss_D: 0.5445 Loss_G: 4.6867 D(x): 0.7515 D(G(z)): 0.0072 / 0.0098 Elapsed 0.08 s\n",
      "[0/100][11/472] Loss_D: 0.5869 Loss_G: 4.6170 D(x): 0.8938 D(G(z)): 0.0228 / 0.0106 Elapsed 0.09 s\n",
      "[0/100][12/472] Loss_D: 0.5881 Loss_G: 5.3611 D(x): 0.8867 D(G(z)): 0.0284 / 0.0051 Elapsed 0.09 s\n",
      "[0/100][13/472] Loss_D: 0.5505 Loss_G: 6.2048 D(x): 0.7832 D(G(z)): 0.0120 / 0.0022 Elapsed 0.08 s\n",
      "[0/100][14/472] Loss_D: 0.5587 Loss_G: 6.2553 D(x): 0.6955 D(G(z)): 0.0051 / 0.0021 Elapsed 0.10 s\n",
      "[0/100][15/472] Loss_D: 0.5839 Loss_G: 5.1370 D(x): 0.6653 D(G(z)): 0.0065 / 0.0066 Elapsed 0.08 s\n",
      "[0/100][16/472] Loss_D: 0.6015 Loss_G: 3.8632 D(x): 0.7703 D(G(z)): 0.0261 / 0.0233 Elapsed 0.09 s\n",
      "[0/100][17/472] Loss_D: 0.6248 Loss_G: 4.3238 D(x): 0.8759 D(G(z)): 0.0656 / 0.0148 Elapsed 0.09 s\n",
      "[0/100][18/472] Loss_D: 0.5738 Loss_G: 5.7214 D(x): 0.8585 D(G(z)): 0.0343 / 0.0039 Elapsed 0.09 s\n",
      "[0/100][19/472] Loss_D: 0.6351 Loss_G: 4.8383 D(x): 0.6508 D(G(z)): 0.0311 / 0.0085 Elapsed 0.10 s\n",
      "[0/100][20/472] Loss_D: 0.5491 Loss_G: 5.2154 D(x): 0.7928 D(G(z)): 0.0218 / 0.0057 Elapsed 0.08 s\n",
      "[0/100][21/472] Loss_D: 0.6806 Loss_G: 3.9520 D(x): 0.6422 D(G(z)): 0.0348 / 0.0207 Elapsed 0.11 s\n",
      "[0/100][22/472] Loss_D: 0.5986 Loss_G: 4.1069 D(x): 0.8205 D(G(z)): 0.0648 / 0.0180 Elapsed 0.08 s\n",
      "[0/100][23/472] Loss_D: 0.6151 Loss_G: 4.6069 D(x): 0.7832 D(G(z)): 0.0753 / 0.0110 Elapsed 0.09 s\n",
      "[0/100][24/472] Loss_D: 0.6572 Loss_G: 4.8204 D(x): 0.6002 D(G(z)): 0.0216 / 0.0092 Elapsed 0.09 s\n",
      "[0/100][25/472] Loss_D: 0.5735 Loss_G: 4.5402 D(x): 0.7871 D(G(z)): 0.0330 / 0.0127 Elapsed 0.08 s\n",
      "[0/100][26/472] Loss_D: 0.5948 Loss_G: 4.8609 D(x): 0.8239 D(G(z)): 0.0345 / 0.0092 Elapsed 0.10 s\n",
      "[0/100][27/472] Loss_D: 0.6304 Loss_G: 5.9082 D(x): 0.8604 D(G(z)): 0.0192 / 0.0035 Elapsed 0.08 s\n",
      "[0/100][28/472] Loss_D: 0.5668 Loss_G: 6.0618 D(x): 0.7776 D(G(z)): 0.0132 / 0.0032 Elapsed 0.09 s\n",
      "[0/100][29/472] Loss_D: 0.6064 Loss_G: 5.6841 D(x): 0.7475 D(G(z)): 0.0108 / 0.0044 Elapsed 0.08 s\n",
      "[0/100][30/472] Loss_D: 0.6650 Loss_G: 4.3160 D(x): 0.6467 D(G(z)): 0.0155 / 0.0192 Elapsed 0.09 s\n",
      "[0/100][31/472] Loss_D: 0.7408 Loss_G: 3.8091 D(x): 0.8071 D(G(z)): 0.0517 / 0.0296 Elapsed 0.10 s\n",
      "[0/100][32/472] Loss_D: 0.7705 Loss_G: 4.6451 D(x): 0.8970 D(G(z)): 0.1389 / 0.0123 Elapsed 0.08 s\n",
      "[0/100][33/472] Loss_D: 0.6922 Loss_G: 5.5254 D(x): 0.7108 D(G(z)): 0.0366 / 0.0060 Elapsed 0.11 s\n",
      "[0/100][34/472] Loss_D: 0.7826 Loss_G: 4.6076 D(x): 0.5516 D(G(z)): 0.0203 / 0.0162 Elapsed 0.07 s\n",
      "[0/100][35/472] Loss_D: 0.6912 Loss_G: 3.8756 D(x): 0.7234 D(G(z)): 0.0293 / 0.0277 Elapsed 0.10 s\n",
      "[0/100][36/472] Loss_D: 0.6769 Loss_G: 4.5480 D(x): 0.9092 D(G(z)): 0.0492 / 0.0155 Elapsed 0.09 s\n",
      "[0/100][37/472] Loss_D: 0.7327 Loss_G: 5.5230 D(x): 0.8975 D(G(z)): 0.0419 / 0.0052 Elapsed 0.08 s\n",
      "[0/100][38/472] Loss_D: 0.6832 Loss_G: 6.3745 D(x): 0.7545 D(G(z)): 0.0113 / 0.0024 Elapsed 0.10 s\n",
      "[0/100][39/472] Loss_D: 0.6288 Loss_G: 6.3909 D(x): 0.7813 D(G(z)): 0.0080 / 0.0022 Elapsed 0.08 s\n",
      "[0/100][40/472] Loss_D: 0.6124 Loss_G: 6.2256 D(x): 0.7203 D(G(z)): 0.0046 / 0.0025 Elapsed 0.10 s\n",
      "[0/100][41/472] Loss_D: 0.6158 Loss_G: 5.3640 D(x): 0.7158 D(G(z)): 0.0061 / 0.0060 Elapsed 0.08 s\n",
      "[0/100][42/472] Loss_D: 0.6120 Loss_G: 4.7032 D(x): 0.7789 D(G(z)): 0.0130 / 0.0121 Elapsed 0.09 s\n",
      "[0/100][43/472] Loss_D: 0.6469 Loss_G: 4.4783 D(x): 0.8429 D(G(z)): 0.0319 / 0.0147 Elapsed 0.10 s\n",
      "[0/100][44/472] Loss_D: 0.6497 Loss_G: 4.8273 D(x): 0.8552 D(G(z)): 0.0478 / 0.0103 Elapsed 0.08 s\n",
      "[0/100][45/472] Loss_D: 0.6172 Loss_G: 5.6697 D(x): 0.7576 D(G(z)): 0.0147 / 0.0044 Elapsed 0.10 s\n",
      "[0/100][46/472] Loss_D: 0.6149 Loss_G: 5.1091 D(x): 0.6696 D(G(z)): 0.0105 / 0.0077 Elapsed 0.08 s\n",
      "[0/100][47/472] Loss_D: 0.5966 Loss_G: 4.2853 D(x): 0.7523 D(G(z)): 0.0150 / 0.0158 Elapsed 0.10 s\n",
      "[0/100][48/472] Loss_D: 0.6272 Loss_G: 4.1375 D(x): 0.8442 D(G(z)): 0.0372 / 0.0203 Elapsed 0.09 s\n",
      "[0/100][49/472] Loss_D: 0.6817 Loss_G: 4.4131 D(x): 0.8037 D(G(z)): 0.0394 / 0.0131 Elapsed 0.08 s\n",
      "[0/100][50/472] Loss_D: 0.5881 Loss_G: 5.2917 D(x): 0.8267 D(G(z)): 0.0259 / 0.0055 Elapsed 0.10 s\n",
      "[0/100][51/472] Loss_D: 0.6419 Loss_G: 4.9197 D(x): 0.6430 D(G(z)): 0.0108 / 0.0080 Elapsed 0.08 s\n",
      "[0/100][52/472] Loss_D: 0.6163 Loss_G: 4.0730 D(x): 0.7120 D(G(z)): 0.0156 / 0.0203 Elapsed 0.10 s\n",
      "[0/100][53/472] Loss_D: 0.6559 Loss_G: 4.3561 D(x): 0.8908 D(G(z)): 0.0383 / 0.0137 Elapsed 0.08 s\n",
      "[0/100][54/472] Loss_D: 0.6045 Loss_G: 5.4768 D(x): 0.8562 D(G(z)): 0.0217 / 0.0055 Elapsed 0.09 s\n",
      "[0/100][55/472] Loss_D: 0.6142 Loss_G: 5.5546 D(x): 0.7094 D(G(z)): 0.0103 / 0.0064 Elapsed 0.09 s\n",
      "[0/100][56/472] Loss_D: 0.6223 Loss_G: 4.9439 D(x): 0.6851 D(G(z)): 0.0092 / 0.0114 Elapsed 0.08 s\n",
      "[0/100][57/472] Loss_D: 0.6089 Loss_G: 3.8087 D(x): 0.7667 D(G(z)): 0.0229 / 0.0270 Elapsed 0.10 s\n",
      "[0/100][58/472] Loss_D: 0.6653 Loss_G: 4.3625 D(x): 0.9062 D(G(z)): 0.0378 / 0.0156 Elapsed 0.08 s\n",
      "[0/100][59/472] Loss_D: 0.5916 Loss_G: 5.0366 D(x): 0.8394 D(G(z)): 0.0325 / 0.0082 Elapsed 0.10 s\n",
      "[0/100][60/472] Loss_D: 0.5916 Loss_G: 5.0698 D(x): 0.7148 D(G(z)): 0.0147 / 0.0071 Elapsed 0.08 s\n",
      "[0/100][61/472] Loss_D: 0.7507 Loss_G: 3.0843 D(x): 0.5213 D(G(z)): 0.0143 / 0.0532 Elapsed 0.09 s\n",
      "[0/100][62/472] Loss_D: 0.7124 Loss_G: 2.9503 D(x): 0.8717 D(G(z)): 0.0972 / 0.0565 Elapsed 0.10 s\n",
      "[0/100][63/472] Loss_D: 0.6925 Loss_G: 4.4712 D(x): 0.8865 D(G(z)): 0.1019 / 0.0155 Elapsed 0.08 s\n",
      "[0/100][64/472] Loss_D: 0.5685 Loss_G: 5.9392 D(x): 0.7903 D(G(z)): 0.0259 / 0.0050 Elapsed 0.10 s\n",
      "[0/100][65/472] Loss_D: 0.8344 Loss_G: 4.8234 D(x): 0.5123 D(G(z)): 0.0114 / 0.0118 Elapsed 0.08 s\n",
      "[0/100][66/472] Loss_D: 0.6112 Loss_G: 3.8886 D(x): 0.7588 D(G(z)): 0.0190 / 0.0256 Elapsed 0.09 s\n",
      "[0/100][67/472] Loss_D: 0.6646 Loss_G: 3.8626 D(x): 0.9010 D(G(z)): 0.0453 / 0.0235 Elapsed 0.09 s\n",
      "[0/100][68/472] Loss_D: 0.6542 Loss_G: 4.6152 D(x): 0.8856 D(G(z)): 0.0485 / 0.0112 Elapsed 0.08 s\n",
      "[0/100][69/472] Loss_D: 0.6306 Loss_G: 5.1297 D(x): 0.7540 D(G(z)): 0.0234 / 0.0067 Elapsed 0.10 s\n",
      "[0/100][70/472] Loss_D: 0.6419 Loss_G: 5.2486 D(x): 0.6815 D(G(z)): 0.0097 / 0.0060 Elapsed 0.08 s\n",
      "[0/100][71/472] Loss_D: 0.6210 Loss_G: 4.3580 D(x): 0.6924 D(G(z)): 0.0131 / 0.0151 Elapsed 0.10 s\n",
      "[0/100][72/472] Loss_D: 0.6171 Loss_G: 3.7569 D(x): 0.7546 D(G(z)): 0.0246 / 0.0301 Elapsed 0.07 s\n",
      "[0/100][73/472] Loss_D: 0.6639 Loss_G: 3.0697 D(x): 0.7424 D(G(z)): 0.0469 / 0.0519 Elapsed 0.10 s\n",
      "[0/100][74/472] Loss_D: 0.6976 Loss_G: 3.2118 D(x): 0.8043 D(G(z)): 0.0951 / 0.0524 Elapsed 0.08 s\n",
      "[0/100][75/472] Loss_D: 0.7167 Loss_G: 4.1053 D(x): 0.8233 D(G(z)): 0.0705 / 0.0199 Elapsed 0.09 s\n",
      "[0/100][76/472] Loss_D: 0.6197 Loss_G: 4.6878 D(x): 0.7498 D(G(z)): 0.0269 / 0.0100 Elapsed 0.10 s\n",
      "[0/100][77/472] Loss_D: 0.6039 Loss_G: 4.7459 D(x): 0.7013 D(G(z)): 0.0134 / 0.0101 Elapsed 0.08 s\n",
      "[0/100][78/472] Loss_D: 0.6165 Loss_G: 4.4016 D(x): 0.7440 D(G(z)): 0.0179 / 0.0178 Elapsed 0.10 s\n",
      "[0/100][79/472] Loss_D: 0.6506 Loss_G: 3.9058 D(x): 0.6806 D(G(z)): 0.0193 / 0.0256 Elapsed 0.08 s\n",
      "[0/100][80/472] Loss_D: 0.6220 Loss_G: 3.7978 D(x): 0.8524 D(G(z)): 0.0434 / 0.0265 Elapsed 0.10 s\n",
      "[0/100][81/472] Loss_D: 0.5884 Loss_G: 4.2574 D(x): 0.8361 D(G(z)): 0.0348 / 0.0150 Elapsed 0.09 s\n",
      "[0/100][82/472] Loss_D: 0.5968 Loss_G: 4.6657 D(x): 0.7699 D(G(z)): 0.0210 / 0.0117 Elapsed 0.08 s\n",
      "[0/100][83/472] Loss_D: 0.5974 Loss_G: 4.7512 D(x): 0.7260 D(G(z)): 0.0132 / 0.0103 Elapsed 0.10 s\n",
      "[0/100][84/472] Loss_D: 0.6096 Loss_G: 4.0502 D(x): 0.7236 D(G(z)): 0.0194 / 0.0203 Elapsed 0.08 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/100][85/472] Loss_D: 0.5989 Loss_G: 3.9245 D(x): 0.8061 D(G(z)): 0.0276 / 0.0224 Elapsed 0.10 s\n",
      "[0/100][86/472] Loss_D: 0.6453 Loss_G: 3.9848 D(x): 0.8133 D(G(z)): 0.0299 / 0.0206 Elapsed 0.07 s\n",
      "[0/100][87/472] Loss_D: 0.5767 Loss_G: 4.1305 D(x): 0.8014 D(G(z)): 0.0312 / 0.0180 Elapsed 0.10 s\n",
      "[0/100][88/472] Loss_D: 0.6016 Loss_G: 4.4121 D(x): 0.7677 D(G(z)): 0.0240 / 0.0142 Elapsed 0.08 s\n",
      "[0/100][89/472] Loss_D: 0.6089 Loss_G: 4.1469 D(x): 0.7451 D(G(z)): 0.0248 / 0.0179 Elapsed 0.09 s\n",
      "[0/100][90/472] Loss_D: 0.5812 Loss_G: 4.2486 D(x): 0.7892 D(G(z)): 0.0241 / 0.0163 Elapsed 0.09 s\n",
      "[0/100][91/472] Loss_D: 0.5866 Loss_G: 4.0434 D(x): 0.7210 D(G(z)): 0.0208 / 0.0200 Elapsed 0.08 s\n",
      "[0/100][92/472] Loss_D: 0.6100 Loss_G: 3.3760 D(x): 0.7339 D(G(z)): 0.0340 / 0.0374 Elapsed 0.10 s\n",
      "[0/100][93/472] Loss_D: 0.6251 Loss_G: 3.5728 D(x): 0.8272 D(G(z)): 0.0455 / 0.0307 Elapsed 0.08 s\n",
      "[0/100][94/472] Loss_D: 0.5973 Loss_G: 3.9050 D(x): 0.8214 D(G(z)): 0.0511 / 0.0237 Elapsed 0.09 s\n",
      "[0/100][95/472] Loss_D: 0.5942 Loss_G: 4.1827 D(x): 0.7488 D(G(z)): 0.0307 / 0.0174 Elapsed 0.09 s\n",
      "[0/100][96/472] Loss_D: 0.6068 Loss_G: 3.8540 D(x): 0.7073 D(G(z)): 0.0281 / 0.0238 Elapsed 0.09 s\n",
      "[0/100][97/472] Loss_D: 0.5887 Loss_G: 3.6071 D(x): 0.7701 D(G(z)): 0.0358 / 0.0308 Elapsed 0.10 s\n",
      "[0/100][98/472] Loss_D: 0.5978 Loss_G: 4.1013 D(x): 0.8461 D(G(z)): 0.0401 / 0.0203 Elapsed 0.08 s\n",
      "[0/100][99/472] Loss_D: 0.5961 Loss_G: 4.4183 D(x): 0.7722 D(G(z)): 0.0262 / 0.0141 Elapsed 0.10 s\n",
      "[0/100][100/472] Loss_D: 0.5785 Loss_G: 4.2892 D(x): 0.7371 D(G(z)): 0.0257 / 0.0170 Elapsed 0.08 s\n",
      "[0/100][101/472] Loss_D: 0.5893 Loss_G: 4.4117 D(x): 0.7577 D(G(z)): 0.0198 / 0.0151 Elapsed 0.07 s\n",
      "[0/100][102/472] Loss_D: 0.5707 Loss_G: 4.2115 D(x): 0.7738 D(G(z)): 0.0239 / 0.0185 Elapsed 0.11 s\n",
      "[0/100][103/472] Loss_D: 0.6251 Loss_G: 3.7072 D(x): 0.7260 D(G(z)): 0.0293 / 0.0297 Elapsed 0.06 s\n",
      "[0/100][104/472] Loss_D: 0.6212 Loss_G: 3.6907 D(x): 0.8519 D(G(z)): 0.0605 / 0.0301 Elapsed 0.10 s\n",
      "[0/100][105/472] Loss_D: 0.6078 Loss_G: 4.3981 D(x): 0.7998 D(G(z)): 0.0415 / 0.0162 Elapsed 0.07 s\n",
      "[0/100][106/472] Loss_D: 0.6108 Loss_G: 4.3862 D(x): 0.6974 D(G(z)): 0.0255 / 0.0162 Elapsed 0.10 s\n",
      "[0/100][107/472] Loss_D: 0.5832 Loss_G: 4.3154 D(x): 0.7653 D(G(z)): 0.0213 / 0.0172 Elapsed 0.08 s\n",
      "[0/100][108/472] Loss_D: 0.5864 Loss_G: 4.0300 D(x): 0.7881 D(G(z)): 0.0311 / 0.0227 Elapsed 0.09 s\n",
      "[0/100][109/472] Loss_D: 0.5877 Loss_G: 4.1656 D(x): 0.8235 D(G(z)): 0.0357 / 0.0185 Elapsed 0.10 s\n",
      "[0/100][110/472] Loss_D: 0.5853 Loss_G: 4.5232 D(x): 0.7727 D(G(z)): 0.0233 / 0.0131 Elapsed 0.08 s\n",
      "[0/100][111/472] Loss_D: 0.6005 Loss_G: 4.2508 D(x): 0.7401 D(G(z)): 0.0205 / 0.0172 Elapsed 0.10 s\n",
      "[0/100][112/472] Loss_D: 0.6939 Loss_G: 2.9489 D(x): 0.6641 D(G(z)): 0.0416 / 0.0614 Elapsed 0.07 s\n",
      "[0/100][113/472] Loss_D: 0.6755 Loss_G: 3.4084 D(x): 0.8741 D(G(z)): 0.0694 / 0.0382 Elapsed 0.10 s\n",
      "[0/100][114/472] Loss_D: 0.6276 Loss_G: 3.9427 D(x): 0.8178 D(G(z)): 0.0723 / 0.0231 Elapsed 0.09 s\n",
      "[0/100][115/472] Loss_D: 0.6647 Loss_G: 4.1070 D(x): 0.6706 D(G(z)): 0.0298 / 0.0201 Elapsed 0.08 s\n",
      "[0/100][116/472] Loss_D: 0.6001 Loss_G: 3.8515 D(x): 0.7485 D(G(z)): 0.0327 / 0.0250 Elapsed 0.10 s\n",
      "[0/100][117/472] Loss_D: 0.7128 Loss_G: 2.7251 D(x): 0.6592 D(G(z)): 0.0776 / 0.0790 Elapsed 0.08 s\n",
      "[0/100][118/472] Loss_D: 0.7095 Loss_G: 3.2546 D(x): 0.8056 D(G(z)): 0.1051 / 0.0485 Elapsed 0.10 s\n",
      "[0/100][119/472] Loss_D: 0.6461 Loss_G: 4.4076 D(x): 0.8388 D(G(z)): 0.0790 / 0.0155 Elapsed 0.06 s\n",
      "[0/100][120/472] Loss_D: 0.7032 Loss_G: 4.1616 D(x): 0.6142 D(G(z)): 0.0466 / 0.0223 Elapsed 0.07 s\n",
      "[0/100][121/472] Loss_D: 0.6124 Loss_G: 4.4156 D(x): 0.7472 D(G(z)): 0.0371 / 0.0183 Elapsed 0.06 s\n",
      "[0/100][122/472] Loss_D: 0.7705 Loss_G: 3.0882 D(x): 0.5679 D(G(z)): 0.0444 / 0.0619 Elapsed 0.10 s\n",
      "[0/100][123/472] Loss_D: 0.6899 Loss_G: 3.6367 D(x): 0.8869 D(G(z)): 0.0861 / 0.0429 Elapsed 0.07 s\n",
      "[0/100][124/472] Loss_D: 0.6808 Loss_G: 4.8609 D(x): 0.8841 D(G(z)): 0.0650 / 0.0131 Elapsed 0.10 s\n",
      "[0/100][125/472] Loss_D: 0.6302 Loss_G: 4.9802 D(x): 0.7196 D(G(z)): 0.0340 / 0.0088 Elapsed 0.08 s\n",
      "[0/100][126/472] Loss_D: 0.6102 Loss_G: 5.1705 D(x): 0.7304 D(G(z)): 0.0206 / 0.0072 Elapsed 0.10 s\n",
      "[0/100][127/472] Loss_D: 0.6088 Loss_G: 4.8327 D(x): 0.7220 D(G(z)): 0.0187 / 0.0100 Elapsed 0.08 s\n",
      "[0/100][128/472] Loss_D: 0.6973 Loss_G: 3.5236 D(x): 0.6246 D(G(z)): 0.0306 / 0.0369 Elapsed 0.09 s\n",
      "[0/100][129/472] Loss_D: 0.6791 Loss_G: 3.8206 D(x): 0.8631 D(G(z)): 0.0728 / 0.0260 Elapsed 0.09 s\n",
      "[0/100][130/472] Loss_D: 0.6920 Loss_G: 5.0447 D(x): 0.8782 D(G(z)): 0.0558 / 0.0077 Elapsed 0.08 s\n",
      "[0/100][131/472] Loss_D: 0.6344 Loss_G: 6.0810 D(x): 0.7399 D(G(z)): 0.0130 / 0.0028 Elapsed 0.10 s\n",
      "[0/100][132/472] Loss_D: 0.7012 Loss_G: 5.5443 D(x): 0.5938 D(G(z)): 0.0058 / 0.0050 Elapsed 0.08 s\n",
      "[0/100][133/472] Loss_D: 0.6283 Loss_G: 4.6326 D(x): 0.7373 D(G(z)): 0.0096 / 0.0110 Elapsed 0.09 s\n",
      "[0/100][134/472] Loss_D: 0.6363 Loss_G: 4.4795 D(x): 0.8723 D(G(z)): 0.0236 / 0.0141 Elapsed 0.09 s\n",
      "[0/100][135/472] Loss_D: 0.6556 Loss_G: 5.1409 D(x): 0.8616 D(G(z)): 0.0209 / 0.0072 Elapsed 0.08 s\n",
      "[0/100][136/472] Loss_D: 0.6056 Loss_G: 5.6187 D(x): 0.8341 D(G(z)): 0.0177 / 0.0050 Elapsed 0.10 s\n",
      "[0/100][137/472] Loss_D: 0.5908 Loss_G: 5.8945 D(x): 0.7512 D(G(z)): 0.0086 / 0.0034 Elapsed 0.08 s\n",
      "[0/100][138/472] Loss_D: 0.6322 Loss_G: 5.6522 D(x): 0.6813 D(G(z)): 0.0058 / 0.0049 Elapsed 0.10 s\n",
      "[0/100][139/472] Loss_D: 0.6268 Loss_G: 4.9275 D(x): 0.6831 D(G(z)): 0.0076 / 0.0115 Elapsed 0.08 s\n",
      "[0/100][140/472] Loss_D: 0.6043 Loss_G: 4.5298 D(x): 0.8581 D(G(z)): 0.0190 / 0.0167 Elapsed 0.09 s\n",
      "[0/100][141/472] Loss_D: 0.7370 Loss_G: 4.7981 D(x): 0.9169 D(G(z)): 0.0695 / 0.0172 Elapsed 0.10 s\n",
      "[0/100][142/472] Loss_D: 0.5876 Loss_G: 6.0450 D(x): 0.8214 D(G(z)): 0.0145 / 0.0031 Elapsed 0.08 s\n",
      "[0/100][143/472] Loss_D: 0.5830 Loss_G: 6.1284 D(x): 0.6777 D(G(z)): 0.0058 / 0.0028 Elapsed 0.10 s\n",
      "[0/100][144/472] Loss_D: 0.6149 Loss_G: 5.2660 D(x): 0.7011 D(G(z)): 0.0070 / 0.0059 Elapsed 0.08 s\n",
      "[0/100][145/472] Loss_D: 0.5679 Loss_G: 4.5055 D(x): 0.7544 D(G(z)): 0.0107 / 0.0122 Elapsed 0.09 s\n",
      "[0/100][146/472] Loss_D: 0.6381 Loss_G: 3.9566 D(x): 0.7932 D(G(z)): 0.0197 / 0.0207 Elapsed 0.09 s\n",
      "[0/100][147/472] Loss_D: 0.6472 Loss_G: 3.6856 D(x): 0.8411 D(G(z)): 0.0550 / 0.0285 Elapsed 0.08 s\n",
      "[0/100][148/472] Loss_D: 0.6165 Loss_G: 4.6620 D(x): 0.8660 D(G(z)): 0.0305 / 0.0105 Elapsed 0.11 s\n",
      "[0/100][149/472] Loss_D: 0.5893 Loss_G: 4.5953 D(x): 0.7236 D(G(z)): 0.0252 / 0.0121 Elapsed 0.08 s\n",
      "[0/100][150/472] Loss_D: 0.6891 Loss_G: 4.1731 D(x): 0.6021 D(G(z)): 0.0191 / 0.0200 Elapsed 0.10 s\n",
      "[0/100][151/472] Loss_D: 0.6317 Loss_G: 3.2087 D(x): 0.7049 D(G(z)): 0.0457 / 0.0479 Elapsed 0.09 s\n",
      "[0/100][152/472] Loss_D: 0.6364 Loss_G: 3.7575 D(x): 0.8914 D(G(z)): 0.0551 / 0.0265 Elapsed 0.08 s\n",
      "[0/100][153/472] Loss_D: 0.5867 Loss_G: 4.1552 D(x): 0.7942 D(G(z)): 0.0411 / 0.0171 Elapsed 0.10 s\n",
      "[0/100][154/472] Loss_D: 0.5969 Loss_G: 4.9544 D(x): 0.8385 D(G(z)): 0.0216 / 0.0077 Elapsed 0.08 s\n",
      "[0/100][155/472] Loss_D: 0.5995 Loss_G: 5.2149 D(x): 0.7113 D(G(z)): 0.0111 / 0.0061 Elapsed 0.10 s\n",
      "[0/100][156/472] Loss_D: 0.5609 Loss_G: 5.0549 D(x): 0.7333 D(G(z)): 0.0090 / 0.0071 Elapsed 0.08 s\n",
      "[0/100][157/472] Loss_D: 0.5795 Loss_G: 4.7807 D(x): 0.7972 D(G(z)): 0.0115 / 0.0094 Elapsed 0.09 s\n",
      "[0/100][158/472] Loss_D: 0.5497 Loss_G: 4.9195 D(x): 0.8193 D(G(z)): 0.0115 / 0.0084 Elapsed 0.09 s\n",
      "[0/100][159/472] Loss_D: 0.5502 Loss_G: 5.0666 D(x): 0.8092 D(G(z)): 0.0106 / 0.0076 Elapsed 0.08 s\n",
      "[0/100][160/472] Loss_D: 0.5605 Loss_G: 4.8992 D(x): 0.7562 D(G(z)): 0.0108 / 0.0091 Elapsed 0.10 s\n",
      "[0/100][161/472] Loss_D: 0.6181 Loss_G: 4.1806 D(x): 0.6577 D(G(z)): 0.0126 / 0.0182 Elapsed 0.08 s\n",
      "[0/100][162/472] Loss_D: 0.5600 Loss_G: 3.7506 D(x): 0.8285 D(G(z)): 0.0240 / 0.0264 Elapsed 0.10 s\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Traceback (most recent call last):\n  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 40, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torchvision-0.1.9-py3.5.egg/torchvision/datasets/folder.py\", line 116, in __getitem__\n    img = self.loader(path)\n  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torchvision-0.1.9-py3.5.egg/torchvision/datasets/folder.py\", line 63, in default_loader\n    return pil_loader(path)\n  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torchvision-0.1.9-py3.5.egg/torchvision/datasets/folder.py\", line 45, in pil_loader\n    with Image.open(f) as img:\n  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/PIL/Image.py\", line 2452, in open\n    % (filename if filename else fp))\nOSError: cannot identify image file <_io.BufferedReader name='/home/gabriel/Redes Neurais/Projeto_Final_GANS/Tutorial_2/dataset/min_anime-faces/black_eyes/danbooru_2605393_76dd8fe243b4e17da1c3350b94b16044.jpg'>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-6d2496b5b10d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0md_labelSmooth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_both_networks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnetG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_labelSmooth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputDir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-1e046641018d>\u001b[0m in \u001b[0;36mtrain_both_networks\u001b[0;34m(num_epochs, dataloader, netD, netG, d_labelSmooth, outputDir, model_option, binary)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mstart_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;31m############################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Traceback (most recent call last):\n  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 40, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torchvision-0.1.9-py3.5.egg/torchvision/datasets/folder.py\", line 116, in __getitem__\n    img = self.loader(path)\n  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torchvision-0.1.9-py3.5.egg/torchvision/datasets/folder.py\", line 63, in default_loader\n    return pil_loader(path)\n  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torchvision-0.1.9-py3.5.egg/torchvision/datasets/folder.py\", line 45, in pil_loader\n    with Image.open(f) as img:\n  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/PIL/Image.py\", line 2452, in open\n    % (filename if filename else fp))\nOSError: cannot identify image file <_io.BufferedReader name='/home/gabriel/Redes Neurais/Projeto_Final_GANS/Tutorial_2/dataset/min_anime-faces/black_eyes/danbooru_2605393_76dd8fe243b4e17da1c3350b94b16044.jpg'>\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "d_labelSmooth = 0.2\n",
    "\n",
    "train_both_networks(num_epochs, dataloader, netD,netG,d_labelSmooth, outputDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
