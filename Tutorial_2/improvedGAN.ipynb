{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import StepLR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gpu_available = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-09e6b9ed5828>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "torch.optim.lr_scheduler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of some important parameters\n",
    "Dataset to be used is defined here. According to the dataset, some other hyperparameters are set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This should, in the future, be set in CLI\n",
    "chosen_dataset = 'CIFAR10'\n",
    "\n",
    "datasets = {\n",
    "    'MNIST': torchvision.datasets.MNIST,\n",
    "    'CIFAR10': torchvision.datasets.CIFAR10\n",
    "    #'FashionMNIST': torchvision.datasets.FashionMNIST\n",
    "}\n",
    "\n",
    "dataset = datasets[chosen_dataset]\n",
    "\n",
    "possible_parameters = {\n",
    "    'MNIST': {\n",
    "        'ndf': 64,\n",
    "        'ngf': 64,\n",
    "        'code_size': 50,\n",
    "        'n_channels': 1,\n",
    "    },\n",
    "    'CIFAR10': {\n",
    "        'ndf': 64,\n",
    "        'ngf': 64,\n",
    "        'code_size': 100,\n",
    "        'n_channels': 3,\n",
    "    },\n",
    "    #'FashionMNIST': {}\n",
    "}\n",
    "\n",
    "ngf = possible_parameters[chosen_dataset]['ngf']\n",
    "ndf = possible_parameters[chosen_dataset]['ndf']\n",
    "code_size = possible_parameters[chosen_dataset]['code_size']\n",
    "n_channels = possible_parameters[chosen_dataset]['n_channels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define data handling structures\n",
    "- Batch size and number of child processes are to be set by user.\n",
    "- Defines data transforms to be used in train and test phases\n",
    "- Defines dataset and dataloader dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These should, in the future, be set in CLI\n",
    "batch_size = 16\n",
    "number_processes = 4\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Scale(32),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        #transforms.ColorJitter(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Scale(32),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'train': dataset('./datasets', train=True, download=False, transform=data_transforms['train']),\n",
    "    'test': dataset('./datasets', train=False, download=False, transform=data_transforms['test'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if gpu_available:\n",
    "    n_train_samples = 1000\n",
    "    n_test_samples = 100\n",
    "    \n",
    "else:\n",
    "    n_train_samples = 500\n",
    "    n_test_samples = 100\n",
    "\n",
    "datasets['train'].train_data = datasets['train'].train_data[:n_train_samples]\n",
    "datasets['train'].train_labels = datasets['train'].train_labels[:n_train_samples]\n",
    "\n",
    "datasets['test'].test_data = datasets['test'].test_data[:n_test_samples]\n",
    "datasets['test'].test_labels = datasets['test'].test_labels[:n_test_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training dataloader: 63\n",
      "Length of test dataloader: 63\n"
     ]
    }
   ],
   "source": [
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(datasets['train'], batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=number_processes),\n",
    "    'test': torch.utils.data.DataLoader(datasets['train'], batch_size=batch_size,\n",
    "                                        shuffle=False, num_workers=number_processes),\n",
    "}\n",
    "print('Length of training dataloader:', len(dataloaders['train']))\n",
    "print('Length of test dataloader:', len(dataloaders['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network definitions\n",
    "Network hyperparameters are defined by the user or defined according to dataset choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class generator_network(nn.Module):\n",
    "    # This model is sequential and will be implemented as such for simplicity\n",
    "    def __init__(self, code_size, ngf, n_channels):\n",
    "        super().__init__()\n",
    "        self.code_size = code_size\n",
    "        self.ngf = ngf\n",
    "        self.n_channels = n_channels\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.code_size, self.ngf*8 * 4 * 4),\n",
    "            #nn.BatchNorm1d(self.ngf*8*4*4),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.deconv = nn.Sequential(\n",
    "            # 4x4 -> 8x8\n",
    "            nn.ConvTranspose2d(self.ngf*8, self.ngf*4, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(self.ngf*4),\n",
    "            nn.ReLU(),\n",
    "            # 8x8 -> 16x16\n",
    "            nn.ConvTranspose2d(self.ngf*4, self.ngf*2, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(self.ngf*2),\n",
    "            nn.ReLU(),\n",
    "            # 16x16 -> 32x32\n",
    "            nn.ConvTranspose2d(self.ngf*2, self.n_channels, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(self.n_channels),\n",
    "            # If uncommented, 32x32 -> 64x64\n",
    "            #nn.ReLU(),\n",
    "            #nn.ConvTranspose2d(self.ngf, self.n_channels, kernel_size=4, stride=2, padding=1),\n",
    "            #nn.BatchNorm2d(self.n_channels),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        input = input.view(-1, self.code_size)\n",
    "        input = self.fc(input)\n",
    "        input = input.view(-1, self.ngf*8, 4, 4)\n",
    "        output = self.deconv(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class discriminator_network(nn.Module):\n",
    "    def __init__(self, ndf, n_channels):\n",
    "        super().__init__()\n",
    "        self.ndf = ndf\n",
    "        self.n_channels = n_channels\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(self.n_channels, 96, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(96, 96, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(96, 96, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Conv2d(96, 192, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(192, 192, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(192, 192, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Conv2d(192, 192, kernel_size=3, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.n_conv_features = self._get_conv_output((3,32,32))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.n_conv_features, 192),\n",
    "            nn.Linear(192, 100),\n",
    "            nn.Linear(100, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = self.conv(input)\n",
    "        x = x.view(-1, self.n_conv_features)\n",
    "        output = self.fc(x).squeeze()\n",
    "        return output\n",
    "    \n",
    "    def _get_conv_output(self, shape):\n",
    "        bs = 1\n",
    "        input = Variable(torch.rand(bs, *shape))\n",
    "        output_feat = self.conv(input)\n",
    "        n_size = output_feat.data.view(bs, -1).size(1)\n",
    "        return n_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary function definitions\n",
    "- weights_init initializes Conv layers and BatchNorm layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.05)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.05)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network creation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generator_network (\n",
      "  (fc): Sequential (\n",
      "    (0): Linear (100 -> 8192)\n",
      "    (1): ReLU ()\n",
      "  )\n",
      "  (deconv): Sequential (\n",
      "    (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU ()\n",
      "    (3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): ReLU ()\n",
      "    (6): ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (7): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (8): Tanh ()\n",
      "  )\n",
      ") \n",
      " discriminator_network (\n",
      "  (conv): Sequential (\n",
      "    (0): Conv2d(3, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): LeakyReLU (0.01)\n",
      "    (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): LeakyReLU (0.01)\n",
      "    (6): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (8): LeakyReLU (0.01)\n",
      "    (9): Dropout (p = 0.5)\n",
      "    (10): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (12): LeakyReLU (0.01)\n",
      "    (13): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (14): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (15): LeakyReLU (0.01)\n",
      "    (16): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (17): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (18): LeakyReLU (0.01)\n",
      "    (19): Dropout (p = 0.5)\n",
      "    (20): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (21): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (22): LeakyReLU (0.01)\n",
      "  )\n",
      "  (fc): Sequential (\n",
      "    (0): Linear (1728 -> 192)\n",
      "    (1): Linear (192 -> 100)\n",
      "    (2): Linear (100 -> 1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "D = discriminator_network(ndf, n_channels)\n",
    "G = generator_network(code_size, ngf, n_channels)\n",
    "\n",
    "D.apply(weights_init)\n",
    "G.apply(weights_init)\n",
    "\n",
    "print(G, '\\n', D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining optimization parameters\n",
    "- Optimizer: Adam\n",
    "- LR: user defined, default = 0.0003 (3e-4)\n",
    "- LR decay: linear decay over the epochs, to a minimum of 0.0001 (1e-4)\n",
    "- Loss function: BCELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = torch.FloatTensor(batch_size, code_size, 32, 32)\n",
    "label = torch.FloatTensor(batch_size)\n",
    "fixed_noise = torch.FloatTensor(batch_size, code_size, 1, 1).normal_(0, 1)\n",
    "noise = torch.FloatTensor(batch_size)\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizerD = torch.optim.Adam(D.parameters(), lr=3e-4)\n",
    "optimizerG = torch.optim.Adam(G.parameters(), lr=3e-4)\n",
    "\n",
    "lin_decay = lambda epoch: np.clip(3 - epoch / 400, 1e-4, None)\n",
    "D_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizerD, lin_decay)\n",
    "G_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizerG, lin_decay)\n",
    "\n",
    "if gpu_available:\n",
    "    D.cuda()\n",
    "    G.cuda()\n",
    "    criterion.cuda()\n",
    "    input, label = input.cuda(), label.cuda()\n",
    "    fixed_noise, noise = fixed_noise.cuda(), noise.cuda()\n",
    "    \n",
    "input, label = Variable(input), Variable(label)\n",
    "fixed_noise, noise = Variable(fixed_noise), Variable(noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def save_images(netG, noise, outputDir,epoch):\n",
    "    # the first 64 samples from the mini-batch are saved.\n",
    "    fake,_ = netG(fixed_noise)\n",
    "    vutils.save_image(fake.data[0:64,:,:,:],\n",
    "            '%s/fake_samples_epoch_%03d.png' % (outputDir, epoch), nrow=8)\n",
    "\n",
    "def save_models(netG, netD, outputDir, epoch):\n",
    "    torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (outputDir, epoch))\n",
    "    torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (outputDir, epoch))\n",
    "\n",
    "\n",
    "def train_both_networks(num_epochs, dataloader, netD, netG, d_labelSmooth, outputDir,\n",
    "                        model_option =1,binary = False, epoch_interval = 1):\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            start_iter = time.time()\n",
    "            \n",
    "            \n",
    "            ############################\n",
    "            # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "            # 1A - Train the detective network in the Real Dataset\n",
    "            ###########################\n",
    "            # train with real\n",
    "            netD.zero_grad()\n",
    "            real_cpu, _ = data\n",
    "            batch_size = real_cpu.size(0)\n",
    "            input.data.resize_(real_cpu.size()).copy_(real_cpu)\n",
    "            label.data.resize_(batch_size).fill_(real_label - d_labelSmooth) # use smooth label for discriminator\n",
    "\n",
    "            output = netD(input)\n",
    "            errD_real = criterion(output, label)\n",
    "            errD_real.backward()\n",
    "            \n",
    "            #######################################################\n",
    "           \n",
    "            #######################################################\n",
    "            # 1B - Train the detective network in the False Dataset\n",
    "            #######################################################\n",
    "            \n",
    "            D_x = output.data.mean()\n",
    "            # train with fake\n",
    "            noise.data.resize_(batch_size, code_size, 1, 1)\n",
    "            if binary:\n",
    "                bernoulli_prob.resize_(noise.data.size())\n",
    "                noise.data.copy_(2*(torch.bernoulli(bernoulli_prob)-0.5))\n",
    "            else:\n",
    "                noise.data.normal_(0, 1)\n",
    "            fake = netG(noise)\n",
    "            label.data.fill_(fake_label)\n",
    "            output = netD(fake.detach()) # add \".detach()\" to avoid backprop through G\n",
    "            errD_fake = criterion(output, label)\n",
    "            errD_fake.backward() # gradients for fake/real will be accumulated\n",
    "            D_G_z1 = output.data.mean()\n",
    "            errD = errD_real + errD_fake\n",
    "            optimizerD.step() # .step() can be called once the gradients are computed\n",
    "            D_scheduler.step()\n",
    "\n",
    "            #######################################################\n",
    "\n",
    "            #######################################################\n",
    "            # (2) Update G network: maximize log(D(G(z)))\n",
    "            #  Train the faker with de output from the Detective (but don't train the Detective)\n",
    "            #############3#########################################\n",
    "            netG.zero_grad()\n",
    "            label.data.fill_(real_label) # fake labels are real for generator cost\n",
    "            output = netD(fake)\n",
    "            errG = criterion(output, label)\n",
    "            errG.backward(retain_graph=True) # True if backward through the graph for the second time()\n",
    "            D_G_z2 = output.data.mean()\n",
    "            optimizerG.step()\n",
    "            G_scheduler.step()\n",
    "\n",
    "            end_iter = time.time()\n",
    "            \n",
    "            #Print the info\n",
    "            print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f Elapsed %.2f s'\n",
    "                  % (epoch, num_epochs, i, len(dataloader),\n",
    "                     errD.data[0], errG.data[0], D_x, D_G_z1, D_G_z2, end_iter-start_iter))\n",
    "            \n",
    "            #Save a grid with the pictures from the dataset, up until 64\n",
    "            if i % 100 == 0:\n",
    "                # the first 64 samples from the mini-batch are saved.\n",
    "                vutils.save_image(real_cpu[0:64,:,:,:],\n",
    "                        '%s/real_samples.png' % outputDir, nrow=8)\n",
    "                fake = netG(fixed_noise)\n",
    "                vutils.save_image(fake.data[0:64,:,:,:],\n",
    "                        '%s/fake_samples_epoch_%03d.png' % (outputDir, epoch), nrow=8)\n",
    "        if epoch % epoch_interval == 0:\n",
    "            # do checkpointing\n",
    "            torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (outputDir, epoch))\n",
    "            torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (outputDir, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][0/63] Loss_D: nan Loss_G: nan D(x): 0.1470 D(G(z)): 0.1928 / -0.5591 Elapsed 1.19 s\n",
      "[0/25][1/63] Loss_D: nan Loss_G: nan D(x): -0.5474 D(G(z)): -0.5591 / -1.7376 Elapsed 0.33 s\n",
      "[0/25][2/63] Loss_D: nan Loss_G: nan D(x): -1.7890 D(G(z)): -1.7362 / -2.9420 Elapsed 0.32 s\n",
      "[0/25][3/63] Loss_D: nan Loss_G: nan D(x): -2.8662 D(G(z)): -3.0227 / -4.2261 Elapsed 0.30 s\n",
      "[0/25][4/63] Loss_D: nan Loss_G: nan D(x): -3.9385 D(G(z)): -4.2271 / -5.2618 Elapsed 0.32 s\n",
      "[0/25][5/63] Loss_D: nan Loss_G: nan D(x): -5.2030 D(G(z)): -5.1704 / -6.3691 Elapsed 0.32 s\n",
      "[0/25][6/63] Loss_D: nan Loss_G: nan D(x): -6.3220 D(G(z)): -6.4502 / -7.6290 Elapsed 0.32 s\n",
      "[0/25][7/63] Loss_D: nan Loss_G: nan D(x): -7.2405 D(G(z)): -7.5437 / -8.7960 Elapsed 0.35 s\n",
      "[0/25][8/63] Loss_D: nan Loss_G: nan D(x): -8.3275 D(G(z)): -8.7876 / -9.8772 Elapsed 0.32 s\n",
      "[0/25][9/63] Loss_D: nan Loss_G: nan D(x): -9.5952 D(G(z)): -10.0143 / -11.0778 Elapsed 0.32 s\n",
      "[0/25][10/63] Loss_D: nan Loss_G: nan D(x): -10.8321 D(G(z)): -10.9150 / -12.1689 Elapsed 0.33 s\n",
      "[0/25][11/63] Loss_D: nan Loss_G: nan D(x): -11.8607 D(G(z)): -12.1172 / -13.4583 Elapsed 0.32 s\n",
      "[0/25][12/63] Loss_D: nan Loss_G: nan D(x): -13.0167 D(G(z)): -13.2908 / -14.4895 Elapsed 0.31 s\n",
      "[0/25][13/63] Loss_D: nan Loss_G: nan D(x): -13.9237 D(G(z)): -14.5801 / -15.7981 Elapsed 0.33 s\n",
      "[0/25][14/63] Loss_D: nan Loss_G: nan D(x): -15.1767 D(G(z)): -15.7357 / -16.7520 Elapsed 0.32 s\n",
      "[0/25][15/63] Loss_D: nan Loss_G: nan D(x): -16.4872 D(G(z)): -16.8219 / -18.0101 Elapsed 0.32 s\n",
      "[0/25][16/63] Loss_D: nan Loss_G: nan D(x): -17.3118 D(G(z)): -17.9744 / -19.2503 Elapsed 0.32 s\n",
      "[0/25][17/63] Loss_D: nan Loss_G: nan D(x): -18.4913 D(G(z)): -19.2731 / -20.3278 Elapsed 0.32 s\n",
      "[0/25][18/63] Loss_D: nan Loss_G: nan D(x): -19.5129 D(G(z)): -20.1948 / -21.4988 Elapsed 0.33 s\n",
      "[0/25][19/63] Loss_D: nan Loss_G: nan D(x): -20.8894 D(G(z)): -21.5336 / -23.0360 Elapsed 0.32 s\n",
      "[0/25][20/63] Loss_D: nan Loss_G: nan D(x): -21.5915 D(G(z)): -22.9110 / -24.0546 Elapsed 0.32 s\n",
      "[0/25][21/63] Loss_D: nan Loss_G: nan D(x): -22.7878 D(G(z)): -23.9780 / -25.3684 Elapsed 0.30 s\n",
      "[0/25][22/63] Loss_D: nan Loss_G: nan D(x): -24.0071 D(G(z)): -25.1338 / -26.4868 Elapsed 0.31 s\n",
      "[0/25][23/63] Loss_D: nan Loss_G: nan D(x): -25.7499 D(G(z)): -26.6635 / -27.5317 Elapsed 0.30 s\n",
      "[0/25][24/63] Loss_D: nan Loss_G: nan D(x): -26.3511 D(G(z)): -27.8734 / -28.9505 Elapsed 0.32 s\n",
      "[0/25][25/63] Loss_D: nan Loss_G: nan D(x): -27.6077 D(G(z)): -28.8681 / -30.2217 Elapsed 0.32 s\n",
      "[0/25][26/63] Loss_D: nan Loss_G: nan D(x): -29.1531 D(G(z)): -30.1572 / -31.4699 Elapsed 0.34 s\n",
      "[0/25][27/63] Loss_D: nan Loss_G: nan D(x): -30.7225 D(G(z)): -31.4968 / -32.5964 Elapsed 0.32 s\n",
      "[0/25][28/63] Loss_D: nan Loss_G: nan D(x): -31.6191 D(G(z)): -33.1036 / -33.9454 Elapsed 0.33 s\n",
      "[0/25][29/63] Loss_D: nan Loss_G: nan D(x): -32.5725 D(G(z)): -34.2351 / -35.2827 Elapsed 0.33 s\n",
      "[0/25][30/63] Loss_D: nan Loss_G: nan D(x): -33.9844 D(G(z)): -35.5035 / -36.8754 Elapsed 0.32 s\n",
      "[0/25][31/63] Loss_D: nan Loss_G: nan D(x): -35.2544 D(G(z)): -36.5342 / -38.0831 Elapsed 0.32 s\n",
      "[0/25][32/63] Loss_D: nan Loss_G: nan D(x): -35.5239 D(G(z)): -37.9219 / -39.1053 Elapsed 0.33 s\n",
      "[0/25][33/63] Loss_D: nan Loss_G: nan D(x): -37.3557 D(G(z)): -39.2253 / -40.7402 Elapsed 0.32 s\n",
      "[0/25][34/63] Loss_D: nan Loss_G: nan D(x): -39.0588 D(G(z)): -40.8524 / -42.5612 Elapsed 0.30 s\n",
      "[0/25][35/63] Loss_D: nan Loss_G: nan D(x): -40.7373 D(G(z)): -42.2639 / -43.5167 Elapsed 0.32 s\n",
      "[0/25][36/63] Loss_D: nan Loss_G: nan D(x): -41.6825 D(G(z)): -43.6532 / -44.7750 Elapsed 0.33 s\n",
      "[0/25][37/63] Loss_D: nan Loss_G: nan D(x): -42.3433 D(G(z)): -45.2915 / -46.6402 Elapsed 0.32 s\n",
      "[0/25][38/63] Loss_D: nan Loss_G: nan D(x): -44.6192 D(G(z)): -46.5913 / -48.4739 Elapsed 0.32 s\n",
      "[0/25][39/63] Loss_D: nan Loss_G: nan D(x): -44.1068 D(G(z)): -48.1779 / -49.5392 Elapsed 0.32 s\n",
      "[0/25][40/63] Loss_D: nan Loss_G: nan D(x): -47.2050 D(G(z)): -49.8658 / -51.3685 Elapsed 0.32 s\n",
      "[0/25][41/63] Loss_D: nan Loss_G: nan D(x): -48.6095 D(G(z)): -51.1301 / -52.7835 Elapsed 0.33 s\n",
      "[0/25][42/63] Loss_D: nan Loss_G: nan D(x): -49.8832 D(G(z)): -52.8657 / -54.2747 Elapsed 0.32 s\n",
      "[0/25][43/63] Loss_D: nan Loss_G: nan D(x): -51.5413 D(G(z)): -54.7403 / -55.5729 Elapsed 0.32 s\n",
      "[0/25][44/63] Loss_D: nan Loss_G: nan D(x): -52.9944 D(G(z)): -56.0477 / -57.9940 Elapsed 0.30 s\n",
      "[0/25][45/63] Loss_D: nan Loss_G: nan D(x): -54.2662 D(G(z)): -57.9610 / -59.3296 Elapsed 0.33 s\n",
      "[0/25][46/63] Loss_D: nan Loss_G: nan D(x): -54.9161 D(G(z)): -59.0266 / -61.0948 Elapsed 0.32 s\n",
      "[0/25][47/63] Loss_D: nan Loss_G: nan D(x): -58.2067 D(G(z)): -61.1053 / -63.8072 Elapsed 0.32 s\n",
      "[0/25][48/63] Loss_D: nan Loss_G: nan D(x): -59.9124 D(G(z)): -63.2203 / -65.0860 Elapsed 0.30 s\n",
      "[0/25][49/63] Loss_D: nan Loss_G: nan D(x): -61.4799 D(G(z)): -64.9819 / -67.2528 Elapsed 0.30 s\n",
      "[0/25][50/63] Loss_D: nan Loss_G: nan D(x): -62.6641 D(G(z)): -66.3915 / -68.4947 Elapsed 0.32 s\n",
      "[0/25][51/63] Loss_D: nan Loss_G: nan D(x): -64.3743 D(G(z)): -68.3420 / -70.3251 Elapsed 0.30 s\n",
      "[0/25][52/63] Loss_D: nan Loss_G: nan D(x): -66.3073 D(G(z)): -70.3008 / -71.9486 Elapsed 0.30 s\n",
      "[0/25][53/63] Loss_D: nan Loss_G: nan D(x): -67.6268 D(G(z)): -72.1953 / -73.5026 Elapsed 0.32 s\n",
      "[0/25][54/63] Loss_D: nan Loss_G: nan D(x): -69.5908 D(G(z)): -74.3550 / -77.2324 Elapsed 0.32 s\n",
      "[0/25][55/63] Loss_D: nan Loss_G: nan D(x): -71.8719 D(G(z)): -77.0637 / -78.8875 Elapsed 0.33 s\n",
      "[0/25][56/63] Loss_D: nan Loss_G: nan D(x): -73.5849 D(G(z)): -79.0218 / -80.7818 Elapsed 0.30 s\n",
      "[0/25][57/63] Loss_D: nan Loss_G: nan D(x): -75.9052 D(G(z)): -80.4291 / -82.8990 Elapsed 0.30 s\n",
      "[0/25][58/63] Loss_D: nan Loss_G: nan D(x): -77.2930 D(G(z)): -82.5195 / -85.0821 Elapsed 0.30 s\n",
      "[0/25][59/63] Loss_D: nan Loss_G: nan D(x): -78.9277 D(G(z)): -85.0674 / -87.5610 Elapsed 0.30 s\n",
      "[0/25][60/63] Loss_D: nan Loss_G: nan D(x): -81.5291 D(G(z)): -88.3444 / -89.7277 Elapsed 0.32 s\n",
      "[0/25][61/63] Loss_D: nan Loss_G: nan D(x): -82.5643 D(G(z)): -89.7616 / -91.7980 Elapsed 0.30 s\n",
      "[0/25][62/63] Loss_D: nan Loss_G: nan D(x): -85.2275 D(G(z)): -91.6250 / -95.2595 Elapsed 0.17 s\n",
      "[1/25][0/63] Loss_D: nan Loss_G: nan D(x): -87.6739 D(G(z)): -94.3296 / -97.1083 Elapsed 0.32 s\n",
      "[1/25][1/63] Loss_D: nan Loss_G: nan D(x): -89.6287 D(G(z)): -96.9190 / -98.9853 Elapsed 0.30 s\n",
      "[1/25][2/63] Loss_D: nan Loss_G: nan D(x): -90.9038 D(G(z)): -99.3180 / -102.3700 Elapsed 0.30 s\n",
      "[1/25][3/63] Loss_D: nan Loss_G: nan D(x): -93.2092 D(G(z)): -101.3333 / -105.2686 Elapsed 0.32 s\n",
      "[1/25][4/63] Loss_D: nan Loss_G: nan D(x): -97.0095 D(G(z)): -103.4633 / -107.3251 Elapsed 0.30 s\n",
      "[1/25][5/63] Loss_D: nan Loss_G: nan D(x): -98.5149 D(G(z)): -106.5620 / -110.1433 Elapsed 0.32 s\n",
      "[1/25][6/63] Loss_D: nan Loss_G: nan D(x): -102.5906 D(G(z)): -109.8300 / -112.1756 Elapsed 0.30 s\n",
      "[1/25][7/63] Loss_D: nan Loss_G: nan D(x): -103.1089 D(G(z)): -111.7629 / -115.4140 Elapsed 0.30 s\n",
      "[1/25][8/63] Loss_D: nan Loss_G: nan D(x): -106.3815 D(G(z)): -116.3562 / -118.2081 Elapsed 0.32 s\n",
      "[1/25][9/63] Loss_D: nan Loss_G: nan D(x): -107.8583 D(G(z)): -120.1439 / -121.0325 Elapsed 0.32 s\n",
      "[1/25][10/63] Loss_D: nan Loss_G: nan D(x): -110.3351 D(G(z)): -121.1597 / -126.1146 Elapsed 0.32 s\n",
      "[1/25][11/63] Loss_D: nan Loss_G: nan D(x): -115.2501 D(G(z)): -124.6351 / -126.9422 Elapsed 0.30 s\n",
      "[1/25][12/63] Loss_D: nan Loss_G: nan D(x): -116.3670 D(G(z)): -127.2988 / -130.7684 Elapsed 0.32 s\n",
      "[1/25][13/63] Loss_D: nan Loss_G: nan D(x): -120.0309 D(G(z)): -131.6068 / -134.5226 Elapsed 0.33 s\n",
      "[1/25][14/63] Loss_D: nan Loss_G: nan D(x): -120.9300 D(G(z)): -134.7809 / -137.6548 Elapsed 0.32 s\n",
      "[1/25][15/63] Loss_D: nan Loss_G: nan D(x): -125.6183 D(G(z)): -136.2380 / -140.1257 Elapsed 0.30 s\n",
      "[1/25][16/63] Loss_D: nan Loss_G: nan D(x): -128.5087 D(G(z)): -140.8961 / -144.8162 Elapsed 0.30 s\n",
      "[1/25][17/63] Loss_D: nan Loss_G: nan D(x): -131.1481 D(G(z)): -145.2747 / -147.5279 Elapsed 0.30 s\n",
      "[1/25][18/63] Loss_D: nan Loss_G: nan D(x): -133.7964 D(G(z)): -147.3490 / -151.2506 Elapsed 0.30 s\n",
      "[1/25][19/63] Loss_D: nan Loss_G: nan D(x): -135.7865 D(G(z)): -151.4956 / -154.6216 Elapsed 0.30 s\n",
      "[1/25][20/63] Loss_D: nan Loss_G: nan D(x): -139.0548 D(G(z)): -154.6241 / -158.3903 Elapsed 0.32 s\n",
      "[1/25][21/63] Loss_D: nan Loss_G: nan D(x): -141.7517 D(G(z)): -159.4870 / -162.9561 Elapsed 0.32 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25][22/63] Loss_D: nan Loss_G: nan D(x): -147.0091 D(G(z)): -162.1294 / -164.9738 Elapsed 0.30 s\n",
      "[1/25][23/63] Loss_D: nan Loss_G: nan D(x): -147.8991 D(G(z)): -167.0981 / -169.7894 Elapsed 0.32 s\n",
      "[1/25][24/63] Loss_D: nan Loss_G: nan D(x): -150.1258 D(G(z)): -171.6676 / -174.7039 Elapsed 0.30 s\n",
      "[1/25][25/63] Loss_D: nan Loss_G: nan D(x): -154.6290 D(G(z)): -173.5522 / -178.0585 Elapsed 0.30 s\n",
      "[1/25][26/63] Loss_D: nan Loss_G: nan D(x): -158.4959 D(G(z)): -176.4958 / -179.9573 Elapsed 0.32 s\n",
      "[1/25][27/63] Loss_D: nan Loss_G: nan D(x): -163.7581 D(G(z)): -181.6717 / -184.4836 Elapsed 0.32 s\n",
      "[1/25][28/63] Loss_D: nan Loss_G: nan D(x): -165.5700 D(G(z)): -185.1011 / -191.1291 Elapsed 0.33 s\n",
      "[1/25][29/63] Loss_D: nan Loss_G: nan D(x): -168.2978 D(G(z)): -189.9021 / -193.7545 Elapsed 0.32 s\n",
      "[1/25][30/63] Loss_D: nan Loss_G: nan D(x): -172.5147 D(G(z)): -194.8741 / -199.3433 Elapsed 0.32 s\n",
      "[1/25][31/63] Loss_D: nan Loss_G: nan D(x): -174.7050 D(G(z)): -199.8458 / -202.3457 Elapsed 0.32 s\n",
      "[1/25][32/63] Loss_D: nan Loss_G: nan D(x): -179.4531 D(G(z)): -202.4288 / -207.6733 Elapsed 0.32 s\n",
      "[1/25][33/63] Loss_D: nan Loss_G: nan D(x): -182.7000 D(G(z)): -207.7679 / -212.6570 Elapsed 0.32 s\n",
      "[1/25][34/63] Loss_D: nan Loss_G: nan D(x): -189.1493 D(G(z)): -213.2185 / -216.3903 Elapsed 0.30 s\n",
      "[1/25][35/63] Loss_D: nan Loss_G: nan D(x): -191.5834 D(G(z)): -217.0879 / -222.8592 Elapsed 0.30 s\n",
      "[1/25][36/63] Loss_D: nan Loss_G: nan D(x): -196.1977 D(G(z)): -223.5760 / -225.0871 Elapsed 0.32 s\n",
      "[1/25][37/63] Loss_D: nan Loss_G: nan D(x): -202.8169 D(G(z)): -227.4369 / -231.6872 Elapsed 0.32 s\n",
      "[1/25][38/63] Loss_D: nan Loss_G: nan D(x): -201.6792 D(G(z)): -229.5574 / -235.0127 Elapsed 0.32 s\n",
      "[1/25][39/63] Loss_D: nan Loss_G: nan D(x): -205.5915 D(G(z)): -236.0481 / -241.0573 Elapsed 0.32 s\n",
      "[1/25][40/63] Loss_D: nan Loss_G: nan D(x): -209.0724 D(G(z)): -240.8994 / -245.1196 Elapsed 0.30 s\n",
      "[1/25][41/63] Loss_D: nan Loss_G: nan D(x): -216.6476 D(G(z)): -248.0126 / -251.8546 Elapsed 0.30 s\n",
      "[1/25][42/63] Loss_D: nan Loss_G: nan D(x): -220.1103 D(G(z)): -252.7569 / -257.5548 Elapsed 0.32 s\n",
      "[1/25][43/63] Loss_D: nan Loss_G: nan D(x): -224.2186 D(G(z)): -258.1749 / -262.6571 Elapsed 0.30 s\n",
      "[1/25][44/63] Loss_D: nan Loss_G: nan D(x): -228.5860 D(G(z)): -265.2352 / -268.3559 Elapsed 0.28 s\n",
      "[1/25][45/63] Loss_D: nan Loss_G: nan D(x): -233.9379 D(G(z)): -270.2777 / -274.0183 Elapsed 0.32 s\n",
      "[1/25][46/63] Loss_D: nan Loss_G: nan D(x): -236.0952 D(G(z)): -273.2448 / -279.2207 Elapsed 0.32 s\n",
      "[1/25][47/63] Loss_D: nan Loss_G: nan D(x): -245.2583 D(G(z)): -279.2616 / -285.1667 Elapsed 0.30 s\n",
      "[1/25][48/63] Loss_D: nan Loss_G: nan D(x): -247.2861 D(G(z)): -285.5438 / -291.6537 Elapsed 0.30 s\n",
      "[1/25][49/63] Loss_D: nan Loss_G: nan D(x): -252.1382 D(G(z)): -291.8541 / -296.9680 Elapsed 0.30 s\n",
      "[1/25][50/63] Loss_D: nan Loss_G: nan D(x): -253.7515 D(G(z)): -298.7590 / -299.6573 Elapsed 0.30 s\n",
      "[1/25][51/63] Loss_D: nan Loss_G: nan D(x): -261.4012 D(G(z)): -306.1062 / -310.0206 Elapsed 0.32 s\n",
      "[1/25][52/63] Loss_D: nan Loss_G: nan D(x): -267.0659 D(G(z)): -307.4796 / -315.4420 Elapsed 0.32 s\n",
      "[1/25][53/63] Loss_D: nan Loss_G: nan D(x): -273.1166 D(G(z)): -315.9255 / -322.7352 Elapsed 0.30 s\n",
      "[1/25][54/63] Loss_D: nan Loss_G: nan D(x): -273.6276 D(G(z)): -323.0975 / -324.4275 Elapsed 0.30 s\n",
      "[1/25][55/63] Loss_D: nan Loss_G: nan D(x): -282.1047 D(G(z)): -328.9923 / -336.6772 Elapsed 0.32 s\n",
      "[1/25][56/63] Loss_D: nan Loss_G: nan D(x): -285.9809 D(G(z)): -333.8748 / -341.8551 Elapsed 0.30 s\n",
      "[1/25][57/63] Loss_D: nan Loss_G: nan D(x): -292.2596 D(G(z)): -340.5339 / -352.3217 Elapsed 0.30 s\n",
      "[1/25][58/63] Loss_D: nan Loss_G: nan D(x): -300.3321 D(G(z)): -346.3827 / -355.4729 Elapsed 0.30 s\n",
      "[1/25][59/63] Loss_D: nan Loss_G: nan D(x): -304.1379 D(G(z)): -359.1306 / -360.7734 Elapsed 0.32 s\n",
      "[1/25][60/63] Loss_D: nan Loss_G: nan D(x): -308.9911 D(G(z)): -364.1555 / -368.9706 Elapsed 0.32 s\n",
      "[1/25][61/63] Loss_D: nan Loss_G: nan D(x): -313.7175 D(G(z)): -367.4682 / -378.1804 Elapsed 0.32 s\n",
      "[1/25][62/63] Loss_D: nan Loss_G: nan D(x): -316.8024 D(G(z)): -378.1721 / -380.7707 Elapsed 0.17 s\n",
      "[2/25][0/63] Loss_D: nan Loss_G: nan D(x): -326.9815 D(G(z)): -381.6507 / -387.2005 Elapsed 0.32 s\n",
      "[2/25][1/63] Loss_D: nan Loss_G: nan D(x): -329.8623 D(G(z)): -390.9285 / -399.6947 Elapsed 0.32 s\n",
      "[2/25][2/63] Loss_D: nan Loss_G: nan D(x): -339.7280 D(G(z)): -396.5086 / -404.5349 Elapsed 0.32 s\n",
      "[2/25][3/63] Loss_D: nan Loss_G: nan D(x): -341.3566 D(G(z)): -403.9778 / -409.7420 Elapsed 0.32 s\n",
      "[2/25][4/63] Loss_D: nan Loss_G: nan D(x): -349.8712 D(G(z)): -411.2509 / -419.5084 Elapsed 0.32 s\n",
      "[2/25][5/63] Loss_D: nan Loss_G: nan D(x): -355.4433 D(G(z)): -417.1163 / -427.9568 Elapsed 0.32 s\n",
      "[2/25][6/63] Loss_D: nan Loss_G: nan D(x): -365.6624 D(G(z)): -426.4908 / -432.3852 Elapsed 0.32 s\n",
      "[2/25][7/63] Loss_D: nan Loss_G: nan D(x): -368.2649 D(G(z)): -433.2897 / -441.5936 Elapsed 0.30 s\n",
      "[2/25][8/63] Loss_D: nan Loss_G: nan D(x): -380.3561 D(G(z)): -439.3454 / -449.2975 Elapsed 0.32 s\n",
      "[2/25][9/63] Loss_D: nan Loss_G: nan D(x): -377.8564 D(G(z)): -449.8290 / -458.6460 Elapsed 0.31 s\n",
      "[2/25][10/63] Loss_D: nan Loss_G: nan D(x): -388.4665 D(G(z)): -455.3149 / -465.4524 Elapsed 0.32 s\n",
      "[2/25][11/63] Loss_D: nan Loss_G: nan D(x): -395.1593 D(G(z)): -467.3151 / -475.9208 Elapsed 0.32 s\n",
      "[2/25][12/63] Loss_D: nan Loss_G: nan D(x): -400.6606 D(G(z)): -474.3343 / -484.1578 Elapsed 0.32 s\n",
      "[2/25][13/63] Loss_D: nan Loss_G: nan D(x): -405.1620 D(G(z)): -481.4026 / -492.3229 Elapsed 0.30 s\n",
      "[2/25][14/63] Loss_D: nan Loss_G: nan D(x): -415.7367 D(G(z)): -487.9110 / -500.6964 Elapsed 0.32 s\n",
      "[2/25][15/63] Loss_D: nan Loss_G: nan D(x): -424.6410 D(G(z)): -496.6242 / -508.5918 Elapsed 0.30 s\n",
      "[2/25][16/63] Loss_D: nan Loss_G: nan D(x): -433.1797 D(G(z)): -507.9930 / -513.0717 Elapsed 0.32 s\n",
      "[2/25][17/63] Loss_D: nan Loss_G: nan D(x): -432.3996 D(G(z)): -516.3986 / -524.9114 Elapsed 0.32 s\n",
      "[2/25][18/63] Loss_D: nan Loss_G: nan D(x): -449.2401 D(G(z)): -528.0233 / -533.2703 Elapsed 0.32 s\n",
      "[2/25][19/63] Loss_D: nan Loss_G: nan D(x): -454.9927 D(G(z)): -537.4761 / -545.8109 Elapsed 0.30 s\n",
      "[2/25][20/63] Loss_D: nan Loss_G: nan D(x): -462.4267 D(G(z)): -543.0854 / -554.6582 Elapsed 0.30 s\n",
      "[2/25][21/63] Loss_D: nan Loss_G: nan D(x): -461.7157 D(G(z)): -551.9915 / -559.3296 Elapsed 0.30 s\n",
      "[2/25][22/63] Loss_D: nan Loss_G: nan D(x): -475.1090 D(G(z)): -563.0809 / -569.6813 Elapsed 0.32 s\n",
      "[2/25][23/63] Loss_D: nan Loss_G: nan D(x): -487.8007 D(G(z)): -573.4988 / -584.7797 Elapsed 0.30 s\n",
      "[2/25][24/63] Loss_D: nan Loss_G: nan D(x): -490.0105 D(G(z)): -578.8575 / -586.8200 Elapsed 0.30 s\n",
      "[2/25][25/63] Loss_D: nan Loss_G: nan D(x): -503.2876 D(G(z)): -592.2171 / -599.1157 Elapsed 0.30 s\n",
      "[2/25][26/63] Loss_D: nan Loss_G: nan D(x): -500.8647 D(G(z)): -599.6041 / -611.8360 Elapsed 0.30 s\n",
      "[2/25][27/63] Loss_D: nan Loss_G: nan D(x): -513.0146 D(G(z)): -611.7670 / -617.3456 Elapsed 0.32 s\n",
      "[2/25][28/63] Loss_D: nan Loss_G: nan D(x): -514.2418 D(G(z)): -614.7355 / -627.6252 Elapsed 0.32 s\n",
      "[2/25][29/63] Loss_D: nan Loss_G: nan D(x): -527.1411 D(G(z)): -629.1117 / -634.1442 Elapsed 0.32 s\n",
      "[2/25][30/63] Loss_D: nan Loss_G: nan D(x): -543.8038 D(G(z)): -628.8799 / -648.7442 Elapsed 0.32 s\n",
      "[2/25][31/63] Loss_D: nan Loss_G: nan D(x): -547.5447 D(G(z)): -645.2483 / -658.7193 Elapsed 0.32 s\n",
      "[2/25][32/63] Loss_D: nan Loss_G: nan D(x): -547.7250 D(G(z)): -658.9111 / -666.9167 Elapsed 0.30 s\n",
      "[2/25][33/63] Loss_D: nan Loss_G: nan D(x): -563.0163 D(G(z)): -671.0197 / -676.2801 Elapsed 0.32 s\n",
      "[2/25][34/63] Loss_D: nan Loss_G: nan D(x): -564.0619 D(G(z)): -679.9277 / -680.7715 Elapsed 0.32 s\n",
      "[2/25][35/63] Loss_D: nan Loss_G: nan D(x): -572.6072 D(G(z)): -689.3137 / -696.9205 Elapsed 0.32 s\n",
      "[2/25][36/63] Loss_D: nan Loss_G: nan D(x): -580.3101 D(G(z)): -700.5650 / -710.1617 Elapsed 0.32 s\n",
      "[2/25][37/63] Loss_D: nan Loss_G: nan D(x): -590.4031 D(G(z)): -707.3325 / -718.3929 Elapsed 0.32 s\n",
      "[2/25][38/63] Loss_D: nan Loss_G: nan D(x): -605.6559 D(G(z)): -719.6751 / -729.9947 Elapsed 0.32 s\n",
      "[2/25][39/63] Loss_D: nan Loss_G: nan D(x): -614.6962 D(G(z)): -733.1089 / -738.9245 Elapsed 0.32 s\n",
      "[2/25][40/63] Loss_D: nan Loss_G: nan D(x): -618.5500 D(G(z)): -733.8435 / -752.2211 Elapsed 0.32 s\n",
      "[2/25][41/63] Loss_D: nan Loss_G: nan D(x): -632.5262 D(G(z)): -756.0530 / -765.1258 Elapsed 0.32 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25][42/63] Loss_D: nan Loss_G: nan D(x): -643.7786 D(G(z)): -764.4562 / -774.8572 Elapsed 0.32 s\n",
      "[2/25][43/63] Loss_D: nan Loss_G: nan D(x): -642.4745 D(G(z)): -769.8682 / -790.9824 Elapsed 0.30 s\n",
      "[2/25][44/63] Loss_D: nan Loss_G: nan D(x): -661.8277 D(G(z)): -778.4151 / -798.8011 Elapsed 0.30 s\n",
      "[2/25][45/63] Loss_D: nan Loss_G: nan D(x): -664.7339 D(G(z)): -805.3428 / -812.1306 Elapsed 0.32 s\n",
      "[2/25][46/63] Loss_D: nan Loss_G: nan D(x): -677.9161 D(G(z)): -806.9878 / -817.5206 Elapsed 0.30 s\n",
      "[2/25][47/63] Loss_D: nan Loss_G: nan D(x): -682.8476 D(G(z)): -819.3083 / -828.3215 Elapsed 0.30 s\n",
      "[2/25][48/63] Loss_D: nan Loss_G: nan D(x): -703.7076 D(G(z)): -831.2719 / -839.0585 Elapsed 0.30 s\n",
      "[2/25][49/63] Loss_D: nan Loss_G: nan D(x): -713.7194 D(G(z)): -835.5396 / -854.3846 Elapsed 0.30 s\n",
      "[2/25][50/63] Loss_D: nan Loss_G: nan D(x): -719.4264 D(G(z)): -857.7681 / -866.6225 Elapsed 0.31 s\n",
      "[2/25][51/63] Loss_D: nan Loss_G: nan D(x): -732.3589 D(G(z)): -869.3672 / -879.6365 Elapsed 0.32 s\n",
      "[2/25][52/63] Loss_D: nan Loss_G: nan D(x): -743.0401 D(G(z)): -879.6099 / -885.2338 Elapsed 0.30 s\n",
      "[2/25][53/63] Loss_D: nan Loss_G: nan D(x): -751.1353 D(G(z)): -890.3300 / -894.5422 Elapsed 0.33 s\n",
      "[2/25][54/63] Loss_D: nan Loss_G: nan D(x): -757.6564 D(G(z)): -899.4420 / -913.6607 Elapsed 0.32 s\n",
      "[2/25][55/63] Loss_D: nan Loss_G: nan D(x): -771.5726 D(G(z)): -910.2505 / -928.1796 Elapsed 0.32 s\n",
      "[2/25][56/63] Loss_D: nan Loss_G: nan D(x): -776.4160 D(G(z)): -925.3435 / -933.7028 Elapsed 0.32 s\n",
      "[2/25][57/63] Loss_D: nan Loss_G: nan D(x): -798.6053 D(G(z)): -941.4551 / -956.8915 Elapsed 0.30 s\n",
      "[2/25][58/63] Loss_D: nan Loss_G: nan D(x): -801.2501 D(G(z)): -953.9376 / -966.0638 Elapsed 0.30 s\n",
      "[2/25][59/63] Loss_D: nan Loss_G: nan D(x): -797.1189 D(G(z)): -964.4979 / -976.8590 Elapsed 0.32 s\n",
      "[2/25][60/63] Loss_D: nan Loss_G: nan D(x): -819.2550 D(G(z)): -978.5560 / -987.8118 Elapsed 0.30 s\n",
      "[2/25][61/63] Loss_D: nan Loss_G: nan D(x): -839.2390 D(G(z)): -991.6278 / -1000.9498 Elapsed 0.32 s\n",
      "[2/25][62/63] Loss_D: nan Loss_G: nan D(x): -843.9391 D(G(z)): -1008.2488 / -1007.2438 Elapsed 0.16 s\n",
      "[3/25][0/63] Loss_D: nan Loss_G: nan D(x): -854.0494 D(G(z)): -1015.6610 / -1028.7343 Elapsed 0.32 s\n",
      "[3/25][1/63] Loss_D: nan Loss_G: nan D(x): -868.3292 D(G(z)): -1029.3385 / -1035.6656 Elapsed 0.33 s\n",
      "[3/25][2/63] Loss_D: nan Loss_G: nan D(x): -872.4622 D(G(z)): -1040.6107 / -1054.2180 Elapsed 0.30 s\n",
      "[3/25][3/63] Loss_D: nan Loss_G: nan D(x): -895.5580 D(G(z)): -1052.4062 / -1071.9806 Elapsed 0.32 s\n",
      "[3/25][4/63] Loss_D: nan Loss_G: nan D(x): -896.8619 D(G(z)): -1063.7526 / -1085.4626 Elapsed 0.32 s\n",
      "[3/25][5/63] Loss_D: nan Loss_G: nan D(x): -903.1981 D(G(z)): -1079.6560 / -1092.1948 Elapsed 0.30 s\n",
      "[3/25][6/63] Loss_D: nan Loss_G: nan D(x): -928.3539 D(G(z)): -1095.4232 / -1105.7229 Elapsed 0.32 s\n",
      "[3/25][7/63] Loss_D: nan Loss_G: nan D(x): -929.0599 D(G(z)): -1098.9572 / -1123.4761 Elapsed 0.32 s\n",
      "[3/25][8/63] Loss_D: nan Loss_G: nan D(x): -951.6506 D(G(z)): -1118.9006 / -1134.8578 Elapsed 0.32 s\n",
      "[3/25][9/63] Loss_D: nan Loss_G: nan D(x): -957.7026 D(G(z)): -1137.3821 / -1148.5483 Elapsed 0.32 s\n",
      "[3/25][10/63] Loss_D: nan Loss_G: nan D(x): -975.8546 D(G(z)): -1141.8628 / -1165.7416 Elapsed 0.30 s\n",
      "[3/25][11/63] Loss_D: nan Loss_G: nan D(x): -984.9016 D(G(z)): -1157.6075 / -1180.0529 Elapsed 0.32 s\n",
      "[3/25][12/63] Loss_D: nan Loss_G: nan D(x): -997.3609 D(G(z)): -1179.9841 / -1196.6254 Elapsed 0.33 s\n",
      "[3/25][13/63] Loss_D: nan Loss_G: nan D(x): -1007.6755 D(G(z)): -1186.2828 / -1205.2670 Elapsed 0.32 s\n",
      "[3/25][14/63] Loss_D: nan Loss_G: nan D(x): -1018.7236 D(G(z)): -1203.4259 / -1218.4855 Elapsed 0.32 s\n",
      "[3/25][15/63] Loss_D: nan Loss_G: nan D(x): -1024.2531 D(G(z)): -1227.5591 / -1239.7106 Elapsed 0.30 s\n",
      "[3/25][16/63] Loss_D: nan Loss_G: nan D(x): -1039.1667 D(G(z)): -1234.6478 / -1248.2273 Elapsed 0.32 s\n",
      "[3/25][17/63] Loss_D: nan Loss_G: nan D(x): -1066.7606 D(G(z)): -1247.6918 / -1260.9595 Elapsed 0.31 s\n",
      "[3/25][18/63] Loss_D: nan Loss_G: nan D(x): -1061.2245 D(G(z)): -1258.5239 / -1272.7369 Elapsed 0.28 s\n",
      "[3/25][19/63] Loss_D: nan Loss_G: nan D(x): -1087.4667 D(G(z)): -1280.1819 / -1298.3671 Elapsed 0.30 s\n",
      "[3/25][20/63] Loss_D: nan Loss_G: nan D(x): -1082.7632 D(G(z)): -1293.3557 / -1314.9504 Elapsed 0.30 s\n",
      "[3/25][21/63] Loss_D: nan Loss_G: nan D(x): -1109.6852 D(G(z)): -1309.4005 / -1313.1276 Elapsed 0.30 s\n",
      "[3/25][22/63] Loss_D: nan Loss_G: nan D(x): -1121.8499 D(G(z)): -1328.3599 / -1336.8085 Elapsed 0.33 s\n",
      "[3/25][23/63] Loss_D: nan Loss_G: nan D(x): -1146.4780 D(G(z)): -1336.5883 / -1348.2386 Elapsed 0.30 s\n",
      "[3/25][24/63] Loss_D: nan Loss_G: nan D(x): -1155.7893 D(G(z)): -1351.4690 / -1371.7660 Elapsed 0.32 s\n",
      "[3/25][25/63] Loss_D: nan Loss_G: nan D(x): -1170.2811 D(G(z)): -1380.2621 / -1379.5684 Elapsed 0.30 s\n",
      "[3/25][26/63] Loss_D: nan Loss_G: nan D(x): -1169.3979 D(G(z)): -1390.1125 / -1401.9919 Elapsed 0.32 s\n",
      "[3/25][27/63] Loss_D: nan Loss_G: nan D(x): -1182.9374 D(G(z)): -1402.7496 / -1410.2427 Elapsed 0.32 s\n",
      "[3/25][28/63] Loss_D: nan Loss_G: nan D(x): -1211.6940 D(G(z)): -1424.2397 / -1432.1534 Elapsed 0.30 s\n",
      "[3/25][29/63] Loss_D: nan Loss_G: nan D(x): -1219.3915 D(G(z)): -1438.8466 / -1447.6147 Elapsed 0.30 s\n",
      "[3/25][30/63] Loss_D: nan Loss_G: nan D(x): -1228.3606 D(G(z)): -1440.4683 / -1463.9431 Elapsed 0.30 s\n",
      "[3/25][31/63] Loss_D: nan Loss_G: nan D(x): -1246.1654 D(G(z)): -1461.7336 / -1478.1064 Elapsed 0.32 s\n",
      "[3/25][32/63] Loss_D: nan Loss_G: nan D(x): -1250.2186 D(G(z)): -1481.8727 / -1488.0535 Elapsed 0.32 s\n",
      "[3/25][33/63] Loss_D: nan Loss_G: nan D(x): -1267.4624 D(G(z)): -1495.1443 / -1511.9565 Elapsed 0.33 s\n",
      "[3/25][34/63] Loss_D: nan Loss_G: nan D(x): -1297.0436 D(G(z)): -1511.2152 / -1522.3438 Elapsed 0.32 s\n",
      "[3/25][35/63] Loss_D: nan Loss_G: nan D(x): -1302.2979 D(G(z)): -1518.4102 / -1542.5903 Elapsed 0.32 s\n",
      "[3/25][36/63] Loss_D: nan Loss_G: nan D(x): -1318.2157 D(G(z)): -1540.6576 / -1559.3280 Elapsed 0.29 s\n",
      "[3/25][37/63] Loss_D: nan Loss_G: nan D(x): -1338.7744 D(G(z)): -1561.9685 / -1583.8323 Elapsed 0.30 s\n",
      "[3/25][38/63] Loss_D: nan Loss_G: nan D(x): -1346.9369 D(G(z)): -1571.4855 / -1593.2297 Elapsed 0.32 s\n",
      "[3/25][39/63] Loss_D: nan Loss_G: nan D(x): -1355.2306 D(G(z)): -1601.9894 / -1599.8511 Elapsed 0.32 s\n",
      "[3/25][40/63] Loss_D: nan Loss_G: nan D(x): -1379.7166 D(G(z)): -1610.6805 / -1631.0701 Elapsed 0.32 s\n",
      "[3/25][41/63] Loss_D: nan Loss_G: nan D(x): -1384.5834 D(G(z)): -1627.4652 / -1651.4006 Elapsed 0.30 s\n",
      "[3/25][42/63] Loss_D: nan Loss_G: nan D(x): -1398.3768 D(G(z)): -1644.3601 / -1664.1936 Elapsed 0.30 s\n",
      "[3/25][43/63] Loss_D: nan Loss_G: nan D(x): -1414.4117 D(G(z)): -1668.9275 / -1675.2714 Elapsed 0.30 s\n",
      "[3/25][44/63] Loss_D: nan Loss_G: nan D(x): -1411.7440 D(G(z)): -1680.2882 / -1688.2444 Elapsed 0.30 s\n",
      "[3/25][45/63] Loss_D: nan Loss_G: nan D(x): -1450.5582 D(G(z)): -1688.8572 / -1709.6958 Elapsed 0.30 s\n",
      "[3/25][46/63] Loss_D: nan Loss_G: nan D(x): -1455.6075 D(G(z)): -1716.3951 / -1735.0404 Elapsed 0.30 s\n",
      "[3/25][47/63] Loss_D: nan Loss_G: nan D(x): -1488.4403 D(G(z)): -1736.8518 / -1750.3613 Elapsed 0.30 s\n",
      "[3/25][48/63] Loss_D: nan Loss_G: nan D(x): -1503.5902 D(G(z)): -1758.5342 / -1762.7578 Elapsed 0.30 s\n",
      "[3/25][49/63] Loss_D: nan Loss_G: nan D(x): -1514.3055 D(G(z)): -1760.2579 / -1790.0570 Elapsed 0.30 s\n",
      "[3/25][50/63] Loss_D: nan Loss_G: nan D(x): -1534.4861 D(G(z)): -1783.7098 / -1802.6790 Elapsed 0.32 s\n",
      "[3/25][51/63] Loss_D: nan Loss_G: nan D(x): -1530.6423 D(G(z)): -1805.8596 / -1826.2150 Elapsed 0.30 s\n",
      "[3/25][52/63] Loss_D: nan Loss_G: nan D(x): -1543.9368 D(G(z)): -1812.2451 / -1846.7457 Elapsed 0.30 s\n",
      "[3/25][53/63] Loss_D: nan Loss_G: nan D(x): -1570.6217 D(G(z)): -1836.8894 / -1847.8047 Elapsed 0.30 s\n",
      "[3/25][54/63] Loss_D: nan Loss_G: nan D(x): -1595.6125 D(G(z)): -1841.3074 / -1871.1796 Elapsed 0.32 s\n",
      "[3/25][55/63] Loss_D: nan Loss_G: nan D(x): -1611.4406 D(G(z)): -1862.6259 / -1896.3405 Elapsed 0.30 s\n",
      "[3/25][56/63] Loss_D: nan Loss_G: nan D(x): -1621.9098 D(G(z)): -1886.9709 / -1901.1165 Elapsed 0.32 s\n",
      "[3/25][57/63] Loss_D: nan Loss_G: nan D(x): -1635.6925 D(G(z)): -1900.8510 / -1923.0300 Elapsed 0.32 s\n",
      "[3/25][58/63] Loss_D: nan Loss_G: nan D(x): -1661.8909 D(G(z)): -1934.6534 / -1951.1367 Elapsed 0.31 s\n",
      "[3/25][59/63] Loss_D: nan Loss_G: nan D(x): -1667.8958 D(G(z)): -1942.5830 / -1959.2123 Elapsed 0.32 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25][60/63] Loss_D: nan Loss_G: nan D(x): -1707.8700 D(G(z)): -1965.5031 / -1976.5673 Elapsed 0.32 s\n",
      "[3/25][61/63] Loss_D: nan Loss_G: nan D(x): -1714.4688 D(G(z)): -1994.1616 / -1997.6616 Elapsed 0.30 s\n",
      "[3/25][62/63] Loss_D: nan Loss_G: nan D(x): -1718.2122 D(G(z)): -2004.5363 / -2015.8457 Elapsed 0.17 s\n",
      "[4/25][0/63] Loss_D: nan Loss_G: nan D(x): -1720.1729 D(G(z)): -2024.7097 / -2040.7870 Elapsed 0.32 s\n",
      "[4/25][1/63] Loss_D: nan Loss_G: nan D(x): -1740.6113 D(G(z)): -2046.5078 / -2067.8093 Elapsed 0.32 s\n",
      "[4/25][2/63] Loss_D: nan Loss_G: nan D(x): -1765.4406 D(G(z)): -2064.3357 / -2078.1804 Elapsed 0.31 s\n",
      "[4/25][3/63] Loss_D: nan Loss_G: nan D(x): -1763.7827 D(G(z)): -2088.7170 / -2101.4019 Elapsed 0.32 s\n",
      "[4/25][4/63] Loss_D: nan Loss_G: nan D(x): -1807.6678 D(G(z)): -2090.2327 / -2118.4705 Elapsed 0.32 s\n",
      "[4/25][5/63] Loss_D: nan Loss_G: nan D(x): -1813.2771 D(G(z)): -2124.8286 / -2131.7539 Elapsed 0.32 s\n",
      "[4/25][6/63] Loss_D: nan Loss_G: nan D(x): -1830.6719 D(G(z)): -2132.5071 / -2146.9541 Elapsed 0.30 s\n",
      "[4/25][7/63] Loss_D: nan Loss_G: nan D(x): -1849.0828 D(G(z)): -2156.5701 / -2179.4719 Elapsed 0.32 s\n",
      "[4/25][8/63] Loss_D: nan Loss_G: nan D(x): -1878.5630 D(G(z)): -2163.8735 / -2208.0654 Elapsed 0.32 s\n",
      "[4/25][9/63] Loss_D: nan Loss_G: nan D(x): -1885.3374 D(G(z)): -2200.1562 / -2219.3992 Elapsed 0.32 s\n",
      "[4/25][10/63] Loss_D: nan Loss_G: nan D(x): -1896.9498 D(G(z)): -2229.1538 / -2233.7947 Elapsed 0.32 s\n",
      "[4/25][11/63] Loss_D: nan Loss_G: nan D(x): -1904.3872 D(G(z)): -2226.9805 / -2260.8823 Elapsed 0.32 s\n",
      "[4/25][12/63] Loss_D: nan Loss_G: nan D(x): -1937.3224 D(G(z)): -2256.9438 / -2266.7786 Elapsed 0.32 s\n",
      "[4/25][13/63] Loss_D: nan Loss_G: nan D(x): -1957.5143 D(G(z)): -2280.1567 / -2289.3486 Elapsed 0.33 s\n",
      "[4/25][14/63] Loss_D: nan Loss_G: nan D(x): -1963.2338 D(G(z)): -2302.8750 / -2321.4119 Elapsed 0.32 s\n",
      "[4/25][15/63] Loss_D: nan Loss_G: nan D(x): -2006.3650 D(G(z)): -2316.5774 / -2339.0300 Elapsed 0.30 s\n",
      "[4/25][16/63] Loss_D: nan Loss_G: nan D(x): -2011.8859 D(G(z)): -2346.1726 / -2361.6514 Elapsed 0.30 s\n",
      "[4/25][17/63] Loss_D: nan Loss_G: nan D(x): -2032.5103 D(G(z)): -2349.6011 / -2378.6592 Elapsed 0.28 s\n",
      "[4/25][18/63] Loss_D: nan Loss_G: nan D(x): -2035.6353 D(G(z)): -2356.5024 / -2388.9312 Elapsed 0.32 s\n",
      "[4/25][19/63] Loss_D: nan Loss_G: nan D(x): -2075.4675 D(G(z)): -2393.8408 / -2417.1541 Elapsed 0.32 s\n",
      "[4/25][20/63] Loss_D: nan Loss_G: nan D(x): -2072.5642 D(G(z)): -2426.9802 / -2438.6362 Elapsed 0.28 s\n",
      "[4/25][21/63] Loss_D: nan Loss_G: nan D(x): -2098.1907 D(G(z)): -2443.5090 / -2449.7288 Elapsed 0.30 s\n",
      "[4/25][22/63] Loss_D: nan Loss_G: nan D(x): -2122.2283 D(G(z)): -2453.8013 / -2484.8320 Elapsed 0.30 s\n",
      "[4/25][23/63] Loss_D: nan Loss_G: nan D(x): -2133.8323 D(G(z)): -2467.0881 / -2485.5093 Elapsed 0.32 s\n",
      "[4/25][24/63] Loss_D: nan Loss_G: nan D(x): -2143.4326 D(G(z)): -2503.1570 / -2520.8232 Elapsed 0.32 s\n",
      "[4/25][25/63] Loss_D: nan Loss_G: nan D(x): -2167.4941 D(G(z)): -2527.0359 / -2535.3552 Elapsed 0.30 s\n",
      "[4/25][26/63] Loss_D: nan Loss_G: nan D(x): -2180.7249 D(G(z)): -2543.1750 / -2569.4751 Elapsed 0.29 s\n",
      "[4/25][27/63] Loss_D: nan Loss_G: nan D(x): -2216.6174 D(G(z)): -2558.2822 / -2595.3879 Elapsed 0.32 s\n",
      "[4/25][28/63] Loss_D: nan Loss_G: nan D(x): -2246.2419 D(G(z)): -2577.6147 / -2602.1013 Elapsed 0.30 s\n",
      "[4/25][29/63] Loss_D: nan Loss_G: nan D(x): -2255.3350 D(G(z)): -2603.1885 / -2613.2351 Elapsed 0.30 s\n",
      "[4/25][30/63] Loss_D: nan Loss_G: nan D(x): -2241.9504 D(G(z)): -2630.6138 / -2647.7332 Elapsed 0.30 s\n",
      "[4/25][31/63] Loss_D: nan Loss_G: nan D(x): -2304.8916 D(G(z)): -2649.7551 / -2665.5813 Elapsed 0.29 s\n",
      "[4/25][32/63] Loss_D: nan Loss_G: nan D(x): -2300.1865 D(G(z)): -2680.6895 / -2686.6580 Elapsed 0.30 s\n",
      "[4/25][33/63] Loss_D: nan Loss_G: nan D(x): -2349.5066 D(G(z)): -2696.4626 / -2716.7007 Elapsed 0.30 s\n",
      "[4/25][34/63] Loss_D: nan Loss_G: nan D(x): -2329.9893 D(G(z)): -2707.7832 / -2746.2783 Elapsed 0.30 s\n",
      "[4/25][35/63] Loss_D: nan Loss_G: nan D(x): -2361.4570 D(G(z)): -2732.0974 / -2746.2058 Elapsed 0.32 s\n",
      "[4/25][36/63] Loss_D: nan Loss_G: nan D(x): -2396.6956 D(G(z)): -2750.6475 / -2783.4590 Elapsed 0.30 s\n",
      "[4/25][37/63] Loss_D: nan Loss_G: nan D(x): -2407.6943 D(G(z)): -2779.9150 / -2805.8179 Elapsed 0.30 s\n",
      "[4/25][38/63] Loss_D: nan Loss_G: nan D(x): -2428.5164 D(G(z)): -2805.1526 / -2823.2307 Elapsed 0.30 s\n",
      "[4/25][39/63] Loss_D: nan Loss_G: nan D(x): -2422.2922 D(G(z)): -2823.5906 / -2839.2725 Elapsed 0.31 s\n",
      "[4/25][40/63] Loss_D: nan Loss_G: nan D(x): -2466.5884 D(G(z)): -2850.8137 / -2863.8130 Elapsed 0.29 s\n",
      "[4/25][41/63] Loss_D: nan Loss_G: nan D(x): -2473.1396 D(G(z)): -2865.9524 / -2886.0005 Elapsed 0.30 s\n",
      "[4/25][42/63] Loss_D: nan Loss_G: nan D(x): -2494.5623 D(G(z)): -2890.6379 / -2925.6892 Elapsed 0.30 s\n",
      "[4/25][43/63] Loss_D: nan Loss_G: nan D(x): -2531.5491 D(G(z)): -2917.2957 / -2938.8579 Elapsed 0.30 s\n",
      "[4/25][44/63] Loss_D: nan Loss_G: nan D(x): -2547.5093 D(G(z)): -2930.0486 / -2966.9065 Elapsed 0.30 s\n",
      "[4/25][45/63] Loss_D: nan Loss_G: nan D(x): -2558.3032 D(G(z)): -2955.8416 / -2983.8123 Elapsed 0.30 s\n",
      "[4/25][46/63] Loss_D: nan Loss_G: nan D(x): -2589.1289 D(G(z)): -2989.1150 / -3002.8369 Elapsed 0.30 s\n",
      "[4/25][47/63] Loss_D: nan Loss_G: nan D(x): -2603.9248 D(G(z)): -3012.4773 / -3034.4194 Elapsed 0.28 s\n",
      "[4/25][48/63] Loss_D: nan Loss_G: nan D(x): -2626.7263 D(G(z)): -3026.2786 / -3047.2791 Elapsed 0.30 s\n",
      "[4/25][49/63] Loss_D: nan Loss_G: nan D(x): -2647.6787 D(G(z)): -3062.0667 / -3063.6826 Elapsed 0.30 s\n",
      "[4/25][50/63] Loss_D: nan Loss_G: nan D(x): -2652.7930 D(G(z)): -3074.7603 / -3087.1021 Elapsed 0.32 s\n",
      "[4/25][51/63] Loss_D: nan Loss_G: nan D(x): -2700.6189 D(G(z)): -3096.1812 / -3116.6250 Elapsed 0.30 s\n",
      "[4/25][52/63] Loss_D: nan Loss_G: nan D(x): -2698.1296 D(G(z)): -3118.6011 / -3137.4026 Elapsed 0.30 s\n",
      "[4/25][53/63] Loss_D: nan Loss_G: nan D(x): -2720.1318 D(G(z)): -3149.1711 / -3180.6406 Elapsed 0.30 s\n",
      "[4/25][54/63] Loss_D: nan Loss_G: nan D(x): -2788.4402 D(G(z)): -3172.0066 / -3190.2910 Elapsed 0.30 s\n",
      "[4/25][55/63] Loss_D: nan Loss_G: nan D(x): -2752.7737 D(G(z)): -3189.9543 / -3208.8103 Elapsed 0.32 s\n",
      "[4/25][56/63] Loss_D: nan Loss_G: nan D(x): -2787.2080 D(G(z)): -3219.4758 / -3230.9956 Elapsed 0.33 s\n",
      "[4/25][57/63] Loss_D: nan Loss_G: nan D(x): -2803.5134 D(G(z)): -3263.1182 / -3269.3691 Elapsed 0.32 s\n",
      "[4/25][58/63] Loss_D: nan Loss_G: nan D(x): -2840.5537 D(G(z)): -3270.5190 / -3289.6750 Elapsed 0.35 s\n",
      "[4/25][59/63] Loss_D: nan Loss_G: nan D(x): -2845.4783 D(G(z)): -3290.3262 / -3317.1960 Elapsed 0.31 s\n",
      "[4/25][60/63] Loss_D: nan Loss_G: nan D(x): -2862.2874 D(G(z)): -3308.4197 / -3337.1550 Elapsed 0.30 s\n",
      "[4/25][61/63] Loss_D: nan Loss_G: nan D(x): -2898.6367 D(G(z)): -3333.3848 / -3360.6758 Elapsed 0.30 s\n",
      "[4/25][62/63] Loss_D: nan Loss_G: nan D(x): -2897.7271 D(G(z)): -3370.0544 / -3381.6902 Elapsed 0.15 s\n",
      "[5/25][0/63] Loss_D: nan Loss_G: nan D(x): -2921.5735 D(G(z)): -3394.4758 / -3404.2971 Elapsed 0.30 s\n",
      "[5/25][1/63] Loss_D: nan Loss_G: nan D(x): -2965.2437 D(G(z)): -3414.8311 / -3438.6438 Elapsed 0.30 s\n",
      "[5/25][2/63] Loss_D: nan Loss_G: nan D(x): -2980.5195 D(G(z)): -3426.1941 / -3463.2285 Elapsed 0.30 s\n",
      "[5/25][3/63] Loss_D: nan Loss_G: nan D(x): -3001.6541 D(G(z)): -3454.8977 / -3486.6057 Elapsed 0.32 s\n",
      "[5/25][4/63] Loss_D: nan Loss_G: nan D(x): -3026.6025 D(G(z)): -3493.4031 / -3519.7346 Elapsed 0.32 s\n",
      "[5/25][5/63] Loss_D: nan Loss_G: nan D(x): -3056.2632 D(G(z)): -3491.9590 / -3530.5627 Elapsed 0.33 s\n",
      "[5/25][6/63] Loss_D: nan Loss_G: nan D(x): -3063.1362 D(G(z)): -3526.6575 / -3572.5071 Elapsed 0.32 s\n",
      "[5/25][7/63] Loss_D: nan Loss_G: nan D(x): -3079.7522 D(G(z)): -3561.6726 / -3582.9724 Elapsed 0.32 s\n",
      "[5/25][8/63] Loss_D: nan Loss_G: nan D(x): -3146.3857 D(G(z)): -3594.6992 / -3606.8862 Elapsed 0.30 s\n",
      "[5/25][9/63] Loss_D: nan Loss_G: nan D(x): -3145.3887 D(G(z)): -3608.2808 / -3626.0557 Elapsed 0.30 s\n",
      "[5/25][10/63] Loss_D: nan Loss_G: nan D(x): -3171.2527 D(G(z)): -3633.9961 / -3651.5737 Elapsed 0.32 s\n",
      "[5/25][11/63] Loss_D: nan Loss_G: nan D(x): -3185.9883 D(G(z)): -3662.7979 / -3666.2351 Elapsed 0.32 s\n",
      "[5/25][12/63] Loss_D: nan Loss_G: nan D(x): -3219.3313 D(G(z)): -3681.8521 / -3716.5947 Elapsed 0.32 s\n",
      "[5/25][13/63] Loss_D: nan Loss_G: nan D(x): -3208.0842 D(G(z)): -3708.3662 / -3735.7456 Elapsed 0.29 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25][14/63] Loss_D: nan Loss_G: nan D(x): -3232.7822 D(G(z)): -3735.6067 / -3769.3176 Elapsed 0.30 s\n",
      "[5/25][15/63] Loss_D: nan Loss_G: nan D(x): -3286.4490 D(G(z)): -3767.2175 / -3806.0020 Elapsed 0.32 s\n",
      "[5/25][16/63] Loss_D: nan Loss_G: nan D(x): -3283.0496 D(G(z)): -3789.4507 / -3814.8840 Elapsed 0.30 s\n",
      "[5/25][17/63] Loss_D: nan Loss_G: nan D(x): -3298.3413 D(G(z)): -3824.3689 / -3843.3638 Elapsed 0.30 s\n",
      "[5/25][18/63] Loss_D: nan Loss_G: nan D(x): -3341.2974 D(G(z)): -3852.7219 / -3866.1838 Elapsed 0.32 s\n",
      "[5/25][19/63] Loss_D: nan Loss_G: nan D(x): -3380.6091 D(G(z)): -3864.9070 / -3891.1372 Elapsed 0.39 s\n",
      "[5/25][20/63] Loss_D: nan Loss_G: nan D(x): -3372.6672 D(G(z)): -3868.3987 / -3925.1692 Elapsed 0.32 s\n",
      "[5/25][21/63] Loss_D: nan Loss_G: nan D(x): -3438.1855 D(G(z)): -3922.5449 / -3923.6545 Elapsed 0.34 s\n",
      "[5/25][22/63] Loss_D: nan Loss_G: nan D(x): -3422.2273 D(G(z)): -3951.0317 / -3977.9319 Elapsed 0.32 s\n",
      "[5/25][23/63] Loss_D: nan Loss_G: nan D(x): -3459.8577 D(G(z)): -3966.7646 / -3988.9209 Elapsed 0.30 s\n",
      "[5/25][24/63] Loss_D: nan Loss_G: nan D(x): -3470.4460 D(G(z)): -4007.8101 / -4011.9546 Elapsed 0.33 s\n",
      "[5/25][25/63] Loss_D: nan Loss_G: nan D(x): -3528.3176 D(G(z)): -4038.8132 / -4050.2280 Elapsed 0.34 s\n",
      "[5/25][26/63] Loss_D: nan Loss_G: nan D(x): -3514.4365 D(G(z)): -4044.0156 / -4081.7620 Elapsed 0.34 s\n",
      "[5/25][27/63] Loss_D: nan Loss_G: nan D(x): -3546.5815 D(G(z)): -4079.5176 / -4110.7280 Elapsed 0.32 s\n",
      "[5/25][28/63] Loss_D: nan Loss_G: nan D(x): -3568.4819 D(G(z)): -4104.8247 / -4144.6299 Elapsed 0.30 s\n",
      "[5/25][29/63] Loss_D: nan Loss_G: nan D(x): -3577.4910 D(G(z)): -4127.9570 / -4161.5171 Elapsed 0.32 s\n",
      "[5/25][30/63] Loss_D: nan Loss_G: nan D(x): -3611.0933 D(G(z)): -4172.0679 / -4212.3389 Elapsed 0.33 s\n",
      "[5/25][31/63] Loss_D: nan Loss_G: nan D(x): -3640.2415 D(G(z)): -4188.9912 / -4209.4243 Elapsed 0.37 s\n",
      "[5/25][32/63] Loss_D: nan Loss_G: nan D(x): -3673.9272 D(G(z)): -4219.8599 / -4231.1748 Elapsed 0.34 s\n",
      "[5/25][33/63] Loss_D: nan Loss_G: nan D(x): -3718.1975 D(G(z)): -4246.4058 / -4270.5679 Elapsed 0.37 s\n",
      "[5/25][34/63] Loss_D: nan Loss_G: nan D(x): -3736.4797 D(G(z)): -4273.0415 / -4280.4502 Elapsed 0.33 s\n",
      "[5/25][35/63] Loss_D: nan Loss_G: nan D(x): -3742.1917 D(G(z)): -4294.9121 / -4326.3145 Elapsed 0.37 s\n",
      "[5/25][36/63] Loss_D: nan Loss_G: nan D(x): -3775.3347 D(G(z)): -4308.2158 / -4341.1270 Elapsed 0.36 s\n",
      "[5/25][37/63] Loss_D: nan Loss_G: nan D(x): -3764.7031 D(G(z)): -4346.8843 / -4375.6069 Elapsed 0.33 s\n",
      "[5/25][38/63] Loss_D: nan Loss_G: nan D(x): -3814.1802 D(G(z)): -4387.3374 / -4411.5991 Elapsed 0.33 s\n",
      "[5/25][39/63] Loss_D: nan Loss_G: nan D(x): -3796.7852 D(G(z)): -4410.4985 / -4432.2275 Elapsed 0.34 s\n",
      "[5/25][40/63] Loss_D: nan Loss_G: nan D(x): -3857.7375 D(G(z)): -4433.5039 / -4454.4102 Elapsed 0.33 s\n",
      "[5/25][41/63] Loss_D: nan Loss_G: nan D(x): -3864.2317 D(G(z)): -4470.9902 / -4489.9531 Elapsed 0.36 s\n",
      "[5/25][42/63] Loss_D: nan Loss_G: nan D(x): -3908.9436 D(G(z)): -4490.9985 / -4514.9976 Elapsed 0.33 s\n",
      "[5/25][43/63] Loss_D: nan Loss_G: nan D(x): -3937.0569 D(G(z)): -4520.4712 / -4535.3853 Elapsed 0.30 s\n",
      "[5/25][44/63] Loss_D: nan Loss_G: nan D(x): -3962.2715 D(G(z)): -4559.7144 / -4582.6216 Elapsed 0.32 s\n",
      "[5/25][45/63] Loss_D: nan Loss_G: nan D(x): -3983.2473 D(G(z)): -4564.6455 / -4608.2837 Elapsed 0.33 s\n",
      "[5/25][46/63] Loss_D: nan Loss_G: nan D(x): -3995.9973 D(G(z)): -4626.2549 / -4630.2466 Elapsed 0.32 s\n",
      "[5/25][47/63] Loss_D: nan Loss_G: nan D(x): -4040.7878 D(G(z)): -4640.1787 / -4659.1172 Elapsed 0.30 s\n",
      "[5/25][48/63] Loss_D: nan Loss_G: nan D(x): -4061.3467 D(G(z)): -4658.5273 / -4671.6050 Elapsed 0.35 s\n",
      "[5/25][49/63] Loss_D: nan Loss_G: nan D(x): -4093.9731 D(G(z)): -4650.1870 / -4704.6538 Elapsed 0.34 s\n",
      "[5/25][50/63] Loss_D: nan Loss_G: nan D(x): -4131.3721 D(G(z)): -4717.8076 / -4741.2920 Elapsed 0.32 s\n",
      "[5/25][51/63] Loss_D: nan Loss_G: nan D(x): -4171.0249 D(G(z)): -4752.4209 / -4760.0967 Elapsed 0.33 s\n",
      "[5/25][52/63] Loss_D: nan Loss_G: nan D(x): -4132.1909 D(G(z)): -4780.8984 / -4790.6602 Elapsed 0.32 s\n",
      "[5/25][53/63] Loss_D: nan Loss_G: nan D(x): -4194.8247 D(G(z)): -4795.0283 / -4840.4355 Elapsed 0.33 s\n",
      "[5/25][54/63] Loss_D: nan Loss_G: nan D(x): -4194.4409 D(G(z)): -4841.1875 / -4857.5381 Elapsed 0.31 s\n",
      "[5/25][55/63] Loss_D: nan Loss_G: nan D(x): -4247.4004 D(G(z)): -4854.4370 / -4897.1504 Elapsed 0.30 s\n",
      "[5/25][56/63] Loss_D: nan Loss_G: nan D(x): -4275.1709 D(G(z)): -4885.5391 / -4932.7466 Elapsed 0.33 s\n",
      "[5/25][57/63] Loss_D: nan Loss_G: nan D(x): -4307.0396 D(G(z)): -4912.6943 / -4935.9541 Elapsed 0.32 s\n",
      "[5/25][58/63] Loss_D: nan Loss_G: nan D(x): -4310.8091 D(G(z)): -4942.3989 / -4979.6880 Elapsed 0.32 s\n",
      "[5/25][59/63] Loss_D: nan Loss_G: nan D(x): -4338.1426 D(G(z)): -4974.7197 / -4996.3926 Elapsed 0.30 s\n",
      "[5/25][60/63] Loss_D: nan Loss_G: nan D(x): -4385.6978 D(G(z)): -5003.0620 / -5016.5435 Elapsed 0.29 s\n",
      "[5/25][61/63] Loss_D: nan Loss_G: nan D(x): -4383.5645 D(G(z)): -5034.4980 / -5055.7319 Elapsed 0.30 s\n",
      "[5/25][62/63] Loss_D: nan Loss_G: nan D(x): -4449.8633 D(G(z)): -5041.5830 / -5082.9976 Elapsed 0.18 s\n",
      "[6/25][0/63] Loss_D: nan Loss_G: nan D(x): -4453.0083 D(G(z)): -5105.3091 / -5107.0918 Elapsed 0.34 s\n",
      "[6/25][1/63] Loss_D: nan Loss_G: nan D(x): -4442.7510 D(G(z)): -5135.1318 / -5161.4448 Elapsed 0.32 s\n",
      "[6/25][2/63] Loss_D: nan Loss_G: nan D(x): -4443.7710 D(G(z)): -5147.5806 / -5153.6978 Elapsed 0.33 s\n",
      "[6/25][3/63] Loss_D: nan Loss_G: nan D(x): -4514.3701 D(G(z)): -5197.6973 / -5212.3643 Elapsed 0.33 s\n",
      "[6/25][4/63] Loss_D: nan Loss_G: nan D(x): -4595.3477 D(G(z)): -5190.3291 / -5214.7227 Elapsed 0.32 s\n",
      "[6/25][5/63] Loss_D: nan Loss_G: nan D(x): -4526.2378 D(G(z)): -5253.0835 / -5279.0410 Elapsed 0.32 s\n",
      "[6/25][6/63] Loss_D: nan Loss_G: nan D(x): -4593.7021 D(G(z)): -5260.5215 / -5315.3291 Elapsed 0.35 s\n",
      "[6/25][7/63] Loss_D: nan Loss_G: nan D(x): -4634.2212 D(G(z)): -5289.9189 / -5338.8477 Elapsed 0.34 s\n",
      "[6/25][8/63] Loss_D: nan Loss_G: nan D(x): -4632.2778 D(G(z)): -5367.0562 / -5352.4819 Elapsed 0.32 s\n",
      "[6/25][9/63] Loss_D: nan Loss_G: nan D(x): -4669.6992 D(G(z)): -5370.9766 / -5405.1348 Elapsed 0.32 s\n",
      "[6/25][10/63] Loss_D: nan Loss_G: nan D(x): -4709.8066 D(G(z)): -5391.0435 / -5415.9497 Elapsed 0.32 s\n",
      "[6/25][11/63] Loss_D: nan Loss_G: nan D(x): -4745.3208 D(G(z)): -5443.3975 / -5465.7334 Elapsed 0.32 s\n",
      "[6/25][12/63] Loss_D: nan Loss_G: nan D(x): -4775.2202 D(G(z)): -5453.3350 / -5496.6392 Elapsed 0.32 s\n",
      "[6/25][13/63] Loss_D: nan Loss_G: nan D(x): -4773.5093 D(G(z)): -5498.9248 / -5506.3765 Elapsed 0.33 s\n",
      "[6/25][14/63] Loss_D: nan Loss_G: nan D(x): -4801.6396 D(G(z)): -5520.7866 / -5557.4507 Elapsed 0.30 s\n",
      "[6/25][15/63] Loss_D: nan Loss_G: nan D(x): -4845.8066 D(G(z)): -5547.3027 / -5567.1631 Elapsed 0.30 s\n",
      "[6/25][16/63] Loss_D: nan Loss_G: nan D(x): -4833.0303 D(G(z)): -5569.3125 / -5608.7012 Elapsed 0.30 s\n",
      "[6/25][17/63] Loss_D: nan Loss_G: nan D(x): -4873.0220 D(G(z)): -5604.0913 / -5640.7480 Elapsed 0.33 s\n",
      "[6/25][18/63] Loss_D: nan Loss_G: nan D(x): -4926.6812 D(G(z)): -5652.3838 / -5672.8003 Elapsed 0.32 s\n",
      "[6/25][19/63] Loss_D: nan Loss_G: nan D(x): -4971.3550 D(G(z)): -5660.1221 / -5700.9243 Elapsed 0.32 s\n",
      "[6/25][20/63] Loss_D: nan Loss_G: nan D(x): -4999.7031 D(G(z)): -5699.7417 / -5732.9180 Elapsed 0.32 s\n",
      "[6/25][21/63] Loss_D: nan Loss_G: nan D(x): -4954.3594 D(G(z)): -5724.7031 / -5768.1069 Elapsed 0.33 s\n",
      "[6/25][22/63] Loss_D: nan Loss_G: nan D(x): -4996.3647 D(G(z)): -5781.5527 / -5793.5244 Elapsed 0.32 s\n",
      "[6/25][23/63] Loss_D: nan Loss_G: nan D(x): -5116.1655 D(G(z)): -5802.4336 / -5831.0581 Elapsed 0.30 s\n",
      "[6/25][24/63] Loss_D: nan Loss_G: nan D(x): -5104.7720 D(G(z)): -5825.6636 / -5853.6230 Elapsed 0.30 s\n",
      "[6/25][25/63] Loss_D: nan Loss_G: nan D(x): -5106.5361 D(G(z)): -5879.2959 / -5891.6538 Elapsed 0.30 s\n",
      "[6/25][26/63] Loss_D: nan Loss_G: nan D(x): -5125.5117 D(G(z)): -5898.1338 / -5905.1831 Elapsed 0.32 s\n",
      "[6/25][27/63] Loss_D: nan Loss_G: nan D(x): -5166.2603 D(G(z)): -5924.7061 / -5974.8975 Elapsed 0.30 s\n",
      "[6/25][28/63] Loss_D: nan Loss_G: nan D(x): -5201.9766 D(G(z)): -5961.8579 / -5978.4565 Elapsed 0.30 s\n",
      "[6/25][29/63] Loss_D: nan Loss_G: nan D(x): -5253.9443 D(G(z)): -5975.0107 / -6034.4888 Elapsed 0.32 s\n",
      "[6/25][30/63] Loss_D: nan Loss_G: nan D(x): -5248.2017 D(G(z)): -5994.3735 / -6046.8125 Elapsed 0.30 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25][31/63] Loss_D: nan Loss_G: nan D(x): -5291.3438 D(G(z)): -6031.9736 / -6048.2012 Elapsed 0.30 s\n",
      "[6/25][32/63] Loss_D: nan Loss_G: nan D(x): -5338.2114 D(G(z)): -6095.1636 / -6100.9331 Elapsed 0.29 s\n",
      "[6/25][33/63] Loss_D: nan Loss_G: nan D(x): -5348.0845 D(G(z)): -6093.6611 / -6113.8857 Elapsed 0.28 s\n",
      "[6/25][34/63] Loss_D: nan Loss_G: nan D(x): -5386.7539 D(G(z)): -6151.4995 / -6189.9438 Elapsed 0.34 s\n",
      "[6/25][35/63] Loss_D: nan Loss_G: nan D(x): -5379.6533 D(G(z)): -6192.0186 / -6212.6772 Elapsed 0.32 s\n",
      "[6/25][36/63] Loss_D: nan Loss_G: nan D(x): -5400.7930 D(G(z)): -6200.1401 / -6260.2920 Elapsed 0.29 s\n",
      "[6/25][37/63] Loss_D: nan Loss_G: nan D(x): -5417.9580 D(G(z)): -6214.5923 / -6269.3042 Elapsed 0.32 s\n",
      "[6/25][38/63] Loss_D: nan Loss_G: nan D(x): -5527.8193 D(G(z)): -6262.9932 / -6309.8823 Elapsed 0.32 s\n",
      "[6/25][39/63] Loss_D: nan Loss_G: nan D(x): -5555.8296 D(G(z)): -6316.0488 / -6321.7891 Elapsed 0.30 s\n",
      "[6/25][40/63] Loss_D: nan Loss_G: nan D(x): -5530.9204 D(G(z)): -6313.3677 / -6341.0454 Elapsed 0.32 s\n",
      "[6/25][41/63] Loss_D: nan Loss_G: nan D(x): -5555.6499 D(G(z)): -6381.5552 / -6416.2856 Elapsed 0.33 s\n",
      "[6/25][42/63] Loss_D: nan Loss_G: nan D(x): -5596.4712 D(G(z)): -6413.9585 / -6427.8936 Elapsed 0.30 s\n",
      "[6/25][43/63] Loss_D: nan Loss_G: nan D(x): -5647.4844 D(G(z)): -6419.3115 / -6487.7842 Elapsed 0.32 s\n",
      "[6/25][44/63] Loss_D: nan Loss_G: nan D(x): -5651.5220 D(G(z)): -6479.0015 / -6504.6406 Elapsed 0.30 s\n",
      "[6/25][45/63] Loss_D: nan Loss_G: nan D(x): -5688.6123 D(G(z)): -6498.3066 / -6526.5200 Elapsed 0.32 s\n",
      "[6/25][46/63] Loss_D: nan Loss_G: nan D(x): -5729.0024 D(G(z)): -6527.9468 / -6554.4995 Elapsed 0.32 s\n",
      "[6/25][47/63] Loss_D: nan Loss_G: nan D(x): -5734.8213 D(G(z)): -6559.6284 / -6589.0195 Elapsed 0.32 s\n",
      "[6/25][48/63] Loss_D: nan Loss_G: nan D(x): -5773.6396 D(G(z)): -6591.9238 / -6628.8823 Elapsed 0.30 s\n",
      "[6/25][49/63] Loss_D: nan Loss_G: nan D(x): -5772.4902 D(G(z)): -6632.4067 / -6653.4727 Elapsed 0.31 s\n",
      "[6/25][50/63] Loss_D: nan Loss_G: nan D(x): -5853.3408 D(G(z)): -6669.6709 / -6689.3218 Elapsed 0.33 s\n",
      "[6/25][51/63] Loss_D: nan Loss_G: nan D(x): -5852.9355 D(G(z)): -6693.3501 / -6742.6782 Elapsed 0.30 s\n",
      "[6/25][52/63] Loss_D: nan Loss_G: nan D(x): -5909.8325 D(G(z)): -6707.6377 / -6767.9795 Elapsed 0.32 s\n",
      "[6/25][53/63] Loss_D: nan Loss_G: nan D(x): -5897.9258 D(G(z)): -6760.8364 / -6810.3545 Elapsed 0.32 s\n",
      "[6/25][54/63] Loss_D: nan Loss_G: nan D(x): -5913.8662 D(G(z)): -6796.9556 / -6860.6943 Elapsed 0.30 s\n",
      "[6/25][55/63] Loss_D: nan Loss_G: nan D(x): -5998.6763 D(G(z)): -6825.5244 / -6865.5625 Elapsed 0.32 s\n",
      "[6/25][56/63] Loss_D: nan Loss_G: nan D(x): -6019.5098 D(G(z)): -6887.5869 / -6907.1084 Elapsed 0.30 s\n",
      "[6/25][57/63] Loss_D: nan Loss_G: nan D(x): -6013.4844 D(G(z)): -6890.4541 / -6936.7866 Elapsed 0.32 s\n",
      "[6/25][58/63] Loss_D: nan Loss_G: nan D(x): -6080.2827 D(G(z)): -6940.7129 / -7021.6611 Elapsed 0.32 s\n",
      "[6/25][59/63] Loss_D: nan Loss_G: nan D(x): -6122.5762 D(G(z)): -6959.8955 / -7002.6899 Elapsed 0.34 s\n",
      "[6/25][60/63] Loss_D: nan Loss_G: nan D(x): -6094.7280 D(G(z)): -7009.9395 / -7066.4824 Elapsed 0.33 s\n",
      "[6/25][61/63] Loss_D: nan Loss_G: nan D(x): -6170.6021 D(G(z)): -7062.7983 / -7091.9365 Elapsed 0.30 s\n",
      "[6/25][62/63] Loss_D: nan Loss_G: nan D(x): -6185.3589 D(G(z)): -7088.4600 / -7129.7080 Elapsed 0.16 s\n",
      "[7/25][0/63] Loss_D: nan Loss_G: nan D(x): -6209.3613 D(G(z)): -7095.4038 / -7152.2295 Elapsed 0.32 s\n",
      "[7/25][1/63] Loss_D: nan Loss_G: nan D(x): -6253.9092 D(G(z)): -7126.7881 / -7166.7026 Elapsed 0.32 s\n",
      "[7/25][2/63] Loss_D: nan Loss_G: nan D(x): -6311.2339 D(G(z)): -7169.6743 / -7218.4351 Elapsed 0.33 s\n",
      "[7/25][3/63] Loss_D: nan Loss_G: nan D(x): -6330.9497 D(G(z)): -7199.2383 / -7234.0596 Elapsed 0.32 s\n",
      "[7/25][4/63] Loss_D: nan Loss_G: nan D(x): -6389.0088 D(G(z)): -7243.0312 / -7281.6729 Elapsed 0.32 s\n",
      "[7/25][5/63] Loss_D: nan Loss_G: nan D(x): -6372.2002 D(G(z)): -7288.5576 / -7320.3491 Elapsed 0.32 s\n",
      "[7/25][6/63] Loss_D: nan Loss_G: nan D(x): -6391.9619 D(G(z)): -7308.9419 / -7325.9526 Elapsed 0.30 s\n",
      "[7/25][7/63] Loss_D: nan Loss_G: nan D(x): -6403.1489 D(G(z)): -7348.9595 / -7375.8066 Elapsed 0.28 s\n",
      "[7/25][8/63] Loss_D: nan Loss_G: nan D(x): -6465.2935 D(G(z)): -7380.9297 / -7410.1055 Elapsed 0.37 s\n",
      "[7/25][9/63] Loss_D: nan Loss_G: nan D(x): -6479.1938 D(G(z)): -7409.4814 / -7422.0483 Elapsed 0.36 s\n",
      "[7/25][10/63] Loss_D: nan Loss_G: nan D(x): -6506.0063 D(G(z)): -7447.3691 / -7468.6328 Elapsed 0.35 s\n",
      "[7/25][11/63] Loss_D: nan Loss_G: nan D(x): -6530.1797 D(G(z)): -7508.0806 / -7515.4507 Elapsed 0.35 s\n",
      "[7/25][12/63] Loss_D: nan Loss_G: nan D(x): -6565.6807 D(G(z)): -7515.1079 / -7559.2271 Elapsed 0.31 s\n",
      "[7/25][13/63] Loss_D: nan Loss_G: nan D(x): -6607.6812 D(G(z)): -7537.7832 / -7582.1548 Elapsed 0.30 s\n",
      "[7/25][14/63] Loss_D: nan Loss_G: nan D(x): -6643.5200 D(G(z)): -7614.9556 / -7601.9775 Elapsed 0.32 s\n",
      "[7/25][15/63] Loss_D: nan Loss_G: nan D(x): -6651.5166 D(G(z)): -7593.5332 / -7651.3823 Elapsed 0.32 s\n",
      "[7/25][16/63] Loss_D: nan Loss_G: nan D(x): -6713.1655 D(G(z)): -7654.7285 / -7715.6797 Elapsed 0.31 s\n",
      "[7/25][17/63] Loss_D: nan Loss_G: nan D(x): -6741.9561 D(G(z)): -7690.2510 / -7725.7510 Elapsed 0.30 s\n",
      "[7/25][18/63] Loss_D: nan Loss_G: nan D(x): -6771.0425 D(G(z)): -7739.4272 / -7767.4966 Elapsed 0.30 s\n",
      "[7/25][19/63] Loss_D: nan Loss_G: nan D(x): -6798.5127 D(G(z)): -7779.3091 / -7790.7510 Elapsed 0.30 s\n",
      "[7/25][20/63] Loss_D: nan Loss_G: nan D(x): -6827.8628 D(G(z)): -7792.9990 / -7838.5547 Elapsed 0.30 s\n",
      "[7/25][21/63] Loss_D: nan Loss_G: nan D(x): -6839.8652 D(G(z)): -7832.9683 / -7864.6372 Elapsed 0.30 s\n",
      "[7/25][22/63] Loss_D: nan Loss_G: nan D(x): -6852.2734 D(G(z)): -7889.3569 / -7930.1924 Elapsed 0.32 s\n",
      "[7/25][23/63] Loss_D: nan Loss_G: nan D(x): -6896.4668 D(G(z)): -7909.9795 / -7951.2949 Elapsed 0.30 s\n",
      "[7/25][24/63] Loss_D: nan Loss_G: nan D(x): -6958.1807 D(G(z)): -7921.8374 / -7982.6660 Elapsed 0.30 s\n",
      "[7/25][25/63] Loss_D: nan Loss_G: nan D(x): -6998.5107 D(G(z)): -7977.6753 / -8032.9009 Elapsed 0.32 s\n",
      "[7/25][26/63] Loss_D: nan Loss_G: nan D(x): -6996.7314 D(G(z)): -8044.1250 / -8043.9404 Elapsed 0.28 s\n",
      "[7/25][27/63] Loss_D: nan Loss_G: nan D(x): -7024.6606 D(G(z)): -8052.2505 / -8078.7617 Elapsed 0.32 s\n",
      "[7/25][28/63] Loss_D: nan Loss_G: nan D(x): -7105.4971 D(G(z)): -8079.1108 / -8094.3057 Elapsed 0.32 s\n",
      "[7/25][29/63] Loss_D: nan Loss_G: nan D(x): -7112.4268 D(G(z)): -8132.0737 / -8175.8257 Elapsed 0.30 s\n",
      "[7/25][30/63] Loss_D: nan Loss_G: nan D(x): -7081.5347 D(G(z)): -8146.9429 / -8221.6094 Elapsed 0.32 s\n",
      "[7/25][31/63] Loss_D: nan Loss_G: nan D(x): -7136.6401 D(G(z)): -8187.4756 / -8245.9160 Elapsed 0.30 s\n",
      "[7/25][32/63] Loss_D: nan Loss_G: nan D(x): -7210.4355 D(G(z)): -8237.9346 / -8278.0576 Elapsed 0.30 s\n",
      "[7/25][33/63] Loss_D: nan Loss_G: nan D(x): -7192.5889 D(G(z)): -8291.4707 / -8304.8643 Elapsed 0.30 s\n",
      "[7/25][34/63] Loss_D: nan Loss_G: nan D(x): -7277.9180 D(G(z)): -8274.0527 / -8321.2021 Elapsed 0.30 s\n",
      "[7/25][35/63] Loss_D: nan Loss_G: nan D(x): -7312.4517 D(G(z)): -8324.3047 / -8350.4854 Elapsed 0.30 s\n",
      "[7/25][36/63] Loss_D: nan Loss_G: nan D(x): -7340.3804 D(G(z)): -8382.6514 / -8411.3662 Elapsed 0.30 s\n",
      "[7/25][37/63] Loss_D: nan Loss_G: nan D(x): -7346.0166 D(G(z)): -8416.6162 / -8468.5723 Elapsed 0.30 s\n",
      "[7/25][38/63] Loss_D: nan Loss_G: nan D(x): -7379.8154 D(G(z)): -8451.5156 / -8473.6533 Elapsed 0.32 s\n",
      "[7/25][39/63] Loss_D: nan Loss_G: nan D(x): -7467.5698 D(G(z)): -8511.2217 / -8521.5645 Elapsed 0.30 s\n",
      "[7/25][40/63] Loss_D: nan Loss_G: nan D(x): -7409.1753 D(G(z)): -8528.6514 / -8549.3516 Elapsed 0.32 s\n",
      "[7/25][41/63] Loss_D: nan Loss_G: nan D(x): -7440.9248 D(G(z)): -8550.6631 / -8576.9121 Elapsed 0.30 s\n",
      "[7/25][42/63] Loss_D: nan Loss_G: nan D(x): -7514.6426 D(G(z)): -8593.9961 / -8614.3408 Elapsed 0.30 s\n",
      "[7/25][43/63] Loss_D: nan Loss_G: nan D(x): -7578.7217 D(G(z)): -8650.1787 / -8677.6777 Elapsed 0.30 s\n",
      "[7/25][44/63] Loss_D: nan Loss_G: nan D(x): -7542.0947 D(G(z)): -8656.4893 / -8741.3057 Elapsed 0.30 s\n",
      "[7/25][45/63] Loss_D: nan Loss_G: nan D(x): -7643.4502 D(G(z)): -8716.9307 / -8755.3447 Elapsed 0.30 s\n",
      "[7/25][46/63] Loss_D: nan Loss_G: nan D(x): -7673.1919 D(G(z)): -8736.4072 / -8771.0137 Elapsed 0.30 s\n",
      "[7/25][47/63] Loss_D: nan Loss_G: nan D(x): -7658.4385 D(G(z)): -8809.8184 / -8830.6152 Elapsed 0.30 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25][48/63] Loss_D: nan Loss_G: nan D(x): -7726.9243 D(G(z)): -8823.4863 / -8844.8477 Elapsed 0.30 s\n",
      "[7/25][49/63] Loss_D: nan Loss_G: nan D(x): -7734.6294 D(G(z)): -8849.0449 / -8875.9043 Elapsed 0.32 s\n",
      "[7/25][50/63] Loss_D: nan Loss_G: nan D(x): -7772.0967 D(G(z)): -8893.4873 / -8937.5889 Elapsed 0.32 s\n",
      "[7/25][51/63] Loss_D: nan Loss_G: nan D(x): -7826.8354 D(G(z)): -8906.0957 / -8964.7549 Elapsed 0.32 s\n",
      "[7/25][52/63] Loss_D: nan Loss_G: nan D(x): -7883.3164 D(G(z)): -8940.9863 / -9009.8369 Elapsed 0.30 s\n",
      "[7/25][53/63] Loss_D: nan Loss_G: nan D(x): -7886.4917 D(G(z)): -8992.8135 / -9046.2471 Elapsed 0.30 s\n",
      "[7/25][54/63] Loss_D: nan Loss_G: nan D(x): -7949.7666 D(G(z)): -9054.0947 / -9080.0605 Elapsed 0.30 s\n",
      "[7/25][55/63] Loss_D: nan Loss_G: nan D(x): -7946.2119 D(G(z)): -9095.7920 / -9097.6816 Elapsed 0.30 s\n",
      "[7/25][56/63] Loss_D: nan Loss_G: nan D(x): -7960.8599 D(G(z)): -9108.7998 / -9153.4453 Elapsed 0.32 s\n",
      "[7/25][57/63] Loss_D: nan Loss_G: nan D(x): -8016.8335 D(G(z)): -9151.3418 / -9148.5215 Elapsed 0.32 s\n",
      "[7/25][58/63] Loss_D: nan Loss_G: nan D(x): -8065.6675 D(G(z)): -9184.8027 / -9224.1523 Elapsed 0.31 s\n",
      "[7/25][59/63] Loss_D: nan Loss_G: nan D(x): -8140.2632 D(G(z)): -9204.2061 / -9295.2021 Elapsed 0.30 s\n",
      "[7/25][60/63] Loss_D: nan Loss_G: nan D(x): -8104.3647 D(G(z)): -9271.4434 / -9322.8252 Elapsed 0.32 s\n",
      "[7/25][61/63] Loss_D: nan Loss_G: nan D(x): -8165.9819 D(G(z)): -9296.2422 / -9373.6689 Elapsed 0.30 s\n",
      "[7/25][62/63] Loss_D: nan Loss_G: nan D(x): -8184.7725 D(G(z)): -9309.0859 / -9427.9189 Elapsed 0.17 s\n",
      "[8/25][0/63] Loss_D: nan Loss_G: nan D(x): -8178.6519 D(G(z)): -9370.9404 / -9441.9648 Elapsed 0.33 s\n",
      "[8/25][1/63] Loss_D: nan Loss_G: nan D(x): -8267.9727 D(G(z)): -9412.6807 / -9499.3389 Elapsed 0.30 s\n",
      "[8/25][2/63] Loss_D: nan Loss_G: nan D(x): -8240.9414 D(G(z)): -9480.0059 / -9488.8496 Elapsed 0.32 s\n",
      "[8/25][3/63] Loss_D: nan Loss_G: nan D(x): -8302.8311 D(G(z)): -9496.1572 / -9548.9443 Elapsed 0.32 s\n",
      "[8/25][4/63] Loss_D: nan Loss_G: nan D(x): -8357.1162 D(G(z)): -9552.0898 / -9568.6973 Elapsed 0.32 s\n",
      "[8/25][5/63] Loss_D: nan Loss_G: nan D(x): -8383.4746 D(G(z)): -9600.0928 / -9589.6416 Elapsed 0.33 s\n",
      "[8/25][6/63] Loss_D: nan Loss_G: nan D(x): -8439.0078 D(G(z)): -9615.3691 / -9622.8447 Elapsed 0.30 s\n",
      "[8/25][7/63] Loss_D: nan Loss_G: nan D(x): -8406.7744 D(G(z)): -9663.8955 / -9659.0049 Elapsed 0.30 s\n",
      "[8/25][8/63] Loss_D: nan Loss_G: nan D(x): -8524.6289 D(G(z)): -9714.4209 / -9735.4795 Elapsed 0.30 s\n",
      "[8/25][9/63] Loss_D: nan Loss_G: nan D(x): -8508.6641 D(G(z)): -9732.0645 / -9746.7939 Elapsed 0.30 s\n",
      "[8/25][10/63] Loss_D: nan Loss_G: nan D(x): -8548.1445 D(G(z)): -9775.7441 / -9792.3086 Elapsed 0.33 s\n",
      "[8/25][11/63] Loss_D: nan Loss_G: nan D(x): -8598.2520 D(G(z)): -9813.3936 / -9887.3828 Elapsed 0.30 s\n",
      "[8/25][12/63] Loss_D: nan Loss_G: nan D(x): -8671.1768 D(G(z)): -9855.3008 / -9865.9141 Elapsed 0.30 s\n",
      "[8/25][13/63] Loss_D: nan Loss_G: nan D(x): -8621.8740 D(G(z)): -9904.9746 / -9880.2549 Elapsed 0.30 s\n",
      "[8/25][14/63] Loss_D: nan Loss_G: nan D(x): -8657.1582 D(G(z)): -9912.3955 / -9958.9521 Elapsed 0.30 s\n",
      "[8/25][15/63] Loss_D: nan Loss_G: nan D(x): -8657.6074 D(G(z)): -9942.0693 / -10020.3711 Elapsed 0.33 s\n",
      "[8/25][16/63] Loss_D: nan Loss_G: nan D(x): -8772.4551 D(G(z)): -9997.7744 / -10024.3271 Elapsed 0.32 s\n",
      "[8/25][17/63] Loss_D: nan Loss_G: nan D(x): -8787.6318 D(G(z)): -10027.9219 / -10016.9512 Elapsed 0.30 s\n",
      "[8/25][18/63] Loss_D: nan Loss_G: nan D(x): -8891.7256 D(G(z)): -10056.3789 / -10092.5361 Elapsed 0.33 s\n",
      "[8/25][19/63] Loss_D: nan Loss_G: nan D(x): -8854.3828 D(G(z)): -10103.4844 / -10157.2393 Elapsed 0.33 s\n",
      "[8/25][20/63] Loss_D: nan Loss_G: nan D(x): -8875.8418 D(G(z)): -10160.8242 / -10203.1406 Elapsed 0.30 s\n",
      "[8/25][21/63] Loss_D: nan Loss_G: nan D(x): -8889.1045 D(G(z)): -10199.6143 / -10188.8877 Elapsed 0.32 s\n",
      "[8/25][22/63] Loss_D: nan Loss_G: nan D(x): -8989.2334 D(G(z)): -10208.6768 / -10287.0010 Elapsed 0.30 s\n",
      "[8/25][23/63] Loss_D: nan Loss_G: nan D(x): -9042.1670 D(G(z)): -10278.0557 / -10306.8721 Elapsed 0.30 s\n",
      "[8/25][24/63] Loss_D: nan Loss_G: nan D(x): -9030.2627 D(G(z)): -10300.5791 / -10322.3164 Elapsed 0.30 s\n",
      "[8/25][25/63] Loss_D: nan Loss_G: nan D(x): -9075.3877 D(G(z)): -10360.4268 / -10405.1025 Elapsed 0.30 s\n",
      "[8/25][26/63] Loss_D: nan Loss_G: nan D(x): -9078.0059 D(G(z)): -10406.1553 / -10458.6934 Elapsed 0.30 s\n",
      "[8/25][27/63] Loss_D: nan Loss_G: nan D(x): -9066.6787 D(G(z)): -10415.0234 / -10479.9922 Elapsed 0.32 s\n",
      "[8/25][28/63] Loss_D: nan Loss_G: nan D(x): -9178.4209 D(G(z)): -10445.9561 / -10514.1309 Elapsed 0.32 s\n",
      "[8/25][29/63] Loss_D: nan Loss_G: nan D(x): -9198.9941 D(G(z)): -10516.2861 / -10516.9951 Elapsed 0.31 s\n",
      "[8/25][30/63] Loss_D: nan Loss_G: nan D(x): -9203.4590 D(G(z)): -10549.3066 / -10592.1963 Elapsed 0.30 s\n",
      "[8/25][31/63] Loss_D: nan Loss_G: nan D(x): -9264.0391 D(G(z)): -10556.4297 / -10606.6289 Elapsed 0.32 s\n",
      "[8/25][32/63] Loss_D: nan Loss_G: nan D(x): -9331.6953 D(G(z)): -10595.2900 / -10660.5381 Elapsed 0.33 s\n",
      "[8/25][33/63] Loss_D: nan Loss_G: nan D(x): -9301.7988 D(G(z)): -10669.6641 / -10700.1152 Elapsed 0.30 s\n",
      "[8/25][34/63] Loss_D: nan Loss_G: nan D(x): -9446.9688 D(G(z)): -10716.6514 / -10736.6699 Elapsed 0.33 s\n",
      "[8/25][35/63] Loss_D: nan Loss_G: nan D(x): -9415.0918 D(G(z)): -10699.0996 / -10766.6699 Elapsed 0.32 s\n",
      "[8/25][36/63] Loss_D: nan Loss_G: nan D(x): -9469.5771 D(G(z)): -10771.6230 / -10780.2041 Elapsed 0.34 s\n",
      "[8/25][37/63] Loss_D: nan Loss_G: nan D(x): -9505.8682 D(G(z)): -10778.0479 / -10869.8389 Elapsed 0.32 s\n",
      "[8/25][38/63] Loss_D: nan Loss_G: nan D(x): -9513.6426 D(G(z)): -10842.3418 / -10890.5293 Elapsed 0.35 s\n",
      "[8/25][39/63] Loss_D: nan Loss_G: nan D(x): -9467.9346 D(G(z)): -10908.1924 / -10950.2969 Elapsed 0.33 s\n",
      "[8/25][40/63] Loss_D: nan Loss_G: nan D(x): -9580.7803 D(G(z)): -10924.3779 / -10960.7402 Elapsed 0.34 s\n",
      "[8/25][41/63] Loss_D: nan Loss_G: nan D(x): -9664.1494 D(G(z)): -10996.9346 / -11072.3223 Elapsed 0.32 s\n",
      "[8/25][42/63] Loss_D: nan Loss_G: nan D(x): -9683.9795 D(G(z)): -11024.4365 / -11039.3115 Elapsed 0.33 s\n",
      "[8/25][43/63] Loss_D: nan Loss_G: nan D(x): -9718.4004 D(G(z)): -11044.9961 / -11091.4834 Elapsed 0.33 s\n",
      "[8/25][44/63] Loss_D: nan Loss_G: nan D(x): -9733.5430 D(G(z)): -11080.8086 / -11149.5010 Elapsed 0.33 s\n",
      "[8/25][45/63] Loss_D: nan Loss_G: nan D(x): -9722.3535 D(G(z)): -11117.8203 / -11185.3535 Elapsed 0.33 s\n",
      "[8/25][46/63] Loss_D: nan Loss_G: nan D(x): -9794.5312 D(G(z)): -11173.0010 / -11190.6348 Elapsed 0.33 s\n",
      "[8/25][47/63] Loss_D: nan Loss_G: nan D(x): -9877.2441 D(G(z)): -11188.0469 / -11252.2725 Elapsed 0.31 s\n",
      "[8/25][48/63] Loss_D: nan Loss_G: nan D(x): -9899.8818 D(G(z)): -11252.4248 / -11290.0000 Elapsed 0.33 s\n",
      "[8/25][49/63] Loss_D: nan Loss_G: nan D(x): -9913.5820 D(G(z)): -11307.1621 / -11364.6807 Elapsed 0.32 s\n",
      "[8/25][50/63] Loss_D: nan Loss_G: nan D(x): -9941.6631 D(G(z)): -11360.6299 / -11371.3242 Elapsed 0.30 s\n",
      "[8/25][51/63] Loss_D: nan Loss_G: nan D(x): -9920.9238 D(G(z)): -11386.6162 / -11440.4902 Elapsed 0.31 s\n",
      "[8/25][52/63] Loss_D: nan Loss_G: nan D(x): -9947.2461 D(G(z)): -11409.5576 / -11451.1348 Elapsed 0.30 s\n",
      "[8/25][53/63] Loss_D: nan Loss_G: nan D(x): -10028.0107 D(G(z)): -11435.2646 / -11512.7695 Elapsed 0.30 s\n",
      "[8/25][54/63] Loss_D: nan Loss_G: nan D(x): -10105.0791 D(G(z)): -11519.8711 / -11501.2207 Elapsed 0.30 s\n",
      "[8/25][55/63] Loss_D: nan Loss_G: nan D(x): -10045.0967 D(G(z)): -11514.7100 / -11548.2246 Elapsed 0.30 s\n",
      "[8/25][56/63] Loss_D: nan Loss_G: nan D(x): -10098.2070 D(G(z)): -11594.5381 / -11589.4678 Elapsed 0.29 s\n",
      "[8/25][57/63] Loss_D: nan Loss_G: nan D(x): -10198.3027 D(G(z)): -11605.5107 / -11656.4766 Elapsed 0.31 s\n",
      "[8/25][58/63] Loss_D: nan Loss_G: nan D(x): -10202.5615 D(G(z)): -11644.7549 / -11682.3115 Elapsed 0.31 s\n",
      "[8/25][59/63] Loss_D: nan Loss_G: nan D(x): -10152.8115 D(G(z)): -11686.1621 / -11710.2275 Elapsed 0.33 s\n",
      "[8/25][60/63] Loss_D: nan Loss_G: nan D(x): -10322.1377 D(G(z)): -11712.1543 / -11771.6621 Elapsed 0.32 s\n",
      "[8/25][61/63] Loss_D: nan Loss_G: nan D(x): -10282.0225 D(G(z)): -11802.5371 / -11817.5566 Elapsed 0.31 s\n",
      "[8/25][62/63] Loss_D: nan Loss_G: nan D(x): -10458.7832 D(G(z)): -11846.4258 / -11961.9844 Elapsed 0.20 s\n",
      "[9/25][0/63] Loss_D: nan Loss_G: nan D(x): -10304.2988 D(G(z)): -11852.5371 / -11889.9316 Elapsed 0.32 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25][1/63] Loss_D: nan Loss_G: nan D(x): -10434.2324 D(G(z)): -11901.7490 / -11934.3496 Elapsed 0.32 s\n",
      "[9/25][2/63] Loss_D: nan Loss_G: nan D(x): -10437.6475 D(G(z)): -11902.9727 / -11954.3018 Elapsed 0.33 s\n",
      "[9/25][3/63] Loss_D: nan Loss_G: nan D(x): -10486.4746 D(G(z)): -12006.1748 / -12003.7354 Elapsed 0.32 s\n",
      "[9/25][4/63] Loss_D: nan Loss_G: nan D(x): -10500.1582 D(G(z)): -12009.1465 / -12077.9111 Elapsed 0.32 s\n",
      "[9/25][5/63] Loss_D: nan Loss_G: nan D(x): -10538.6553 D(G(z)): -12025.3135 / -12119.1484 Elapsed 0.33 s\n",
      "[9/25][6/63] Loss_D: nan Loss_G: nan D(x): -10536.5469 D(G(z)): -12081.7266 / -12162.1719 Elapsed 0.31 s\n",
      "[9/25][7/63] Loss_D: nan Loss_G: nan D(x): -10594.5938 D(G(z)): -12135.0293 / -12180.1377 Elapsed 0.33 s\n",
      "[9/25][8/63] Loss_D: nan Loss_G: nan D(x): -10686.1182 D(G(z)): -12167.8604 / -12248.9736 Elapsed 0.32 s\n",
      "[9/25][9/63] Loss_D: nan Loss_G: nan D(x): -10745.2461 D(G(z)): -12254.6973 / -12277.9033 Elapsed 0.33 s\n",
      "[9/25][10/63] Loss_D: nan Loss_G: nan D(x): -10759.5381 D(G(z)): -12331.7578 / -12303.2959 Elapsed 0.33 s\n",
      "[9/25][11/63] Loss_D: nan Loss_G: nan D(x): -10843.6504 D(G(z)): -12287.6807 / -12338.7754 Elapsed 0.32 s\n",
      "[9/25][12/63] Loss_D: nan Loss_G: nan D(x): -10844.8760 D(G(z)): -12385.3105 / -12411.1562 Elapsed 0.30 s\n",
      "[9/25][13/63] Loss_D: nan Loss_G: nan D(x): -10854.2881 D(G(z)): -12347.2783 / -12436.9814 Elapsed 0.32 s\n",
      "[9/25][14/63] Loss_D: nan Loss_G: nan D(x): -10915.2842 D(G(z)): -12398.8701 / -12434.4717 Elapsed 0.30 s\n",
      "[9/25][15/63] Loss_D: nan Loss_G: nan D(x): -10903.8018 D(G(z)): -12481.4961 / -12560.4248 Elapsed 0.30 s\n",
      "[9/25][16/63] Loss_D: nan Loss_G: nan D(x): -10970.8193 D(G(z)): -12514.1123 / -12560.3838 Elapsed 0.30 s\n",
      "[9/25][17/63] Loss_D: nan Loss_G: nan D(x): -11061.1562 D(G(z)): -12577.1719 / -12600.4844 Elapsed 0.30 s\n",
      "[9/25][18/63] Loss_D: nan Loss_G: nan D(x): -11064.9844 D(G(z)): -12549.2930 / -12658.2275 Elapsed 0.30 s\n",
      "[9/25][19/63] Loss_D: nan Loss_G: nan D(x): -11071.8408 D(G(z)): -12615.4512 / -12708.7793 Elapsed 0.33 s\n",
      "[9/25][20/63] Loss_D: nan Loss_G: nan D(x): -11139.9844 D(G(z)): -12705.9814 / -12731.6621 Elapsed 0.30 s\n",
      "[9/25][21/63] Loss_D: nan Loss_G: nan D(x): -11159.9072 D(G(z)): -12743.6289 / -12725.3867 Elapsed 0.30 s\n",
      "[9/25][22/63] Loss_D: nan Loss_G: nan D(x): -11159.0547 D(G(z)): -12768.8877 / -12831.6123 Elapsed 0.30 s\n",
      "[9/25][23/63] Loss_D: nan Loss_G: nan D(x): -11228.9326 D(G(z)): -12803.5957 / -12824.0840 Elapsed 0.30 s\n",
      "[9/25][24/63] Loss_D: nan Loss_G: nan D(x): -11237.0146 D(G(z)): -12857.9346 / -12834.5723 Elapsed 0.30 s\n",
      "[9/25][25/63] Loss_D: nan Loss_G: nan D(x): -11339.6592 D(G(z)): -12889.4023 / -12916.9873 Elapsed 0.31 s\n",
      "[9/25][26/63] Loss_D: nan Loss_G: nan D(x): -11343.7402 D(G(z)): -12941.7793 / -12961.8066 Elapsed 0.32 s\n",
      "[9/25][27/63] Loss_D: nan Loss_G: nan D(x): -11314.2139 D(G(z)): -12980.8125 / -12984.2676 Elapsed 0.31 s\n",
      "[9/25][28/63] Loss_D: nan Loss_G: nan D(x): -11411.8340 D(G(z)): -12979.6387 / -13025.7031 Elapsed 0.29 s\n",
      "[9/25][29/63] Loss_D: nan Loss_G: nan D(x): -11501.9434 D(G(z)): -13023.9463 / -13119.7295 Elapsed 0.30 s\n",
      "[9/25][30/63] Loss_D: nan Loss_G: nan D(x): -11510.3584 D(G(z)): -13126.1582 / -13136.8271 Elapsed 0.30 s\n",
      "[9/25][31/63] Loss_D: nan Loss_G: nan D(x): -11487.1104 D(G(z)): -13096.7881 / -13119.0596 Elapsed 0.31 s\n",
      "[9/25][32/63] Loss_D: nan Loss_G: nan D(x): -11584.1943 D(G(z)): -13154.3564 / -13172.3340 Elapsed 0.32 s\n",
      "[9/25][33/63] Loss_D: nan Loss_G: nan D(x): -11596.1514 D(G(z)): -13209.5479 / -13240.4639 Elapsed 0.30 s\n",
      "[9/25][34/63] Loss_D: nan Loss_G: nan D(x): -11650.1514 D(G(z)): -13226.2197 / -13277.6699 Elapsed 0.32 s\n",
      "[9/25][35/63] Loss_D: nan Loss_G: nan D(x): -11677.5986 D(G(z)): -13307.3916 / -13342.1016 Elapsed 0.31 s\n",
      "[9/25][36/63] Loss_D: nan Loss_G: nan D(x): -11691.8701 D(G(z)): -13365.2705 / -13363.2559 Elapsed 0.32 s\n",
      "[9/25][37/63] Loss_D: nan Loss_G: nan D(x): -11718.7783 D(G(z)): -13381.5225 / -13366.8184 Elapsed 0.32 s\n",
      "[9/25][38/63] Loss_D: nan Loss_G: nan D(x): -11791.3096 D(G(z)): -13414.5215 / -13457.2725 Elapsed 0.31 s\n",
      "[9/25][39/63] Loss_D: nan Loss_G: nan D(x): -11818.5088 D(G(z)): -13466.3838 / -13506.8945 Elapsed 0.32 s\n",
      "[9/25][40/63] Loss_D: nan Loss_G: nan D(x): -11864.2793 D(G(z)): -13501.1611 / -13547.5752 Elapsed 0.33 s\n",
      "[9/25][41/63] Loss_D: nan Loss_G: nan D(x): -11874.1719 D(G(z)): -13584.1201 / -13565.6338 Elapsed 0.30 s\n",
      "[9/25][42/63] Loss_D: nan Loss_G: nan D(x): -11859.7080 D(G(z)): -13578.5068 / -13566.2969 Elapsed 0.31 s\n",
      "[9/25][43/63] Loss_D: nan Loss_G: nan D(x): -11968.3262 D(G(z)): -13632.5117 / -13729.6934 Elapsed 0.31 s\n",
      "[9/25][44/63] Loss_D: nan Loss_G: nan D(x): -11969.6855 D(G(z)): -13707.1445 / -13722.4961 Elapsed 0.30 s\n",
      "[9/25][45/63] Loss_D: nan Loss_G: nan D(x): -12043.2666 D(G(z)): -13711.8818 / -13734.4316 Elapsed 0.30 s\n",
      "[9/25][46/63] Loss_D: nan Loss_G: nan D(x): -12045.0859 D(G(z)): -13800.7061 / -13784.2227 Elapsed 0.31 s\n",
      "[9/25][47/63] Loss_D: nan Loss_G: nan D(x): -12054.9082 D(G(z)): -13803.8564 / -13881.1562 Elapsed 0.29 s\n",
      "[9/25][48/63] Loss_D: nan Loss_G: nan D(x): -12100.5312 D(G(z)): -13865.3828 / -13889.4688 Elapsed 0.30 s\n",
      "[9/25][49/63] Loss_D: nan Loss_G: nan D(x): -12167.8311 D(G(z)): -13863.5986 / -13948.3984 Elapsed 0.30 s\n",
      "[9/25][50/63] Loss_D: nan Loss_G: nan D(x): -12115.8359 D(G(z)): -13901.3613 / -13948.5879 Elapsed 0.30 s\n",
      "[9/25][51/63] Loss_D: nan Loss_G: nan D(x): -12269.5693 D(G(z)): -13977.0850 / -14006.0596 Elapsed 0.30 s\n",
      "[9/25][52/63] Loss_D: nan Loss_G: nan D(x): -12296.0410 D(G(z)): -14005.2695 / -14068.5664 Elapsed 0.31 s\n",
      "[9/25][53/63] Loss_D: nan Loss_G: nan D(x): -12378.5156 D(G(z)): -14063.9238 / -14091.2959 Elapsed 0.30 s\n",
      "[9/25][54/63] Loss_D: nan Loss_G: nan D(x): -12372.9150 D(G(z)): -14090.1191 / -14099.7725 Elapsed 0.30 s\n",
      "[9/25][55/63] Loss_D: nan Loss_G: nan D(x): -12446.8828 D(G(z)): -14098.0537 / -14183.0332 Elapsed 0.30 s\n",
      "[9/25][56/63] Loss_D: nan Loss_G: nan D(x): -12490.4238 D(G(z)): -14149.7715 / -14202.3359 Elapsed 0.30 s\n",
      "[9/25][57/63] Loss_D: nan Loss_G: nan D(x): -12512.2432 D(G(z)): -14204.4951 / -14258.7871 Elapsed 0.32 s\n",
      "[9/25][58/63] Loss_D: nan Loss_G: nan D(x): -12447.8438 D(G(z)): -14265.3730 / -14292.2109 Elapsed 0.29 s\n",
      "[9/25][59/63] Loss_D: nan Loss_G: nan D(x): -12517.5352 D(G(z)): -14345.4316 / -14283.6270 Elapsed 0.32 s\n",
      "[9/25][60/63] Loss_D: nan Loss_G: nan D(x): -12619.4287 D(G(z)): -14341.7891 / -14380.3809 Elapsed 0.29 s\n",
      "[9/25][61/63] Loss_D: nan Loss_G: nan D(x): -12671.4961 D(G(z)): -14381.6865 / -14432.2656 Elapsed 0.30 s\n",
      "[9/25][62/63] Loss_D: nan Loss_G: nan D(x): -12560.1807 D(G(z)): -14451.0586 / -14514.9717 Elapsed 0.17 s\n",
      "[10/25][0/63] Loss_D: nan Loss_G: nan D(x): -12641.3721 D(G(z)): -14423.0879 / -14536.9463 Elapsed 0.32 s\n",
      "[10/25][1/63] Loss_D: nan Loss_G: nan D(x): -12744.0273 D(G(z)): -14451.2803 / -14520.8662 Elapsed 0.32 s\n",
      "[10/25][2/63] Loss_D: nan Loss_G: nan D(x): -12769.6855 D(G(z)): -14580.7607 / -14602.2383 Elapsed 0.32 s\n",
      "[10/25][3/63] Loss_D: nan Loss_G: nan D(x): -12764.4268 D(G(z)): -14572.8662 / -14644.6475 Elapsed 0.33 s\n",
      "[10/25][4/63] Loss_D: nan Loss_G: nan D(x): -12943.0820 D(G(z)): -14619.3789 / -14656.3408 Elapsed 0.32 s\n",
      "[10/25][5/63] Loss_D: nan Loss_G: nan D(x): -12871.6611 D(G(z)): -14695.6484 / -14754.7031 Elapsed 0.33 s\n",
      "[10/25][6/63] Loss_D: nan Loss_G: nan D(x): -12945.2754 D(G(z)): -14738.9688 / -14724.9766 Elapsed 0.32 s\n",
      "[10/25][7/63] Loss_D: nan Loss_G: nan D(x): -12937.6914 D(G(z)): -14746.2188 / -14820.2197 Elapsed 0.30 s\n",
      "[10/25][8/63] Loss_D: nan Loss_G: nan D(x): -12991.5498 D(G(z)): -14840.2715 / -14895.3320 Elapsed 0.32 s\n",
      "[10/25][9/63] Loss_D: nan Loss_G: nan D(x): -13039.3750 D(G(z)): -14874.1201 / -14912.7090 Elapsed 0.30 s\n",
      "[10/25][10/63] Loss_D: nan Loss_G: nan D(x): -13060.8340 D(G(z)): -14878.0869 / -14897.0479 Elapsed 0.30 s\n",
      "[10/25][11/63] Loss_D: nan Loss_G: nan D(x): -13113.9395 D(G(z)): -14914.0498 / -14980.3760 Elapsed 0.32 s\n",
      "[10/25][12/63] Loss_D: nan Loss_G: nan D(x): -13071.7646 D(G(z)): -14938.7578 / -15029.1680 Elapsed 0.31 s\n",
      "[10/25][13/63] Loss_D: nan Loss_G: nan D(x): -13106.9951 D(G(z)): -15001.1016 / -15059.3262 Elapsed 0.32 s\n",
      "[10/25][14/63] Loss_D: nan Loss_G: nan D(x): -13220.3447 D(G(z)): -15089.4648 / -15138.5547 Elapsed 0.30 s\n",
      "[10/25][15/63] Loss_D: nan Loss_G: nan D(x): -13233.0391 D(G(z)): -15143.0410 / -15180.1113 Elapsed 0.30 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25][16/63] Loss_D: nan Loss_G: nan D(x): -13348.8828 D(G(z)): -15143.9961 / -15238.1895 Elapsed 0.30 s\n",
      "[10/25][17/63] Loss_D: nan Loss_G: nan D(x): -13371.8848 D(G(z)): -15194.8301 / -15239.6611 Elapsed 0.30 s\n",
      "[10/25][18/63] Loss_D: nan Loss_G: nan D(x): -13353.8955 D(G(z)): -15213.6660 / -15282.1895 Elapsed 0.32 s\n",
      "[10/25][19/63] Loss_D: nan Loss_G: nan D(x): -13345.7197 D(G(z)): -15229.2637 / -15337.1338 Elapsed 0.31 s\n",
      "[10/25][20/63] Loss_D: nan Loss_G: nan D(x): -13455.9141 D(G(z)): -15320.0693 / -15353.3047 Elapsed 0.30 s\n",
      "[10/25][21/63] Loss_D: nan Loss_G: nan D(x): -13439.7031 D(G(z)): -15377.5332 / -15344.4463 Elapsed 0.32 s\n",
      "[10/25][22/63] Loss_D: nan Loss_G: nan D(x): -13421.9189 D(G(z)): -15434.2949 / -15416.4404 Elapsed 0.31 s\n",
      "[10/25][23/63] Loss_D: nan Loss_G: nan D(x): -13609.0879 D(G(z)): -15452.7012 / -15530.0781 Elapsed 0.30 s\n",
      "[10/25][24/63] Loss_D: nan Loss_G: nan D(x): -13616.2334 D(G(z)): -15479.7061 / -15536.2979 Elapsed 0.33 s\n",
      "[10/25][25/63] Loss_D: nan Loss_G: nan D(x): -13660.7539 D(G(z)): -15499.9619 / -15532.5732 Elapsed 0.30 s\n",
      "[10/25][26/63] Loss_D: nan Loss_G: nan D(x): -13623.1094 D(G(z)): -15593.4697 / -15627.8623 Elapsed 0.30 s\n",
      "[10/25][27/63] Loss_D: nan Loss_G: nan D(x): -13715.0586 D(G(z)): -15597.7539 / -15624.8096 Elapsed 0.31 s\n",
      "[10/25][28/63] Loss_D: nan Loss_G: nan D(x): -13687.3311 D(G(z)): -15666.9551 / -15708.5850 Elapsed 0.32 s\n",
      "[10/25][29/63] Loss_D: nan Loss_G: nan D(x): -13762.4131 D(G(z)): -15703.7793 / -15737.8105 Elapsed 0.30 s\n",
      "[10/25][30/63] Loss_D: nan Loss_G: nan D(x): -13776.7158 D(G(z)): -15717.5049 / -15757.2178 Elapsed 0.30 s\n",
      "[10/25][31/63] Loss_D: nan Loss_G: nan D(x): -13862.6553 D(G(z)): -15772.3418 / -15850.8848 Elapsed 0.30 s\n",
      "[10/25][32/63] Loss_D: nan Loss_G: nan D(x): -13852.0244 D(G(z)): -15879.5283 / -15899.0830 Elapsed 0.32 s\n",
      "[10/25][33/63] Loss_D: nan Loss_G: nan D(x): -13887.6279 D(G(z)): -15831.9648 / -15839.4971 Elapsed 0.31 s\n",
      "[10/25][34/63] Loss_D: nan Loss_G: nan D(x): -13891.8506 D(G(z)): -15910.4277 / -15945.2217 Elapsed 0.32 s\n",
      "[10/25][35/63] Loss_D: nan Loss_G: nan D(x): -13934.6729 D(G(z)): -15928.4131 / -16000.8457 Elapsed 0.36 s\n",
      "[10/25][36/63] Loss_D: nan Loss_G: nan D(x): -13936.9229 D(G(z)): -15961.6758 / -16055.2480 Elapsed 0.32 s\n",
      "[10/25][37/63] Loss_D: nan Loss_G: nan D(x): -14076.9082 D(G(z)): -15996.2969 / -16055.7734 Elapsed 0.34 s\n",
      "[10/25][38/63] Loss_D: nan Loss_G: nan D(x): -14045.1680 D(G(z)): -16044.1621 / -16135.4297 Elapsed 0.32 s\n",
      "[10/25][39/63] Loss_D: nan Loss_G: nan D(x): -14194.4082 D(G(z)): -16130.9863 / -16159.2451 Elapsed 0.32 s\n",
      "[10/25][40/63] Loss_D: nan Loss_G: nan D(x): -14143.8096 D(G(z)): -16186.6055 / -16194.9355 Elapsed 0.30 s\n",
      "[10/25][41/63] Loss_D: nan Loss_G: nan D(x): -14312.1826 D(G(z)): -16212.7949 / -16268.4414 Elapsed 0.32 s\n",
      "[10/25][42/63] Loss_D: nan Loss_G: nan D(x): -14317.8105 D(G(z)): -16212.0498 / -16331.0117 Elapsed 0.32 s\n",
      "[10/25][43/63] Loss_D: nan Loss_G: nan D(x): -14285.9688 D(G(z)): -16330.5938 / -16339.6973 Elapsed 0.32 s\n",
      "[10/25][44/63] Loss_D: nan Loss_G: nan D(x): -14351.9639 D(G(z)): -16341.7334 / -16378.5635 Elapsed 0.32 s\n",
      "[10/25][45/63] Loss_D: nan Loss_G: nan D(x): -14336.5547 D(G(z)): -16390.3066 / -16415.4883 Elapsed 0.32 s\n",
      "[10/25][46/63] Loss_D: nan Loss_G: nan D(x): -14444.3389 D(G(z)): -16442.5449 / -16472.0312 Elapsed 0.33 s\n",
      "[10/25][47/63] Loss_D: nan Loss_G: nan D(x): -14420.4053 D(G(z)): -16419.5566 / -16521.2363 Elapsed 0.30 s\n",
      "[10/25][48/63] Loss_D: nan Loss_G: nan D(x): -14504.4189 D(G(z)): -16462.9434 / -16541.1016 Elapsed 0.30 s\n",
      "[10/25][49/63] Loss_D: nan Loss_G: nan D(x): -14457.3145 D(G(z)): -16512.0371 / -16563.1504 Elapsed 0.32 s\n",
      "[10/25][50/63] Loss_D: nan Loss_G: nan D(x): -14525.9658 D(G(z)): -16612.8398 / -16604.7773 Elapsed 0.32 s\n",
      "[10/25][51/63] Loss_D: nan Loss_G: nan D(x): -14538.2754 D(G(z)): -16588.6797 / -16756.7773 Elapsed 0.30 s\n",
      "[10/25][52/63] Loss_D: nan Loss_G: nan D(x): -14587.9863 D(G(z)): -16671.6934 / -16699.0898 Elapsed 0.30 s\n",
      "[10/25][53/63] Loss_D: nan Loss_G: nan D(x): -14591.7490 D(G(z)): -16664.7793 / -16718.9883 Elapsed 0.32 s\n",
      "[10/25][54/63] Loss_D: nan Loss_G: nan D(x): -14662.3975 D(G(z)): -16794.6719 / -16767.8555 Elapsed 0.30 s\n",
      "[10/25][55/63] Loss_D: nan Loss_G: nan D(x): -14740.8506 D(G(z)): -16807.4473 / -16866.5645 Elapsed 0.34 s\n",
      "[10/25][56/63] Loss_D: nan Loss_G: nan D(x): -14690.8770 D(G(z)): -16818.6855 / -16949.4766 Elapsed 0.32 s\n",
      "[10/25][57/63] Loss_D: nan Loss_G: nan D(x): -14847.1543 D(G(z)): -16878.9668 / -16864.4961 Elapsed 0.32 s\n",
      "[10/25][58/63] Loss_D: nan Loss_G: nan D(x): -14765.8750 D(G(z)): -16984.8574 / -16997.9688 Elapsed 0.32 s\n",
      "[10/25][59/63] Loss_D: nan Loss_G: nan D(x): -14827.8389 D(G(z)): -17001.9668 / -17031.2637 Elapsed 0.32 s\n",
      "[10/25][60/63] Loss_D: nan Loss_G: nan D(x): -14982.6689 D(G(z)): -17029.5664 / -17053.6367 Elapsed 0.30 s\n",
      "[10/25][61/63] Loss_D: nan Loss_G: nan D(x): -15026.5879 D(G(z)): -17022.1250 / -17045.6270 Elapsed 0.30 s\n",
      "[10/25][62/63] Loss_D: nan Loss_G: nan D(x): -14975.8145 D(G(z)): -17138.0195 / -17172.7402 Elapsed 0.15 s\n",
      "[11/25][0/63] Loss_D: nan Loss_G: nan D(x): -15067.8770 D(G(z)): -17092.1562 / -17211.2969 Elapsed 0.30 s\n",
      "[11/25][1/63] Loss_D: nan Loss_G: nan D(x): -15172.8350 D(G(z)): -17203.7188 / -17213.8496 Elapsed 0.32 s\n",
      "[11/25][2/63] Loss_D: nan Loss_G: nan D(x): -15240.2988 D(G(z)): -17225.3887 / -17272.0293 Elapsed 0.34 s\n",
      "[11/25][3/63] Loss_D: nan Loss_G: nan D(x): -15051.1631 D(G(z)): -17300.3164 / -17275.0957 Elapsed 0.33 s\n",
      "[11/25][4/63] Loss_D: nan Loss_G: nan D(x): -15138.1436 D(G(z)): -17307.9141 / -17398.0918 Elapsed 0.28 s\n",
      "[11/25][5/63] Loss_D: nan Loss_G: nan D(x): -15216.0361 D(G(z)): -17372.1680 / -17375.5723 Elapsed 0.33 s\n",
      "[11/25][6/63] Loss_D: nan Loss_G: nan D(x): -15359.1201 D(G(z)): -17395.2754 / -17461.9023 Elapsed 0.32 s\n",
      "[11/25][7/63] Loss_D: nan Loss_G: nan D(x): -15294.9805 D(G(z)): -17412.2617 / -17494.7754 Elapsed 0.32 s\n",
      "[11/25][8/63] Loss_D: nan Loss_G: nan D(x): -15359.5889 D(G(z)): -17506.3750 / -17527.0078 Elapsed 0.30 s\n",
      "[11/25][9/63] Loss_D: nan Loss_G: nan D(x): -15424.9346 D(G(z)): -17573.3828 / -17496.0742 Elapsed 0.34 s\n",
      "[11/25][10/63] Loss_D: nan Loss_G: nan D(x): -15333.2520 D(G(z)): -17562.5742 / -17560.1504 Elapsed 0.30 s\n",
      "[11/25][11/63] Loss_D: nan Loss_G: nan D(x): -15568.9580 D(G(z)): -17615.0430 / -17656.1641 Elapsed 0.32 s\n",
      "[11/25][12/63] Loss_D: nan Loss_G: nan D(x): -15432.6484 D(G(z)): -17628.0723 / -17671.0898 Elapsed 0.30 s\n",
      "[11/25][13/63] Loss_D: nan Loss_G: nan D(x): -15564.3115 D(G(z)): -17685.6914 / -17672.7949 Elapsed 0.34 s\n",
      "[11/25][14/63] Loss_D: nan Loss_G: nan D(x): -15554.9258 D(G(z)): -17714.5957 / -17796.4688 Elapsed 0.33 s\n",
      "[11/25][15/63] Loss_D: nan Loss_G: nan D(x): -15562.6885 D(G(z)): -17791.5391 / -17821.9570 Elapsed 0.33 s\n",
      "[11/25][16/63] Loss_D: nan Loss_G: nan D(x): -15615.3848 D(G(z)): -17906.8555 / -17902.3906 Elapsed 0.35 s\n",
      "[11/25][17/63] Loss_D: nan Loss_G: nan D(x): -15779.7539 D(G(z)): -17827.6562 / -17915.6699 Elapsed 0.33 s\n",
      "[11/25][18/63] Loss_D: nan Loss_G: nan D(x): -15691.1494 D(G(z)): -17834.8691 / -17967.9258 Elapsed 0.35 s\n",
      "[11/25][19/63] Loss_D: nan Loss_G: nan D(x): -15741.2432 D(G(z)): -17897.8555 / -18029.9551 Elapsed 0.33 s\n",
      "[11/25][20/63] Loss_D: nan Loss_G: nan D(x): -15693.4922 D(G(z)): -18046.0566 / -18025.4570 Elapsed 0.36 s\n",
      "[11/25][21/63] Loss_D: nan Loss_G: nan D(x): -15854.5088 D(G(z)): -18046.9043 / -18063.4980 Elapsed 0.35 s\n",
      "[11/25][22/63] Loss_D: nan Loss_G: nan D(x): -15810.7480 D(G(z)): -18073.3184 / -18157.6309 Elapsed 0.41 s\n",
      "[11/25][23/63] Loss_D: nan Loss_G: nan D(x): -15884.8389 D(G(z)): -18078.3516 / -18159.6758 Elapsed 0.36 s\n",
      "[11/25][24/63] Loss_D: nan Loss_G: nan D(x): -15769.0332 D(G(z)): -18145.9492 / -18195.6582 Elapsed 0.33 s\n",
      "[11/25][25/63] Loss_D: nan Loss_G: nan D(x): -16026.2139 D(G(z)): -18172.5410 / -18235.5508 Elapsed 0.33 s\n",
      "[11/25][26/63] Loss_D: nan Loss_G: nan D(x): -16055.2656 D(G(z)): -18229.8438 / -18317.0391 Elapsed 0.33 s\n",
      "[11/25][27/63] Loss_D: nan Loss_G: nan D(x): -16074.5527 D(G(z)): -18291.4668 / -18279.1562 Elapsed 0.36 s\n",
      "[11/25][28/63] Loss_D: nan Loss_G: nan D(x): -15993.4463 D(G(z)): -18324.5371 / -18388.5996 Elapsed 0.34 s\n",
      "[11/25][29/63] Loss_D: nan Loss_G: nan D(x): -16065.8203 D(G(z)): -18359.0391 / -18430.1191 Elapsed 0.34 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25][30/63] Loss_D: nan Loss_G: nan D(x): -16232.8750 D(G(z)): -18447.6680 / -18447.4668 Elapsed 0.34 s\n",
      "[11/25][31/63] Loss_D: nan Loss_G: nan D(x): -16223.5615 D(G(z)): -18426.8984 / -18459.5703 Elapsed 0.31 s\n",
      "[11/25][32/63] Loss_D: nan Loss_G: nan D(x): -16233.6123 D(G(z)): -18529.2676 / -18545.6543 Elapsed 0.32 s\n",
      "[11/25][33/63] Loss_D: nan Loss_G: nan D(x): -16352.4160 D(G(z)): -18534.0547 / -18589.3086 Elapsed 0.35 s\n",
      "[11/25][34/63] Loss_D: nan Loss_G: nan D(x): -16359.7178 D(G(z)): -18587.4766 / -18623.9082 Elapsed 0.36 s\n",
      "[11/25][35/63] Loss_D: nan Loss_G: nan D(x): -16370.4336 D(G(z)): -18636.3242 / -18694.5605 Elapsed 0.38 s\n",
      "[11/25][36/63] Loss_D: nan Loss_G: nan D(x): -16437.4473 D(G(z)): -18624.3945 / -18675.3438 Elapsed 0.37 s\n",
      "[11/25][37/63] Loss_D: nan Loss_G: nan D(x): -16414.5918 D(G(z)): -18704.3242 / -18724.3730 Elapsed 0.33 s\n",
      "[11/25][38/63] Loss_D: nan Loss_G: nan D(x): -16433.0645 D(G(z)): -18724.9336 / -18757.3867 Elapsed 0.35 s\n",
      "[11/25][39/63] Loss_D: nan Loss_G: nan D(x): -16535.5742 D(G(z)): -18834.5977 / -18875.9805 Elapsed 0.36 s\n",
      "[11/25][40/63] Loss_D: nan Loss_G: nan D(x): -16572.7383 D(G(z)): -18855.5859 / -18869.5820 Elapsed 0.33 s\n",
      "[11/25][41/63] Loss_D: nan Loss_G: nan D(x): -16642.4023 D(G(z)): -18850.8418 / -18900.0352 Elapsed 0.34 s\n",
      "[11/25][42/63] Loss_D: nan Loss_G: nan D(x): -16620.5195 D(G(z)): -18896.5156 / -18887.6602 Elapsed 0.35 s\n",
      "[11/25][43/63] Loss_D: nan Loss_G: nan D(x): -16635.1523 D(G(z)): -18962.1504 / -18952.1680 Elapsed 0.36 s\n",
      "[11/25][44/63] Loss_D: nan Loss_G: nan D(x): -16592.1465 D(G(z)): -18972.5078 / -19022.3848 Elapsed 0.33 s\n",
      "[11/25][45/63] Loss_D: nan Loss_G: nan D(x): -16729.2969 D(G(z)): -19039.9180 / -19030.8203 Elapsed 0.32 s\n",
      "[11/25][46/63] Loss_D: nan Loss_G: nan D(x): -16791.4648 D(G(z)): -19048.4824 / -19133.8105 Elapsed 0.32 s\n",
      "[11/25][47/63] Loss_D: nan Loss_G: nan D(x): -16804.1758 D(G(z)): -19109.8496 / -19177.8594 Elapsed 0.34 s\n",
      "[11/25][48/63] Loss_D: nan Loss_G: nan D(x): -16921.0449 D(G(z)): -19147.4844 / -19217.7461 Elapsed 0.33 s\n",
      "[11/25][49/63] Loss_D: nan Loss_G: nan D(x): -16832.4590 D(G(z)): -19153.3945 / -19248.3926 Elapsed 0.32 s\n",
      "[11/25][50/63] Loss_D: nan Loss_G: nan D(x): -16898.7656 D(G(z)): -19249.7812 / -19302.7988 Elapsed 0.34 s\n",
      "[11/25][51/63] Loss_D: nan Loss_G: nan D(x): -16981.4160 D(G(z)): -19323.1895 / -19346.3242 Elapsed 0.32 s\n",
      "[11/25][52/63] Loss_D: nan Loss_G: nan D(x): -17009.4043 D(G(z)): -19303.4844 / -19327.0430 Elapsed 0.32 s\n",
      "[11/25][53/63] Loss_D: nan Loss_G: nan D(x): -16988.7559 D(G(z)): -19313.1895 / -19409.4141 Elapsed 0.32 s\n",
      "[11/25][54/63] Loss_D: nan Loss_G: nan D(x): -16978.7363 D(G(z)): -19410.3711 / -19469.6348 Elapsed 0.32 s\n",
      "[11/25][55/63] Loss_D: nan Loss_G: nan D(x): -17182.7598 D(G(z)): -19439.8340 / -19487.0527 Elapsed 0.32 s\n",
      "[11/25][56/63] Loss_D: nan Loss_G: nan D(x): -17176.4375 D(G(z)): -19465.3730 / -19570.1719 Elapsed 0.31 s\n",
      "[11/25][57/63] Loss_D: nan Loss_G: nan D(x): -17109.4785 D(G(z)): -19535.3418 / -19515.5059 Elapsed 0.30 s\n",
      "[11/25][58/63] Loss_D: nan Loss_G: nan D(x): -17246.6543 D(G(z)): -19560.5957 / -19621.8008 Elapsed 0.29 s\n",
      "[11/25][59/63] Loss_D: nan Loss_G: nan D(x): -17128.8262 D(G(z)): -19621.2715 / -19641.9102 Elapsed 0.33 s\n",
      "[11/25][60/63] Loss_D: nan Loss_G: nan D(x): -17269.4629 D(G(z)): -19684.9746 / -19721.9668 Elapsed 0.34 s\n",
      "[11/25][61/63] Loss_D: nan Loss_G: nan D(x): -17226.0332 D(G(z)): -19706.6309 / -19759.3438 Elapsed 0.32 s\n",
      "[11/25][62/63] Loss_D: nan Loss_G: nan D(x): -17423.9082 D(G(z)): -19767.0566 / -19847.5527 Elapsed 0.19 s\n",
      "[12/25][0/63] Loss_D: nan Loss_G: nan D(x): -17301.4238 D(G(z)): -19830.1680 / -19856.7441 Elapsed 0.36 s\n",
      "[12/25][1/63] Loss_D: nan Loss_G: nan D(x): -17407.0391 D(G(z)): -19847.4277 / -19862.6016 Elapsed 0.35 s\n",
      "[12/25][2/63] Loss_D: nan Loss_G: nan D(x): -17446.6836 D(G(z)): -19903.4902 / -19928.1758 Elapsed 0.35 s\n",
      "[12/25][3/63] Loss_D: nan Loss_G: nan D(x): -17491.6562 D(G(z)): -19940.7031 / -19995.7012 Elapsed 0.37 s\n",
      "[12/25][4/63] Loss_D: nan Loss_G: nan D(x): -17586.2109 D(G(z)): -19933.8711 / -20018.6641 Elapsed 0.36 s\n",
      "[12/25][5/63] Loss_D: nan Loss_G: nan D(x): -17536.8652 D(G(z)): -19942.0332 / -20015.3242 Elapsed 0.32 s\n",
      "[12/25][6/63] Loss_D: nan Loss_G: nan D(x): -17644.1328 D(G(z)): -20044.4180 / -20118.5078 Elapsed 0.32 s\n",
      "[12/25][7/63] Loss_D: nan Loss_G: nan D(x): -17611.9707 D(G(z)): -20014.3301 / -20125.6797 Elapsed 0.33 s\n",
      "[12/25][8/63] Loss_D: nan Loss_G: nan D(x): -17587.1445 D(G(z)): -20079.1387 / -20131.0605 Elapsed 0.33 s\n",
      "[12/25][9/63] Loss_D: nan Loss_G: nan D(x): -17677.5547 D(G(z)): -20158.7285 / -20159.8906 Elapsed 0.30 s\n",
      "[12/25][10/63] Loss_D: nan Loss_G: nan D(x): -17761.9805 D(G(z)): -20241.7246 / -20268.7793 Elapsed 0.30 s\n",
      "[12/25][11/63] Loss_D: nan Loss_G: nan D(x): -17801.4688 D(G(z)): -20236.9180 / -20243.3125 Elapsed 0.30 s\n",
      "[12/25][12/63] Loss_D: nan Loss_G: nan D(x): -17898.3555 D(G(z)): -20300.3086 / -20385.4512 Elapsed 0.30 s\n",
      "[12/25][13/63] Loss_D: nan Loss_G: nan D(x): -17952.5586 D(G(z)): -20378.8809 / -20369.4785 Elapsed 0.30 s\n",
      "[12/25][14/63] Loss_D: nan Loss_G: nan D(x): -17891.4375 D(G(z)): -20327.2383 / -20417.9043 Elapsed 0.30 s\n",
      "[12/25][15/63] Loss_D: nan Loss_G: nan D(x): -17833.6211 D(G(z)): -20468.1211 / -20499.0703 Elapsed 0.30 s\n",
      "[12/25][16/63] Loss_D: nan Loss_G: nan D(x): -17938.0039 D(G(z)): -20474.8906 / -20499.4219 Elapsed 0.30 s\n",
      "[12/25][17/63] Loss_D: nan Loss_G: nan D(x): -18027.3164 D(G(z)): -20504.0312 / -20553.3926 Elapsed 0.30 s\n",
      "[12/25][18/63] Loss_D: nan Loss_G: nan D(x): -18031.2090 D(G(z)): -20552.7695 / -20570.0977 Elapsed 0.31 s\n",
      "[12/25][19/63] Loss_D: nan Loss_G: nan D(x): -17829.8457 D(G(z)): -20580.3750 / -20615.7227 Elapsed 0.31 s\n",
      "[12/25][20/63] Loss_D: nan Loss_G: nan D(x): -18078.5898 D(G(z)): -20658.4297 / -20672.2344 Elapsed 0.32 s\n",
      "[12/25][21/63] Loss_D: nan Loss_G: nan D(x): -18065.4023 D(G(z)): -20690.1582 / -20733.5391 Elapsed 0.30 s\n",
      "[12/25][22/63] Loss_D: nan Loss_G: nan D(x): -18254.7031 D(G(z)): -20680.8594 / -20756.8359 Elapsed 0.30 s\n",
      "[12/25][23/63] Loss_D: nan Loss_G: nan D(x): -18134.7871 D(G(z)): -20696.5195 / -20761.4160 Elapsed 0.32 s\n",
      "[12/25][24/63] Loss_D: nan Loss_G: nan D(x): -18325.8477 D(G(z)): -20749.0352 / -20875.2656 Elapsed 0.35 s\n",
      "[12/25][25/63] Loss_D: nan Loss_G: nan D(x): -18189.3438 D(G(z)): -20854.0371 / -20880.7422 Elapsed 0.33 s\n",
      "[12/25][26/63] Loss_D: nan Loss_G: nan D(x): -18236.0410 D(G(z)): -20836.5391 / -20900.8848 Elapsed 0.33 s\n",
      "[12/25][27/63] Loss_D: nan Loss_G: nan D(x): -18301.0273 D(G(z)): -20960.2012 / -20963.9902 Elapsed 0.34 s\n",
      "[12/25][28/63] Loss_D: nan Loss_G: nan D(x): -18335.3516 D(G(z)): -20921.4082 / -20972.3301 Elapsed 0.31 s\n",
      "[12/25][29/63] Loss_D: nan Loss_G: nan D(x): -18438.9062 D(G(z)): -21036.3809 / -21080.3555 Elapsed 0.32 s\n",
      "[12/25][30/63] Loss_D: nan Loss_G: nan D(x): -18452.3516 D(G(z)): -21043.8516 / -21136.8359 Elapsed 0.30 s\n",
      "[12/25][31/63] Loss_D: nan Loss_G: nan D(x): -18485.3926 D(G(z)): -21036.4277 / -21086.7246 Elapsed 0.32 s\n",
      "[12/25][32/63] Loss_D: nan Loss_G: nan D(x): -18525.5645 D(G(z)): -21138.0293 / -21125.9668 Elapsed 0.30 s\n",
      "[12/25][33/63] Loss_D: nan Loss_G: nan D(x): -18541.5059 D(G(z)): -21134.8691 / -21185.6094 Elapsed 0.30 s\n",
      "[12/25][34/63] Loss_D: nan Loss_G: nan D(x): -18567.5586 D(G(z)): -21190.0645 / -21313.5000 Elapsed 0.30 s\n",
      "[12/25][35/63] Loss_D: nan Loss_G: nan D(x): -18641.4355 D(G(z)): -21234.4316 / -21299.6953 Elapsed 0.30 s\n",
      "[12/25][36/63] Loss_D: nan Loss_G: nan D(x): -18669.1289 D(G(z)): -21267.7910 / -21305.5898 Elapsed 0.30 s\n",
      "[12/25][37/63] Loss_D: nan Loss_G: nan D(x): -18698.8984 D(G(z)): -21345.7539 / -21435.9004 Elapsed 0.32 s\n",
      "[12/25][38/63] Loss_D: nan Loss_G: nan D(x): -18807.9961 D(G(z)): -21397.2090 / -21412.9375 Elapsed 0.30 s\n",
      "[12/25][39/63] Loss_D: nan Loss_G: nan D(x): -18759.4160 D(G(z)): -21354.1016 / -21457.5508 Elapsed 0.30 s\n",
      "[12/25][40/63] Loss_D: nan Loss_G: nan D(x): -18836.8418 D(G(z)): -21474.3340 / -21479.6621 Elapsed 0.32 s\n",
      "[12/25][41/63] Loss_D: nan Loss_G: nan D(x): -18912.1270 D(G(z)): -21484.2207 / -21494.4727 Elapsed 0.30 s\n",
      "[12/25][42/63] Loss_D: nan Loss_G: nan D(x): -18994.5234 D(G(z)): -21436.1973 / -21589.7754 Elapsed 0.30 s\n",
      "[12/25][43/63] Loss_D: nan Loss_G: nan D(x): -18991.5449 D(G(z)): -21534.8770 / -21641.7891 Elapsed 0.32 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25][44/63] Loss_D: nan Loss_G: nan D(x): -18994.9902 D(G(z)): -21553.8535 / -21644.7285 Elapsed 0.30 s\n",
      "[12/25][45/63] Loss_D: nan Loss_G: nan D(x): -18971.1113 D(G(z)): -21609.4648 / -21720.2344 Elapsed 0.30 s\n",
      "[12/25][46/63] Loss_D: nan Loss_G: nan D(x): -19034.8047 D(G(z)): -21667.8281 / -21692.0977 Elapsed 0.30 s\n",
      "[12/25][47/63] Loss_D: nan Loss_G: nan D(x): -19191.9102 D(G(z)): -21717.3184 / -21792.1562 Elapsed 0.31 s\n",
      "[12/25][48/63] Loss_D: nan Loss_G: nan D(x): -19097.1797 D(G(z)): -21754.0801 / -21880.4844 Elapsed 0.30 s\n",
      "[12/25][49/63] Loss_D: nan Loss_G: nan D(x): -19002.6035 D(G(z)): -21811.0332 / -21778.3027 Elapsed 0.32 s\n",
      "[12/25][50/63] Loss_D: nan Loss_G: nan D(x): -19153.3574 D(G(z)): -21875.9707 / -21878.4336 Elapsed 0.30 s\n",
      "[12/25][51/63] Loss_D: nan Loss_G: nan D(x): -19120.8027 D(G(z)): -21867.2285 / -21922.2305 Elapsed 0.32 s\n",
      "[12/25][52/63] Loss_D: nan Loss_G: nan D(x): -19239.5098 D(G(z)): -21889.8496 / -21935.9668 Elapsed 0.32 s\n",
      "[12/25][53/63] Loss_D: nan Loss_G: nan D(x): -19316.9277 D(G(z)): -21922.1055 / -21978.2637 Elapsed 0.31 s\n",
      "[12/25][54/63] Loss_D: nan Loss_G: nan D(x): -19279.9160 D(G(z)): -22022.7461 / -21965.6934 Elapsed 0.30 s\n",
      "[12/25][55/63] Loss_D: nan Loss_G: nan D(x): -19469.8086 D(G(z)): -21994.0527 / -22000.1504 Elapsed 0.30 s\n",
      "[12/25][56/63] Loss_D: nan Loss_G: nan D(x): -19425.9062 D(G(z)): -22098.0820 / -22118.2148 Elapsed 0.30 s\n",
      "[12/25][57/63] Loss_D: nan Loss_G: nan D(x): -19516.8438 D(G(z)): -22126.9238 / -22152.3652 Elapsed 0.32 s\n",
      "[12/25][58/63] Loss_D: nan Loss_G: nan D(x): -19389.8242 D(G(z)): -22189.6055 / -22129.9043 Elapsed 0.32 s\n",
      "[12/25][59/63] Loss_D: nan Loss_G: nan D(x): -19714.3652 D(G(z)): -22150.8926 / -22270.5059 Elapsed 0.30 s\n",
      "[12/25][60/63] Loss_D: nan Loss_G: nan D(x): -19498.2852 D(G(z)): -22234.3984 / -22259.7930 Elapsed 0.32 s\n",
      "[12/25][61/63] Loss_D: nan Loss_G: nan D(x): -19493.7363 D(G(z)): -22231.2324 / -22353.7285 Elapsed 0.33 s\n",
      "[12/25][62/63] Loss_D: nan Loss_G: nan D(x): -19453.6504 D(G(z)): -22291.3945 / -22272.0293 Elapsed 0.20 s\n",
      "[13/25][0/63] Loss_D: nan Loss_G: nan D(x): -19547.2754 D(G(z)): -22315.1211 / -22406.8457 Elapsed 0.30 s\n",
      "[13/25][1/63] Loss_D: nan Loss_G: nan D(x): -19627.0918 D(G(z)): -22323.2930 / -22369.2266 Elapsed 0.32 s\n",
      "[13/25][2/63] Loss_D: nan Loss_G: nan D(x): -19671.9727 D(G(z)): -22449.9102 / -22450.9551 Elapsed 0.32 s\n",
      "[13/25][3/63] Loss_D: nan Loss_G: nan D(x): -19630.1250 D(G(z)): -22485.0312 / -22514.2363 Elapsed 0.32 s\n",
      "[13/25][4/63] Loss_D: nan Loss_G: nan D(x): -19808.8477 D(G(z)): -22519.3164 / -22599.6191 Elapsed 0.30 s\n",
      "[13/25][5/63] Loss_D: nan Loss_G: nan D(x): -19664.8477 D(G(z)): -22482.6152 / -22600.7031 Elapsed 0.32 s\n",
      "[13/25][6/63] Loss_D: nan Loss_G: nan D(x): -19739.4453 D(G(z)): -22565.3262 / -22612.9883 Elapsed 0.30 s\n",
      "[13/25][7/63] Loss_D: nan Loss_G: nan D(x): -19828.4082 D(G(z)): -22618.2402 / -22684.5254 Elapsed 0.32 s\n",
      "[13/25][8/63] Loss_D: nan Loss_G: nan D(x): -20018.7168 D(G(z)): -22685.0801 / -22738.3652 Elapsed 0.32 s\n",
      "[13/25][9/63] Loss_D: nan Loss_G: nan D(x): -19956.7305 D(G(z)): -22703.9434 / -22735.0781 Elapsed 0.30 s\n",
      "[13/25][10/63] Loss_D: nan Loss_G: nan D(x): -20025.3828 D(G(z)): -22776.2832 / -22760.1621 Elapsed 0.33 s\n",
      "[13/25][11/63] Loss_D: nan Loss_G: nan D(x): -20066.3281 D(G(z)): -22753.3398 / -22831.4707 Elapsed 0.32 s\n",
      "[13/25][12/63] Loss_D: nan Loss_G: nan D(x): -19971.8008 D(G(z)): -22812.9180 / -22872.1113 Elapsed 0.32 s\n",
      "[13/25][13/63] Loss_D: nan Loss_G: nan D(x): -20007.4219 D(G(z)): -22836.9980 / -23038.5898 Elapsed 0.31 s\n",
      "[13/25][14/63] Loss_D: nan Loss_G: nan D(x): -20162.3848 D(G(z)): -22898.4688 / -22869.8750 Elapsed 0.33 s\n",
      "[13/25][15/63] Loss_D: nan Loss_G: nan D(x): -20173.0391 D(G(z)): -22862.5508 / -22940.9375 Elapsed 0.32 s\n",
      "[13/25][16/63] Loss_D: nan Loss_G: nan D(x): -20296.4883 D(G(z)): -22949.9141 / -23023.5801 Elapsed 0.30 s\n",
      "[13/25][17/63] Loss_D: nan Loss_G: nan D(x): -20318.3965 D(G(z)): -22956.2656 / -23024.4883 Elapsed 0.32 s\n",
      "[13/25][18/63] Loss_D: nan Loss_G: nan D(x): -20218.0215 D(G(z)): -23014.6699 / -22992.6328 Elapsed 0.32 s\n",
      "[13/25][19/63] Loss_D: nan Loss_G: nan D(x): -20185.5430 D(G(z)): -23138.3340 / -23075.0352 Elapsed 0.35 s\n",
      "[13/25][20/63] Loss_D: nan Loss_G: nan D(x): -20322.9199 D(G(z)): -23100.7422 / -23188.8477 Elapsed 0.35 s\n",
      "[13/25][21/63] Loss_D: nan Loss_G: nan D(x): -20400.1367 D(G(z)): -23135.1328 / -23224.3320 Elapsed 0.32 s\n",
      "[13/25][22/63] Loss_D: nan Loss_G: nan D(x): -20378.5527 D(G(z)): -23179.2793 / -23359.7188 Elapsed 0.32 s\n",
      "[13/25][23/63] Loss_D: nan Loss_G: nan D(x): -20515.7832 D(G(z)): -23244.5098 / -23310.4570 Elapsed 0.32 s\n",
      "[13/25][24/63] Loss_D: nan Loss_G: nan D(x): -20463.9375 D(G(z)): -23323.8848 / -23299.0039 Elapsed 0.32 s\n",
      "[13/25][25/63] Loss_D: nan Loss_G: nan D(x): -20531.6016 D(G(z)): -23317.4297 / -23337.3828 Elapsed 0.30 s\n",
      "[13/25][26/63] Loss_D: nan Loss_G: nan D(x): -20485.9551 D(G(z)): -23285.3438 / -23403.0801 Elapsed 0.32 s\n",
      "[13/25][27/63] Loss_D: nan Loss_G: nan D(x): -20449.6992 D(G(z)): -23426.9551 / -23450.3906 Elapsed 0.32 s\n",
      "[13/25][28/63] Loss_D: nan Loss_G: nan D(x): -20512.6543 D(G(z)): -23379.5879 / -23471.1230 Elapsed 0.32 s\n",
      "[13/25][29/63] Loss_D: nan Loss_G: nan D(x): -20592.9766 D(G(z)): -23527.8594 / -23457.1914 Elapsed 0.30 s\n",
      "[13/25][30/63] Loss_D: nan Loss_G: nan D(x): -20555.7168 D(G(z)): -23516.8105 / -23473.6953 Elapsed 0.32 s\n",
      "[13/25][31/63] Loss_D: nan Loss_G: nan D(x): -20829.0371 D(G(z)): -23543.7852 / -23599.4023 Elapsed 0.32 s\n",
      "[13/25][32/63] Loss_D: nan Loss_G: nan D(x): -20618.9980 D(G(z)): -23571.2773 / -23605.2891 Elapsed 0.34 s\n",
      "[13/25][33/63] Loss_D: nan Loss_G: nan D(x): -20643.1602 D(G(z)): -23644.5020 / -23652.2227 Elapsed 0.32 s\n",
      "[13/25][34/63] Loss_D: nan Loss_G: nan D(x): -20799.5098 D(G(z)): -23627.2812 / -23725.7891 Elapsed 0.32 s\n",
      "[13/25][35/63] Loss_D: nan Loss_G: nan D(x): -20952.8340 D(G(z)): -23688.4629 / -23714.5684 Elapsed 0.32 s\n",
      "[13/25][36/63] Loss_D: nan Loss_G: nan D(x): -20794.9492 D(G(z)): -23711.3828 / -23799.2773 Elapsed 0.30 s\n",
      "[13/25][37/63] Loss_D: nan Loss_G: nan D(x): -20922.0488 D(G(z)): -23769.3398 / -23840.2695 Elapsed 0.30 s\n",
      "[13/25][38/63] Loss_D: nan Loss_G: nan D(x): -20761.1406 D(G(z)): -23849.9512 / -23845.0547 Elapsed 0.33 s\n",
      "[13/25][39/63] Loss_D: nan Loss_G: nan D(x): -20962.0508 D(G(z)): -23803.8008 / -23805.3242 Elapsed 0.32 s\n",
      "[13/25][40/63] Loss_D: nan Loss_G: nan D(x): -21054.0547 D(G(z)): -23901.8320 / -23906.5898 Elapsed 0.32 s\n",
      "[13/25][41/63] Loss_D: nan Loss_G: nan D(x): -21012.4824 D(G(z)): -23947.6582 / -23992.8457 Elapsed 0.32 s\n",
      "[13/25][42/63] Loss_D: nan Loss_G: nan D(x): -21090.4727 D(G(z)): -23972.8711 / -24045.7480 Elapsed 0.32 s\n",
      "[13/25][43/63] Loss_D: nan Loss_G: nan D(x): -21092.6895 D(G(z)): -23928.2754 / -24017.7793 Elapsed 0.33 s\n",
      "[13/25][44/63] Loss_D: nan Loss_G: nan D(x): -21141.0195 D(G(z)): -23968.5176 / -24052.6621 Elapsed 0.34 s\n",
      "[13/25][45/63] Loss_D: nan Loss_G: nan D(x): -21083.6914 D(G(z)): -24077.7539 / -24048.1289 Elapsed 0.32 s\n",
      "[13/25][46/63] Loss_D: nan Loss_G: nan D(x): -21147.8496 D(G(z)): -24086.2305 / -24162.6602 Elapsed 0.32 s\n",
      "[13/25][47/63] Loss_D: nan Loss_G: nan D(x): -21137.9902 D(G(z)): -24127.8691 / -24202.1016 Elapsed 0.30 s\n",
      "[13/25][48/63] Loss_D: nan Loss_G: nan D(x): -21203.5156 D(G(z)): -24182.1836 / -24205.2695 Elapsed 0.32 s\n",
      "[13/25][49/63] Loss_D: nan Loss_G: nan D(x): -21391.9219 D(G(z)): -24202.2227 / -24277.6582 Elapsed 0.30 s\n",
      "[13/25][50/63] Loss_D: nan Loss_G: nan D(x): -21309.6621 D(G(z)): -24288.0430 / -24342.2324 Elapsed 0.32 s\n",
      "[13/25][51/63] Loss_D: nan Loss_G: nan D(x): -21331.2617 D(G(z)): -24275.9277 / -24333.4316 Elapsed 0.32 s\n",
      "[13/25][52/63] Loss_D: nan Loss_G: nan D(x): -21351.8066 D(G(z)): -24300.3887 / -24367.0312 Elapsed 0.32 s\n",
      "[13/25][53/63] Loss_D: nan Loss_G: nan D(x): -21396.5352 D(G(z)): -24316.1504 / -24367.1680 Elapsed 0.32 s\n",
      "[13/25][54/63] Loss_D: nan Loss_G: nan D(x): -21463.2617 D(G(z)): -24398.6621 / -24439.0488 Elapsed 0.30 s\n",
      "[13/25][55/63] Loss_D: nan Loss_G: nan D(x): -21468.1758 D(G(z)): -24455.0586 / -24422.6719 Elapsed 0.32 s\n",
      "[13/25][56/63] Loss_D: nan Loss_G: nan D(x): -21536.5469 D(G(z)): -24502.2188 / -24530.1699 Elapsed 0.32 s\n",
      "[13/25][57/63] Loss_D: nan Loss_G: nan D(x): -21693.6465 D(G(z)): -24540.1738 / -24607.7305 Elapsed 0.30 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/25][58/63] Loss_D: nan Loss_G: nan D(x): -21658.2754 D(G(z)): -24524.1992 / -24541.8438 Elapsed 0.30 s\n",
      "[13/25][59/63] Loss_D: nan Loss_G: nan D(x): -21506.0508 D(G(z)): -24521.9961 / -24621.4336 Elapsed 0.30 s\n",
      "[13/25][60/63] Loss_D: nan Loss_G: nan D(x): -21607.3379 D(G(z)): -24688.7480 / -24624.1406 Elapsed 0.30 s\n",
      "[13/25][61/63] Loss_D: nan Loss_G: nan D(x): -21789.8926 D(G(z)): -24654.7754 / -24777.6758 Elapsed 0.32 s\n",
      "[13/25][62/63] Loss_D: nan Loss_G: nan D(x): -21876.9844 D(G(z)): -24715.5723 / -24777.8750 Elapsed 0.18 s\n",
      "[14/25][0/63] Loss_D: nan Loss_G: nan D(x): -21810.4531 D(G(z)): -24678.5898 / -24760.4180 Elapsed 0.32 s\n",
      "[14/25][1/63] Loss_D: nan Loss_G: nan D(x): -21691.4785 D(G(z)): -24734.0430 / -24746.2812 Elapsed 0.32 s\n",
      "[14/25][2/63] Loss_D: nan Loss_G: nan D(x): -21853.5664 D(G(z)): -24807.8594 / -24843.5879 Elapsed 0.30 s\n",
      "[14/25][3/63] Loss_D: nan Loss_G: nan D(x): -21722.5918 D(G(z)): -24786.4941 / -24839.7324 Elapsed 0.32 s\n",
      "[14/25][4/63] Loss_D: nan Loss_G: nan D(x): -21972.4238 D(G(z)): -24924.5410 / -24887.9414 Elapsed 0.32 s\n",
      "[14/25][5/63] Loss_D: nan Loss_G: nan D(x): -22036.6738 D(G(z)): -24898.4805 / -24951.2852 Elapsed 0.32 s\n",
      "[14/25][6/63] Loss_D: nan Loss_G: nan D(x): -21905.6738 D(G(z)): -24932.9121 / -24954.3848 Elapsed 0.32 s\n",
      "[14/25][7/63] Loss_D: nan Loss_G: nan D(x): -21910.6973 D(G(z)): -25000.1328 / -25041.0645 Elapsed 0.32 s\n",
      "[14/25][8/63] Loss_D: nan Loss_G: nan D(x): -21910.5039 D(G(z)): -24964.2422 / -25084.1816 Elapsed 0.32 s\n",
      "[14/25][9/63] Loss_D: nan Loss_G: nan D(x): -22089.0723 D(G(z)): -25094.9160 / -25039.5371 Elapsed 0.30 s\n",
      "[14/25][10/63] Loss_D: nan Loss_G: nan D(x): -22035.4141 D(G(z)): -25096.7383 / -25082.3242 Elapsed 0.33 s\n",
      "[14/25][11/63] Loss_D: nan Loss_G: nan D(x): -22028.9004 D(G(z)): -25167.1523 / -25114.7305 Elapsed 0.30 s\n",
      "[14/25][12/63] Loss_D: nan Loss_G: nan D(x): -22041.6934 D(G(z)): -25180.6797 / -25162.5801 Elapsed 0.30 s\n",
      "[14/25][13/63] Loss_D: nan Loss_G: nan D(x): -22161.2500 D(G(z)): -25237.5859 / -25202.9844 Elapsed 0.32 s\n",
      "[14/25][14/63] Loss_D: nan Loss_G: nan D(x): -22102.8262 D(G(z)): -25246.2754 / -25250.2852 Elapsed 0.30 s\n",
      "[14/25][15/63] Loss_D: nan Loss_G: nan D(x): -22117.6719 D(G(z)): -25183.3906 / -25297.5781 Elapsed 0.32 s\n",
      "[14/25][16/63] Loss_D: nan Loss_G: nan D(x): -22264.0508 D(G(z)): -25229.5781 / -25367.5039 Elapsed 0.32 s\n",
      "[14/25][17/63] Loss_D: nan Loss_G: nan D(x): -22129.3652 D(G(z)): -25375.9102 / -25302.4277 Elapsed 0.30 s\n",
      "[14/25][18/63] Loss_D: nan Loss_G: nan D(x): -22273.0273 D(G(z)): -25428.5195 / -25347.2148 Elapsed 0.29 s\n",
      "[14/25][19/63] Loss_D: nan Loss_G: nan D(x): -22310.6562 D(G(z)): -25431.7812 / -25386.1816 Elapsed 0.32 s\n",
      "[14/25][20/63] Loss_D: nan Loss_G: nan D(x): -22485.5332 D(G(z)): -25415.0781 / -25440.6680 Elapsed 0.32 s\n",
      "[14/25][21/63] Loss_D: nan Loss_G: nan D(x): -22521.2031 D(G(z)): -25471.1621 / -25421.6855 Elapsed 0.32 s\n",
      "[14/25][22/63] Loss_D: nan Loss_G: nan D(x): -22370.3262 D(G(z)): -25509.7520 / -25563.6113 Elapsed 0.30 s\n",
      "[14/25][23/63] Loss_D: nan Loss_G: nan D(x): -22549.6211 D(G(z)): -25524.8887 / -25497.4531 Elapsed 0.30 s\n",
      "[14/25][24/63] Loss_D: nan Loss_G: nan D(x): -22459.8594 D(G(z)): -25621.7656 / -25613.7773 Elapsed 0.31 s\n",
      "[14/25][25/63] Loss_D: nan Loss_G: nan D(x): -22499.9219 D(G(z)): -25624.2363 / -25630.2520 Elapsed 0.31 s\n",
      "[14/25][26/63] Loss_D: nan Loss_G: nan D(x): -22535.3418 D(G(z)): -25657.4082 / -25644.7598 Elapsed 0.30 s\n",
      "[14/25][27/63] Loss_D: nan Loss_G: nan D(x): -22590.5449 D(G(z)): -25662.8828 / -25721.5371 Elapsed 0.30 s\n",
      "[14/25][28/63] Loss_D: nan Loss_G: nan D(x): -22727.9492 D(G(z)): -25653.2441 / -25787.3828 Elapsed 0.30 s\n",
      "[14/25][29/63] Loss_D: nan Loss_G: nan D(x): -22595.1699 D(G(z)): -25715.4277 / -25803.9531 Elapsed 0.32 s\n",
      "[14/25][30/63] Loss_D: nan Loss_G: nan D(x): -22585.4102 D(G(z)): -25771.5430 / -25862.8223 Elapsed 0.32 s\n",
      "[14/25][31/63] Loss_D: nan Loss_G: nan D(x): -22741.5469 D(G(z)): -25814.4863 / -25820.2168 Elapsed 0.33 s\n",
      "[14/25][32/63] Loss_D: nan Loss_G: nan D(x): -22844.6777 D(G(z)): -25765.4941 / -25851.3789 Elapsed 0.30 s\n",
      "[14/25][33/63] Loss_D: nan Loss_G: nan D(x): -22770.1719 D(G(z)): -25829.0547 / -25941.8496 Elapsed 0.33 s\n",
      "[14/25][34/63] Loss_D: nan Loss_G: nan D(x): -22801.3438 D(G(z)): -25961.0898 / -25931.4902 Elapsed 0.34 s\n",
      "[14/25][35/63] Loss_D: nan Loss_G: nan D(x): -22691.9062 D(G(z)): -25910.4980 / -25893.7266 Elapsed 0.30 s\n",
      "[14/25][36/63] Loss_D: nan Loss_G: nan D(x): -22635.1035 D(G(z)): -25954.2168 / -25991.4277 Elapsed 0.32 s\n",
      "[14/25][37/63] Loss_D: nan Loss_G: nan D(x): -22875.7676 D(G(z)): -25983.5957 / -25987.8105 Elapsed 0.32 s\n",
      "[14/25][38/63] Loss_D: nan Loss_G: nan D(x): -22898.0605 D(G(z)): -26038.7500 / -26040.3496 Elapsed 0.32 s\n",
      "[14/25][39/63] Loss_D: nan Loss_G: nan D(x): -22919.3164 D(G(z)): -26098.0352 / -26072.3750 Elapsed 0.32 s\n",
      "[14/25][40/63] Loss_D: nan Loss_G: nan D(x): -22904.7812 D(G(z)): -26061.1602 / -26133.8086 Elapsed 0.32 s\n",
      "[14/25][41/63] Loss_D: nan Loss_G: nan D(x): -22989.2168 D(G(z)): -26094.3652 / -26149.8496 Elapsed 0.30 s\n",
      "[14/25][42/63] Loss_D: nan Loss_G: nan D(x): -22884.1035 D(G(z)): -26218.5293 / -26143.7344 Elapsed 0.30 s\n",
      "[14/25][43/63] Loss_D: nan Loss_G: nan D(x): -23217.5176 D(G(z)): -26225.7695 / -26225.4062 Elapsed 0.32 s\n",
      "[14/25][44/63] Loss_D: nan Loss_G: nan D(x): -23061.4004 D(G(z)): -26219.9707 / -26251.3105 Elapsed 0.30 s\n",
      "[14/25][45/63] Loss_D: nan Loss_G: nan D(x): -22989.6152 D(G(z)): -26228.3770 / -26279.2207 Elapsed 0.32 s\n",
      "[14/25][46/63] Loss_D: nan Loss_G: nan D(x): -23140.2559 D(G(z)): -26302.5391 / -26335.9551 Elapsed 0.32 s\n",
      "[14/25][47/63] Loss_D: nan Loss_G: nan D(x): -23112.2852 D(G(z)): -26264.1582 / -26316.2500 Elapsed 0.32 s\n",
      "[14/25][48/63] Loss_D: nan Loss_G: nan D(x): -23210.5684 D(G(z)): -26301.6289 / -26363.9902 Elapsed 0.34 s\n",
      "[14/25][49/63] Loss_D: nan Loss_G: nan D(x): -23157.1250 D(G(z)): -26340.2402 / -26449.6641 Elapsed 0.34 s\n",
      "[14/25][50/63] Loss_D: nan Loss_G: nan D(x): -23253.0195 D(G(z)): -26407.2617 / -26460.5410 Elapsed 0.31 s\n",
      "[14/25][51/63] Loss_D: nan Loss_G: nan D(x): -23242.7344 D(G(z)): -26430.9746 / -26566.6367 Elapsed 0.32 s\n",
      "[14/25][52/63] Loss_D: nan Loss_G: nan D(x): -23348.0469 D(G(z)): -26508.3555 / -26540.8848 Elapsed 0.32 s\n",
      "[14/25][53/63] Loss_D: nan Loss_G: nan D(x): -23304.3223 D(G(z)): -26507.1855 / -26452.8633 Elapsed 0.32 s\n",
      "[14/25][54/63] Loss_D: nan Loss_G: nan D(x): -23401.6289 D(G(z)): -26524.8945 / -26647.4746 Elapsed 0.32 s\n",
      "[14/25][55/63] Loss_D: nan Loss_G: nan D(x): -23315.8164 D(G(z)): -26605.9668 / -26531.3730 Elapsed 0.33 s\n",
      "[14/25][56/63] Loss_D: nan Loss_G: nan D(x): -23337.6699 D(G(z)): -26543.5762 / -26676.3359 Elapsed 0.32 s\n",
      "[14/25][57/63] Loss_D: nan Loss_G: nan D(x): -23501.7305 D(G(z)): -26726.2793 / -26649.2031 Elapsed 0.32 s\n",
      "[14/25][58/63] Loss_D: nan Loss_G: nan D(x): -23522.5410 D(G(z)): -26735.9219 / -26718.0234 Elapsed 0.30 s\n",
      "[14/25][59/63] Loss_D: nan Loss_G: nan D(x): -23410.9180 D(G(z)): -26735.2012 / -26769.4219 Elapsed 0.30 s\n",
      "[14/25][60/63] Loss_D: nan Loss_G: nan D(x): -23427.7617 D(G(z)): -26740.5195 / -26799.4023 Elapsed 0.30 s\n",
      "[14/25][61/63] Loss_D: nan Loss_G: nan D(x): -23572.0195 D(G(z)): -26806.8164 / -26759.2207 Elapsed 0.30 s\n",
      "[14/25][62/63] Loss_D: nan Loss_G: nan D(x): -23628.0547 D(G(z)): -26686.4453 / -26878.8281 Elapsed 0.17 s\n",
      "[15/25][0/63] Loss_D: nan Loss_G: nan D(x): -23442.3594 D(G(z)): -26789.1621 / -26864.8418 Elapsed 0.34 s\n",
      "[15/25][1/63] Loss_D: nan Loss_G: nan D(x): -23519.2988 D(G(z)): -26919.4883 / -26819.1699 Elapsed 0.32 s\n",
      "[15/25][2/63] Loss_D: nan Loss_G: nan D(x): -23617.8887 D(G(z)): -26902.2480 / -26851.9004 Elapsed 0.32 s\n",
      "[15/25][3/63] Loss_D: nan Loss_G: nan D(x): -23604.5215 D(G(z)): -26889.1172 / -27009.2500 Elapsed 0.29 s\n",
      "[15/25][4/63] Loss_D: nan Loss_G: nan D(x): -23664.0176 D(G(z)): -26980.0254 / -26991.8809 Elapsed 0.30 s\n",
      "[15/25][5/63] Loss_D: nan Loss_G: nan D(x): -23623.2656 D(G(z)): -26981.0820 / -27010.4316 Elapsed 0.32 s\n",
      "[15/25][6/63] Loss_D: nan Loss_G: nan D(x): -23608.2344 D(G(z)): -27038.1699 / -27013.9844 Elapsed 0.30 s\n",
      "[15/25][7/63] Loss_D: nan Loss_G: nan D(x): -23896.4355 D(G(z)): -26994.1562 / -27079.4590 Elapsed 0.30 s\n",
      "[15/25][8/63] Loss_D: nan Loss_G: nan D(x): -23828.5078 D(G(z)): -27038.1562 / -27103.6797 Elapsed 0.30 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/25][9/63] Loss_D: nan Loss_G: nan D(x): -23872.9199 D(G(z)): -27120.8906 / -27114.2715 Elapsed 0.30 s\n",
      "[15/25][10/63] Loss_D: nan Loss_G: nan D(x): -23839.4453 D(G(z)): -27127.2949 / -27127.8594 Elapsed 0.30 s\n",
      "[15/25][11/63] Loss_D: nan Loss_G: nan D(x): -23809.3496 D(G(z)): -27203.6816 / -27164.3418 Elapsed 0.30 s\n",
      "[15/25][12/63] Loss_D: nan Loss_G: nan D(x): -23787.9531 D(G(z)): -27193.0664 / -27237.8320 Elapsed 0.30 s\n",
      "[15/25][13/63] Loss_D: nan Loss_G: nan D(x): -24010.1816 D(G(z)): -27249.7031 / -27219.0391 Elapsed 0.32 s\n",
      "[15/25][14/63] Loss_D: nan Loss_G: nan D(x): -23963.2520 D(G(z)): -27371.9473 / -27126.9883 Elapsed 0.32 s\n",
      "[15/25][15/63] Loss_D: nan Loss_G: nan D(x): -24042.9414 D(G(z)): -27345.4844 / -27241.5059 Elapsed 0.32 s\n",
      "[15/25][16/63] Loss_D: nan Loss_G: nan D(x): -24014.9277 D(G(z)): -27281.0977 / -27288.6680 Elapsed 0.30 s\n",
      "[15/25][17/63] Loss_D: nan Loss_G: nan D(x): -24077.8281 D(G(z)): -27336.9023 / -27399.5156 Elapsed 0.32 s\n",
      "[15/25][18/63] Loss_D: nan Loss_G: nan D(x): -24070.3398 D(G(z)): -27322.3613 / -27434.5430 Elapsed 0.30 s\n",
      "[15/25][19/63] Loss_D: nan Loss_G: nan D(x): -24093.6836 D(G(z)): -27482.6992 / -27445.3164 Elapsed 0.34 s\n",
      "[15/25][20/63] Loss_D: nan Loss_G: nan D(x): -24159.6641 D(G(z)): -27417.6270 / -27434.7090 Elapsed 0.32 s\n",
      "[15/25][21/63] Loss_D: nan Loss_G: nan D(x): -24124.7559 D(G(z)): -27388.1211 / -27482.2266 Elapsed 0.34 s\n",
      "[15/25][22/63] Loss_D: nan Loss_G: nan D(x): -24107.8203 D(G(z)): -27478.9004 / -27555.1113 Elapsed 0.32 s\n",
      "[15/25][23/63] Loss_D: nan Loss_G: nan D(x): -24137.1367 D(G(z)): -27565.9629 / -27602.2109 Elapsed 0.34 s\n",
      "[15/25][24/63] Loss_D: nan Loss_G: nan D(x): -24081.7793 D(G(z)): -27550.7461 / -27626.8828 Elapsed 0.31 s\n",
      "[15/25][25/63] Loss_D: nan Loss_G: nan D(x): -24066.8086 D(G(z)): -27625.4590 / -27580.8086 Elapsed 0.33 s\n",
      "[15/25][26/63] Loss_D: nan Loss_G: nan D(x): -24260.6211 D(G(z)): -27555.7520 / -27619.2832 Elapsed 0.32 s\n",
      "[15/25][27/63] Loss_D: nan Loss_G: nan D(x): -24202.5859 D(G(z)): -27618.5430 / -27598.2246 Elapsed 0.32 s\n",
      "[15/25][28/63] Loss_D: nan Loss_G: nan D(x): -24177.5996 D(G(z)): -27707.5996 / -27716.4551 Elapsed 0.32 s\n",
      "[15/25][29/63] Loss_D: nan Loss_G: nan D(x): -24416.1680 D(G(z)): -27694.8262 / -27716.4473 Elapsed 0.32 s\n",
      "[15/25][30/63] Loss_D: nan Loss_G: nan D(x): -24278.4922 D(G(z)): -27712.6211 / -27716.8027 Elapsed 0.32 s\n",
      "[15/25][31/63] Loss_D: nan Loss_G: nan D(x): -24330.2656 D(G(z)): -27679.0957 / -27790.2930 Elapsed 0.34 s\n",
      "[15/25][32/63] Loss_D: nan Loss_G: nan D(x): -24373.9609 D(G(z)): -27785.4883 / -27877.7520 Elapsed 0.33 s\n",
      "[15/25][33/63] Loss_D: nan Loss_G: nan D(x): -24461.6543 D(G(z)): -27787.8438 / -27878.5957 Elapsed 0.32 s\n",
      "[15/25][34/63] Loss_D: nan Loss_G: nan D(x): -24345.8438 D(G(z)): -27861.6504 / -27806.9512 Elapsed 0.32 s\n",
      "[15/25][35/63] Loss_D: nan Loss_G: nan D(x): -24447.2988 D(G(z)): -27857.0312 / -27935.0664 Elapsed 0.32 s\n",
      "[15/25][36/63] Loss_D: nan Loss_G: nan D(x): -24583.0059 D(G(z)): -27918.7676 / -27886.0430 Elapsed 0.32 s\n",
      "[15/25][37/63] Loss_D: nan Loss_G: nan D(x): -24373.7852 D(G(z)): -27870.8945 / -28022.9219 Elapsed 0.32 s\n",
      "[15/25][38/63] Loss_D: nan Loss_G: nan D(x): -24556.5918 D(G(z)): -27891.5703 / -27981.7109 Elapsed 0.30 s\n",
      "[15/25][39/63] Loss_D: nan Loss_G: nan D(x): -24649.7266 D(G(z)): -27989.5742 / -28088.3066 Elapsed 0.30 s\n",
      "[15/25][40/63] Loss_D: nan Loss_G: nan D(x): -24682.6309 D(G(z)): -28049.0234 / -28058.0430 Elapsed 0.30 s\n",
      "[15/25][41/63] Loss_D: nan Loss_G: nan D(x): -24624.7402 D(G(z)): -28013.7754 / -28100.5059 Elapsed 0.30 s\n",
      "[15/25][42/63] Loss_D: nan Loss_G: nan D(x): -24692.1289 D(G(z)): -28081.9688 / -28049.6758 Elapsed 0.32 s\n",
      "[15/25][43/63] Loss_D: nan Loss_G: nan D(x): -24544.1699 D(G(z)): -28030.7734 / -28077.7031 Elapsed 0.32 s\n",
      "[15/25][44/63] Loss_D: nan Loss_G: nan D(x): -24758.2363 D(G(z)): -28155.6133 / -28193.4160 Elapsed 0.32 s\n",
      "[15/25][45/63] Loss_D: nan Loss_G: nan D(x): -24802.6250 D(G(z)): -28078.4922 / -28166.1777 Elapsed 0.31 s\n",
      "[15/25][46/63] Loss_D: nan Loss_G: nan D(x): -24856.7129 D(G(z)): -28130.9004 / -28130.1504 Elapsed 0.31 s\n",
      "[15/25][47/63] Loss_D: nan Loss_G: nan D(x): -24696.8906 D(G(z)): -28188.9648 / -28130.8750 Elapsed 0.30 s\n",
      "[15/25][48/63] Loss_D: nan Loss_G: nan D(x): -24644.7129 D(G(z)): -28209.4883 / -28240.8613 Elapsed 0.32 s\n",
      "[15/25][49/63] Loss_D: nan Loss_G: nan D(x): -24815.8574 D(G(z)): -28284.4492 / -28291.8828 Elapsed 0.30 s\n",
      "[15/25][50/63] Loss_D: nan Loss_G: nan D(x): -24890.9219 D(G(z)): -28282.4023 / -28223.9746 Elapsed 0.30 s\n",
      "[15/25][51/63] Loss_D: nan Loss_G: nan D(x): -24870.3359 D(G(z)): -28312.9492 / -28330.6562 Elapsed 0.30 s\n",
      "[15/25][52/63] Loss_D: nan Loss_G: nan D(x): -24915.8633 D(G(z)): -28305.4551 / -28434.0117 Elapsed 0.30 s\n",
      "[15/25][53/63] Loss_D: nan Loss_G: nan D(x): -24957.1973 D(G(z)): -28438.4316 / -28374.0312 Elapsed 0.32 s\n",
      "[15/25][54/63] Loss_D: nan Loss_G: nan D(x): -24726.2734 D(G(z)): -28348.2422 / -28375.1992 Elapsed 0.30 s\n",
      "[15/25][55/63] Loss_D: nan Loss_G: nan D(x): -24925.5820 D(G(z)): -28348.6426 / -28477.6719 Elapsed 0.33 s\n",
      "[15/25][56/63] Loss_D: nan Loss_G: nan D(x): -24918.4453 D(G(z)): -28394.7598 / -28404.8535 Elapsed 0.31 s\n",
      "[15/25][57/63] Loss_D: nan Loss_G: nan D(x): -25046.1094 D(G(z)): -28378.3887 / -28503.3691 Elapsed 0.34 s\n",
      "[15/25][58/63] Loss_D: nan Loss_G: nan D(x): -24954.7012 D(G(z)): -28541.0312 / -28510.3945 Elapsed 0.32 s\n",
      "[15/25][59/63] Loss_D: nan Loss_G: nan D(x): -25055.4902 D(G(z)): -28540.0195 / -28500.0625 Elapsed 0.32 s\n",
      "[15/25][60/63] Loss_D: nan Loss_G: nan D(x): -25194.3105 D(G(z)): -28559.8105 / -28643.2578 Elapsed 0.32 s\n",
      "[15/25][61/63] Loss_D: nan Loss_G: nan D(x): -25077.8105 D(G(z)): -28557.8770 / -28645.1094 Elapsed 0.30 s\n",
      "[15/25][62/63] Loss_D: nan Loss_G: nan D(x): -25130.7227 D(G(z)): -28580.0254 / -28693.1777 Elapsed 0.16 s\n",
      "[16/25][0/63] Loss_D: nan Loss_G: nan D(x): -25234.0215 D(G(z)): -28536.7305 / -28617.8184 Elapsed 0.33 s\n",
      "[16/25][1/63] Loss_D: nan Loss_G: nan D(x): -25270.5684 D(G(z)): -28675.6191 / -28629.5723 Elapsed 0.30 s\n",
      "[16/25][2/63] Loss_D: nan Loss_G: nan D(x): -25172.8398 D(G(z)): -28638.7266 / -28680.3926 Elapsed 0.33 s\n",
      "[16/25][3/63] Loss_D: nan Loss_G: nan D(x): -25148.1895 D(G(z)): -28709.9824 / -28675.9238 Elapsed 0.32 s\n",
      "[16/25][4/63] Loss_D: nan Loss_G: nan D(x): -25269.5840 D(G(z)): -28718.3906 / -28725.9434 Elapsed 0.32 s\n",
      "[16/25][5/63] Loss_D: nan Loss_G: nan D(x): -25162.2012 D(G(z)): -28684.2246 / -28786.9922 Elapsed 0.33 s\n",
      "[16/25][6/63] Loss_D: nan Loss_G: nan D(x): -25312.4551 D(G(z)): -28828.9141 / -28807.3340 Elapsed 0.30 s\n",
      "[16/25][7/63] Loss_D: nan Loss_G: nan D(x): -25265.0762 D(G(z)): -28844.9219 / -28812.2402 Elapsed 0.30 s\n",
      "[16/25][8/63] Loss_D: nan Loss_G: nan D(x): -25270.0820 D(G(z)): -28785.6094 / -28930.7754 Elapsed 0.30 s\n",
      "[16/25][9/63] Loss_D: nan Loss_G: nan D(x): -25311.9629 D(G(z)): -28752.7168 / -28777.8242 Elapsed 0.32 s\n",
      "[16/25][10/63] Loss_D: nan Loss_G: nan D(x): -25470.5254 D(G(z)): -28852.2188 / -28885.8770 Elapsed 0.32 s\n",
      "[16/25][11/63] Loss_D: nan Loss_G: nan D(x): -25584.5527 D(G(z)): -28922.6348 / -28938.3008 Elapsed 0.32 s\n",
      "[16/25][12/63] Loss_D: nan Loss_G: nan D(x): -25339.2637 D(G(z)): -28919.0957 / -28968.6211 Elapsed 0.30 s\n",
      "[16/25][13/63] Loss_D: nan Loss_G: nan D(x): -25444.9902 D(G(z)): -28886.9922 / -28985.6191 Elapsed 0.32 s\n",
      "[16/25][14/63] Loss_D: nan Loss_G: nan D(x): -25501.2363 D(G(z)): -29002.9258 / -28983.9688 Elapsed 0.32 s\n",
      "[16/25][15/63] Loss_D: nan Loss_G: nan D(x): -25456.5547 D(G(z)): -29029.0293 / -28927.1406 Elapsed 0.32 s\n",
      "[16/25][16/63] Loss_D: nan Loss_G: nan D(x): -25409.2949 D(G(z)): -28986.2773 / -28948.2070 Elapsed 0.33 s\n",
      "[16/25][17/63] Loss_D: nan Loss_G: nan D(x): -25462.2539 D(G(z)): -28857.3340 / -29011.8281 Elapsed 0.32 s\n",
      "[16/25][18/63] Loss_D: nan Loss_G: nan D(x): -25552.5332 D(G(z)): -28966.4668 / -29169.4219 Elapsed 0.32 s\n",
      "[16/25][19/63] Loss_D: nan Loss_G: nan D(x): -25576.2988 D(G(z)): -29035.3867 / -29066.7305 Elapsed 0.30 s\n",
      "[16/25][20/63] Loss_D: nan Loss_G: nan D(x): -25676.8086 D(G(z)): -29039.2227 / -29056.9375 Elapsed 0.30 s\n",
      "[16/25][21/63] Loss_D: nan Loss_G: nan D(x): -25585.3770 D(G(z)): -29063.5918 / -29119.4277 Elapsed 0.32 s\n",
      "[16/25][22/63] Loss_D: nan Loss_G: nan D(x): -25526.4414 D(G(z)): -29047.9160 / -29146.6406 Elapsed 0.32 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/25][23/63] Loss_D: nan Loss_G: nan D(x): -25707.3594 D(G(z)): -29137.1836 / -29192.4668 Elapsed 0.32 s\n",
      "[16/25][24/63] Loss_D: nan Loss_G: nan D(x): -25461.1719 D(G(z)): -29130.8652 / -29162.7773 Elapsed 0.33 s\n",
      "[16/25][25/63] Loss_D: nan Loss_G: nan D(x): -25625.7344 D(G(z)): -29125.3047 / -29241.1934 Elapsed 0.33 s\n",
      "[16/25][26/63] Loss_D: nan Loss_G: nan D(x): -25670.3906 D(G(z)): -29216.8281 / -29229.1621 Elapsed 0.32 s\n",
      "[16/25][27/63] Loss_D: nan Loss_G: nan D(x): -25711.9473 D(G(z)): -29190.4355 / -29295.8242 Elapsed 0.32 s\n",
      "[16/25][28/63] Loss_D: nan Loss_G: nan D(x): -25806.1914 D(G(z)): -29230.2891 / -29288.0312 Elapsed 0.32 s\n",
      "[16/25][29/63] Loss_D: nan Loss_G: nan D(x): -25701.7832 D(G(z)): -29286.9902 / -29310.2324 Elapsed 0.32 s\n",
      "[16/25][30/63] Loss_D: nan Loss_G: nan D(x): -25765.4551 D(G(z)): -29305.6777 / -29304.7109 Elapsed 0.30 s\n",
      "[16/25][31/63] Loss_D: nan Loss_G: nan D(x): -25786.4043 D(G(z)): -29230.5586 / -29304.7754 Elapsed 0.32 s\n",
      "[16/25][32/63] Loss_D: nan Loss_G: nan D(x): -25822.2383 D(G(z)): -29265.6367 / -29427.4316 Elapsed 0.32 s\n",
      "[16/25][33/63] Loss_D: nan Loss_G: nan D(x): -25873.0879 D(G(z)): -29334.8320 / -29344.1484 Elapsed 0.32 s\n",
      "[16/25][34/63] Loss_D: nan Loss_G: nan D(x): -25770.5977 D(G(z)): -29413.0957 / -29374.0352 Elapsed 0.33 s\n",
      "[16/25][35/63] Loss_D: nan Loss_G: nan D(x): -25862.7305 D(G(z)): -29373.8945 / -29460.3574 Elapsed 0.33 s\n",
      "[16/25][36/63] Loss_D: nan Loss_G: nan D(x): -25768.6406 D(G(z)): -29462.2148 / -29414.0762 Elapsed 0.31 s\n",
      "[16/25][37/63] Loss_D: nan Loss_G: nan D(x): -25853.0664 D(G(z)): -29476.6191 / -29447.9668 Elapsed 0.30 s\n",
      "[16/25][38/63] Loss_D: nan Loss_G: nan D(x): -25927.0898 D(G(z)): -29528.3652 / -29521.9043 Elapsed 0.32 s\n",
      "[16/25][39/63] Loss_D: nan Loss_G: nan D(x): -25872.9160 D(G(z)): -29516.9414 / -29484.2754 Elapsed 0.32 s\n",
      "[16/25][40/63] Loss_D: nan Loss_G: nan D(x): -26125.8223 D(G(z)): -29591.4219 / -29448.8086 Elapsed 0.32 s\n",
      "[16/25][41/63] Loss_D: nan Loss_G: nan D(x): -25994.1699 D(G(z)): -29547.3203 / -29572.4004 Elapsed 0.30 s\n",
      "[16/25][42/63] Loss_D: nan Loss_G: nan D(x): -26056.4180 D(G(z)): -29507.7891 / -29545.7695 Elapsed 0.32 s\n",
      "[16/25][43/63] Loss_D: nan Loss_G: nan D(x): -26022.9023 D(G(z)): -29647.9629 / -29528.0977 Elapsed 0.32 s\n",
      "[16/25][44/63] Loss_D: nan Loss_G: nan D(x): -26030.9219 D(G(z)): -29630.0879 / -29647.1992 Elapsed 0.31 s\n",
      "[16/25][45/63] Loss_D: nan Loss_G: nan D(x): -26249.8574 D(G(z)): -29556.6211 / -29578.9004 Elapsed 0.32 s\n",
      "[16/25][46/63] Loss_D: nan Loss_G: nan D(x): -26072.1777 D(G(z)): -29607.4141 / -29639.0645 Elapsed 0.30 s\n",
      "[16/25][47/63] Loss_D: nan Loss_G: nan D(x): -26139.8145 D(G(z)): -29714.5508 / -29664.3125 Elapsed 0.32 s\n",
      "[16/25][48/63] Loss_D: nan Loss_G: nan D(x): -26151.0957 D(G(z)): -29641.9902 / -29689.8809 Elapsed 0.32 s\n",
      "[16/25][49/63] Loss_D: nan Loss_G: nan D(x): -26108.5879 D(G(z)): -29706.4902 / -29707.4922 Elapsed 0.30 s\n",
      "[16/25][50/63] Loss_D: nan Loss_G: nan D(x): -26070.4707 D(G(z)): -29668.2344 / -29689.6133 Elapsed 0.32 s\n",
      "[16/25][51/63] Loss_D: nan Loss_G: nan D(x): -26086.1777 D(G(z)): -29654.1055 / -29755.8418 Elapsed 0.32 s\n",
      "[16/25][52/63] Loss_D: nan Loss_G: nan D(x): -26178.0762 D(G(z)): -29723.5762 / -29813.0566 Elapsed 0.30 s\n",
      "[16/25][53/63] Loss_D: nan Loss_G: nan D(x): -26239.4844 D(G(z)): -29756.4980 / -29711.0645 Elapsed 0.30 s\n",
      "[16/25][54/63] Loss_D: nan Loss_G: nan D(x): -26152.4551 D(G(z)): -29739.7773 / -29813.6133 Elapsed 0.30 s\n",
      "[16/25][55/63] Loss_D: nan Loss_G: nan D(x): -26188.9277 D(G(z)): -29859.9551 / -29833.2715 Elapsed 0.32 s\n",
      "[16/25][56/63] Loss_D: nan Loss_G: nan D(x): -26232.9102 D(G(z)): -29785.5684 / -29842.0332 Elapsed 0.30 s\n",
      "[16/25][57/63] Loss_D: nan Loss_G: nan D(x): -26269.6621 D(G(z)): -29815.4180 / -29820.6758 Elapsed 0.30 s\n",
      "[16/25][58/63] Loss_D: nan Loss_G: nan D(x): -26167.7383 D(G(z)): -29887.3965 / -29851.9336 Elapsed 0.32 s\n",
      "[16/25][59/63] Loss_D: nan Loss_G: nan D(x): -26210.5547 D(G(z)): -29892.6992 / -29906.9961 Elapsed 0.32 s\n",
      "[16/25][60/63] Loss_D: nan Loss_G: nan D(x): -26323.3184 D(G(z)): -29979.7539 / -29902.9902 Elapsed 0.32 s\n",
      "[16/25][61/63] Loss_D: nan Loss_G: nan D(x): -26238.5059 D(G(z)): -29924.1094 / -29932.0781 Elapsed 0.32 s\n",
      "[16/25][62/63] Loss_D: nan Loss_G: nan D(x): -26299.9688 D(G(z)): -30027.7930 / -29925.0664 Elapsed 0.16 s\n",
      "[17/25][0/63] Loss_D: nan Loss_G: nan D(x): -26365.0820 D(G(z)): -29947.3184 / -29963.0234 Elapsed 0.33 s\n",
      "[17/25][1/63] Loss_D: nan Loss_G: nan D(x): -26210.5957 D(G(z)): -29937.6602 / -30020.2539 Elapsed 0.32 s\n",
      "[17/25][2/63] Loss_D: nan Loss_G: nan D(x): -26247.8047 D(G(z)): -29964.9531 / -29979.0352 Elapsed 0.30 s\n",
      "[17/25][3/63] Loss_D: nan Loss_G: nan D(x): -26403.3145 D(G(z)): -30080.6562 / -30004.9316 Elapsed 0.30 s\n",
      "[17/25][4/63] Loss_D: nan Loss_G: nan D(x): -26385.9863 D(G(z)): -29975.2656 / -30013.8633 Elapsed 0.30 s\n",
      "[17/25][5/63] Loss_D: nan Loss_G: nan D(x): -26491.9785 D(G(z)): -29983.9297 / -30056.1973 Elapsed 0.32 s\n",
      "[17/25][6/63] Loss_D: nan Loss_G: nan D(x): -26421.7383 D(G(z)): -30106.9648 / -30015.6992 Elapsed 0.32 s\n",
      "[17/25][7/63] Loss_D: nan Loss_G: nan D(x): -26288.0449 D(G(z)): -30058.1172 / -30072.4258 Elapsed 0.32 s\n",
      "[17/25][8/63] Loss_D: nan Loss_G: nan D(x): -26582.6074 D(G(z)): -30037.0254 / -30149.6230 Elapsed 0.32 s\n",
      "[17/25][9/63] Loss_D: nan Loss_G: nan D(x): -26464.7246 D(G(z)): -30124.8086 / -30100.0879 Elapsed 0.32 s\n",
      "[17/25][10/63] Loss_D: nan Loss_G: nan D(x): -26555.3750 D(G(z)): -30125.6094 / -30035.0215 Elapsed 0.32 s\n",
      "[17/25][11/63] Loss_D: nan Loss_G: nan D(x): -26572.9121 D(G(z)): -30091.1582 / -30112.5840 Elapsed 0.32 s\n",
      "[17/25][12/63] Loss_D: nan Loss_G: nan D(x): -26480.6035 D(G(z)): -30090.7793 / -30136.8867 Elapsed 0.34 s\n",
      "[17/25][13/63] Loss_D: nan Loss_G: nan D(x): -26432.3438 D(G(z)): -30164.2832 / -30182.9824 Elapsed 0.34 s\n",
      "[17/25][14/63] Loss_D: nan Loss_G: nan D(x): -26505.7715 D(G(z)): -30260.1621 / -30214.2285 Elapsed 0.30 s\n",
      "[17/25][15/63] Loss_D: nan Loss_G: nan D(x): -26716.6289 D(G(z)): -30146.8066 / -30180.6191 Elapsed 0.30 s\n",
      "[17/25][16/63] Loss_D: nan Loss_G: nan D(x): -26487.8906 D(G(z)): -30161.5879 / -30225.9629 Elapsed 0.30 s\n",
      "[17/25][17/63] Loss_D: nan Loss_G: nan D(x): -26551.5645 D(G(z)): -30222.7773 / -30242.3105 Elapsed 0.33 s\n",
      "[17/25][18/63] Loss_D: nan Loss_G: nan D(x): -26541.6523 D(G(z)): -30252.1543 / -30261.8086 Elapsed 0.32 s\n",
      "[17/25][19/63] Loss_D: nan Loss_G: nan D(x): -26561.8066 D(G(z)): -30259.7695 / -30217.2637 Elapsed 0.30 s\n",
      "[17/25][20/63] Loss_D: nan Loss_G: nan D(x): -26732.6895 D(G(z)): -30282.2227 / -30332.5684 Elapsed 0.32 s\n",
      "[17/25][21/63] Loss_D: nan Loss_G: nan D(x): -26689.2793 D(G(z)): -30224.7305 / -30370.3711 Elapsed 0.33 s\n",
      "[17/25][22/63] Loss_D: nan Loss_G: nan D(x): -26721.0469 D(G(z)): -30304.9570 / -30296.8984 Elapsed 0.32 s\n",
      "[17/25][23/63] Loss_D: nan Loss_G: nan D(x): -26623.5645 D(G(z)): -30349.3926 / -30389.1641 Elapsed 0.32 s\n",
      "[17/25][24/63] Loss_D: nan Loss_G: nan D(x): -26631.9531 D(G(z)): -30263.5742 / -30319.9297 Elapsed 0.30 s\n",
      "[17/25][25/63] Loss_D: nan Loss_G: nan D(x): -26753.4902 D(G(z)): -30291.9258 / -30311.7031 Elapsed 0.32 s\n",
      "[17/25][26/63] Loss_D: nan Loss_G: nan D(x): -26763.0371 D(G(z)): -30394.1523 / -30428.8633 Elapsed 0.32 s\n",
      "[17/25][27/63] Loss_D: nan Loss_G: nan D(x): -26719.4316 D(G(z)): -30342.6699 / -30449.5996 Elapsed 0.32 s\n",
      "[17/25][28/63] Loss_D: nan Loss_G: nan D(x): -26738.2891 D(G(z)): -30344.2109 / -30399.0430 Elapsed 0.30 s\n",
      "[17/25][29/63] Loss_D: nan Loss_G: nan D(x): -26712.6543 D(G(z)): -30347.7266 / -30425.4375 Elapsed 0.30 s\n",
      "[17/25][30/63] Loss_D: nan Loss_G: nan D(x): -26735.8516 D(G(z)): -30463.4258 / -30493.6641 Elapsed 0.30 s\n",
      "[17/25][31/63] Loss_D: nan Loss_G: nan D(x): -26830.3848 D(G(z)): -30432.0801 / -30503.9414 Elapsed 0.30 s\n",
      "[17/25][32/63] Loss_D: nan Loss_G: nan D(x): -26747.2559 D(G(z)): -30445.3438 / -30463.2734 Elapsed 0.30 s\n",
      "[17/25][33/63] Loss_D: nan Loss_G: nan D(x): -26904.1992 D(G(z)): -30454.3398 / -30463.1016 Elapsed 0.32 s\n",
      "[17/25][34/63] Loss_D: nan Loss_G: nan D(x): -26957.4707 D(G(z)): -30472.6777 / -30478.0488 Elapsed 0.32 s\n",
      "[17/25][35/63] Loss_D: nan Loss_G: nan D(x): -26669.9199 D(G(z)): -30412.9512 / -30439.8535 Elapsed 0.30 s\n",
      "[17/25][36/63] Loss_D: nan Loss_G: nan D(x): -26763.1465 D(G(z)): -30438.1914 / -30537.0254 Elapsed 0.30 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/25][37/63] Loss_D: nan Loss_G: nan D(x): -26863.9766 D(G(z)): -30505.8594 / -30553.2012 Elapsed 0.30 s\n",
      "[17/25][38/63] Loss_D: nan Loss_G: nan D(x): -26789.9648 D(G(z)): -30535.6484 / -30507.7656 Elapsed 0.32 s\n",
      "[17/25][39/63] Loss_D: nan Loss_G: nan D(x): -26974.7090 D(G(z)): -30552.7266 / -30577.3848 Elapsed 0.32 s\n",
      "[17/25][40/63] Loss_D: nan Loss_G: nan D(x): -26643.9102 D(G(z)): -30581.0449 / -30517.3281 Elapsed 0.32 s\n",
      "[17/25][41/63] Loss_D: nan Loss_G: nan D(x): -26971.0410 D(G(z)): -30634.5859 / -30576.7734 Elapsed 0.32 s\n",
      "[17/25][42/63] Loss_D: nan Loss_G: nan D(x): -26827.1895 D(G(z)): -30586.7500 / -30570.2637 Elapsed 0.32 s\n",
      "[17/25][43/63] Loss_D: nan Loss_G: nan D(x): -26984.7246 D(G(z)): -30622.1855 / -30546.8301 Elapsed 0.30 s\n",
      "[17/25][44/63] Loss_D: nan Loss_G: nan D(x): -26893.1230 D(G(z)): -30646.9766 / -30689.0098 Elapsed 0.32 s\n",
      "[17/25][45/63] Loss_D: nan Loss_G: nan D(x): -26842.0664 D(G(z)): -30626.3359 / -30640.5527 Elapsed 0.32 s\n",
      "[17/25][46/63] Loss_D: nan Loss_G: nan D(x): -26846.2148 D(G(z)): -30531.6094 / -30653.5078 Elapsed 0.30 s\n",
      "[17/25][47/63] Loss_D: nan Loss_G: nan D(x): -27039.0918 D(G(z)): -30632.4766 / -30702.6953 Elapsed 0.32 s\n",
      "[17/25][48/63] Loss_D: nan Loss_G: nan D(x): -27015.3320 D(G(z)): -30659.9727 / -30698.1113 Elapsed 0.32 s\n",
      "[17/25][49/63] Loss_D: nan Loss_G: nan D(x): -26973.6094 D(G(z)): -30677.7539 / -30670.0000 Elapsed 0.32 s\n",
      "[17/25][50/63] Loss_D: nan Loss_G: nan D(x): -26933.2871 D(G(z)): -30578.8691 / -30663.7812 Elapsed 0.32 s\n",
      "[17/25][51/63] Loss_D: nan Loss_G: nan D(x): -27011.9902 D(G(z)): -30695.1484 / -30718.5176 Elapsed 0.34 s\n",
      "[17/25][52/63] Loss_D: nan Loss_G: nan D(x): -26979.0312 D(G(z)): -30591.2324 / -30719.3945 Elapsed 0.30 s\n",
      "[17/25][53/63] Loss_D: nan Loss_G: nan D(x): -26967.1543 D(G(z)): -30697.9062 / -30688.2051 Elapsed 0.32 s\n",
      "[17/25][54/63] Loss_D: nan Loss_G: nan D(x): -26983.9375 D(G(z)): -30703.7031 / -30694.6582 Elapsed 0.32 s\n",
      "[17/25][55/63] Loss_D: nan Loss_G: nan D(x): -27117.5625 D(G(z)): -30753.2188 / -30709.2266 Elapsed 0.32 s\n",
      "[17/25][56/63] Loss_D: nan Loss_G: nan D(x): -26983.2832 D(G(z)): -30708.3066 / -30702.4453 Elapsed 0.30 s\n",
      "[17/25][57/63] Loss_D: nan Loss_G: nan D(x): -26983.1113 D(G(z)): -30823.3281 / -30788.4980 Elapsed 0.32 s\n",
      "[17/25][58/63] Loss_D: nan Loss_G: nan D(x): -27034.4453 D(G(z)): -30776.8047 / -30813.4219 Elapsed 0.32 s\n",
      "[17/25][59/63] Loss_D: nan Loss_G: nan D(x): -27107.5078 D(G(z)): -30731.9316 / -30770.5957 Elapsed 0.32 s\n",
      "[17/25][60/63] Loss_D: nan Loss_G: nan D(x): -27118.1348 D(G(z)): -30772.4453 / -30817.0469 Elapsed 0.30 s\n",
      "[17/25][61/63] Loss_D: nan Loss_G: nan D(x): -27061.9961 D(G(z)): -30729.0879 / -30840.1973 Elapsed 0.30 s\n",
      "[17/25][62/63] Loss_D: nan Loss_G: nan D(x): -27023.0723 D(G(z)): -30809.4961 / -30903.0488 Elapsed 0.15 s\n",
      "[18/25][0/63] Loss_D: nan Loss_G: nan D(x): -27126.6406 D(G(z)): -30739.4023 / -30769.1309 Elapsed 0.32 s\n",
      "[18/25][1/63] Loss_D: nan Loss_G: nan D(x): -27105.8418 D(G(z)): -30847.5039 / -30813.5020 Elapsed 0.32 s\n",
      "[18/25][2/63] Loss_D: nan Loss_G: nan D(x): -27091.5684 D(G(z)): -30828.2012 / -30874.0918 Elapsed 0.33 s\n",
      "[18/25][3/63] Loss_D: nan Loss_G: nan D(x): -27218.6211 D(G(z)): -30820.0156 / -30863.5430 Elapsed 0.30 s\n",
      "[18/25][4/63] Loss_D: nan Loss_G: nan D(x): -27092.1465 D(G(z)): -30817.6816 / -30865.8516 Elapsed 0.32 s\n",
      "[18/25][5/63] Loss_D: nan Loss_G: nan D(x): -27231.7148 D(G(z)): -30862.6914 / -30812.9199 Elapsed 0.31 s\n",
      "[18/25][6/63] Loss_D: nan Loss_G: nan D(x): -27045.4043 D(G(z)): -30893.6758 / -30825.7910 Elapsed 0.30 s\n",
      "[18/25][7/63] Loss_D: nan Loss_G: nan D(x): -27185.3672 D(G(z)): -30869.4629 / -30822.8594 Elapsed 0.32 s\n",
      "[18/25][8/63] Loss_D: nan Loss_G: nan D(x): -27168.2109 D(G(z)): -30830.0840 / -30864.5566 Elapsed 0.33 s\n",
      "[18/25][9/63] Loss_D: nan Loss_G: nan D(x): -27130.4297 D(G(z)): -30910.1230 / -30889.2520 Elapsed 0.32 s\n",
      "[18/25][10/63] Loss_D: nan Loss_G: nan D(x): -27233.0879 D(G(z)): -30884.3926 / -30930.7148 Elapsed 0.32 s\n",
      "[18/25][11/63] Loss_D: nan Loss_G: nan D(x): -27016.6875 D(G(z)): -30917.9492 / -30924.2715 Elapsed 0.32 s\n",
      "[18/25][12/63] Loss_D: nan Loss_G: nan D(x): -27186.6094 D(G(z)): -30834.8535 / -30910.4648 Elapsed 0.32 s\n",
      "[18/25][13/63] Loss_D: nan Loss_G: nan D(x): -27135.3398 D(G(z)): -30945.6914 / -30924.6367 Elapsed 0.32 s\n",
      "[18/25][14/63] Loss_D: nan Loss_G: nan D(x): -27127.2168 D(G(z)): -30960.0430 / -30923.6758 Elapsed 0.30 s\n",
      "[18/25][15/63] Loss_D: nan Loss_G: nan D(x): -27289.4297 D(G(z)): -30954.0938 / -30962.6992 Elapsed 0.30 s\n",
      "[18/25][16/63] Loss_D: nan Loss_G: nan D(x): -27242.2539 D(G(z)): -30863.6914 / -30935.9766 Elapsed 0.30 s\n",
      "[18/25][17/63] Loss_D: nan Loss_G: nan D(x): -27203.2129 D(G(z)): -30960.0078 / -30957.5098 Elapsed 0.30 s\n",
      "[18/25][18/63] Loss_D: nan Loss_G: nan D(x): -27037.3535 D(G(z)): -31031.9258 / -30978.0605 Elapsed 0.32 s\n",
      "[18/25][19/63] Loss_D: nan Loss_G: nan D(x): -27185.1836 D(G(z)): -30904.8301 / -30900.0000 Elapsed 0.32 s\n",
      "[18/25][20/63] Loss_D: nan Loss_G: nan D(x): -27234.7461 D(G(z)): -30970.0312 / -30987.5332 Elapsed 0.32 s\n",
      "[18/25][21/63] Loss_D: nan Loss_G: nan D(x): -27266.6816 D(G(z)): -30940.2422 / -30984.8125 Elapsed 0.32 s\n",
      "[18/25][22/63] Loss_D: nan Loss_G: nan D(x): -27256.8281 D(G(z)): -31039.8867 / -31003.3477 Elapsed 0.32 s\n",
      "[18/25][23/63] Loss_D: nan Loss_G: nan D(x): -27256.0840 D(G(z)): -31009.8809 / -31017.3711 Elapsed 0.32 s\n",
      "[18/25][24/63] Loss_D: nan Loss_G: nan D(x): -27275.7734 D(G(z)): -31025.1426 / -30969.3242 Elapsed 0.32 s\n",
      "[18/25][25/63] Loss_D: nan Loss_G: nan D(x): -27267.0840 D(G(z)): -31027.8965 / -31065.8281 Elapsed 0.33 s\n",
      "[18/25][26/63] Loss_D: nan Loss_G: nan D(x): -27269.6504 D(G(z)): -31058.9609 / -31044.4160 Elapsed 0.37 s\n",
      "[18/25][27/63] Loss_D: nan Loss_G: nan D(x): -27295.6309 D(G(z)): -31044.5293 / -30996.8555 Elapsed 0.32 s\n",
      "[18/25][28/63] Loss_D: nan Loss_G: nan D(x): -27190.7949 D(G(z)): -31013.4922 / -31087.0508 Elapsed 0.38 s\n",
      "[18/25][29/63] Loss_D: nan Loss_G: nan D(x): -27370.4492 D(G(z)): -31023.0801 / -31096.0977 Elapsed 0.30 s\n",
      "[18/25][30/63] Loss_D: nan Loss_G: nan D(x): -27287.2715 D(G(z)): -31082.4844 / -31156.1973 Elapsed 0.30 s\n",
      "[18/25][31/63] Loss_D: nan Loss_G: nan D(x): -27348.8672 D(G(z)): -31027.1230 / -30987.2363 Elapsed 0.32 s\n",
      "[18/25][32/63] Loss_D: nan Loss_G: nan D(x): -27400.6602 D(G(z)): -31003.3203 / -31068.7012 Elapsed 0.32 s\n",
      "[18/25][33/63] Loss_D: nan Loss_G: nan D(x): -27318.1992 D(G(z)): -31124.8926 / -30971.5820 Elapsed 0.30 s\n",
      "[18/25][34/63] Loss_D: nan Loss_G: nan D(x): -27459.1914 D(G(z)): -30952.8047 / -31160.7598 Elapsed 0.32 s\n",
      "[18/25][35/63] Loss_D: nan Loss_G: nan D(x): -27318.8770 D(G(z)): -31059.3242 / -31029.5723 Elapsed 0.33 s\n",
      "[18/25][36/63] Loss_D: nan Loss_G: nan D(x): -27296.6523 D(G(z)): -31040.6680 / -31072.8008 Elapsed 0.32 s\n",
      "[18/25][37/63] Loss_D: nan Loss_G: nan D(x): -27268.9629 D(G(z)): -31010.6270 / -31033.6270 Elapsed 0.30 s\n",
      "[18/25][38/63] Loss_D: nan Loss_G: nan D(x): -27156.7305 D(G(z)): -31101.9141 / -31049.5410 Elapsed 0.32 s\n",
      "[18/25][39/63] Loss_D: nan Loss_G: nan D(x): -27519.2832 D(G(z)): -31071.3340 / -31084.7559 Elapsed 0.33 s\n",
      "[18/25][40/63] Loss_D: nan Loss_G: nan D(x): -27287.3457 D(G(z)): -31075.9609 / -31208.7832 Elapsed 0.32 s\n",
      "[18/25][41/63] Loss_D: nan Loss_G: nan D(x): -27200.2207 D(G(z)): -31147.7227 / -31121.0176 Elapsed 0.31 s\n",
      "[18/25][42/63] Loss_D: nan Loss_G: nan D(x): -27345.7539 D(G(z)): -31136.3105 / -31106.3223 Elapsed 0.30 s\n",
      "[18/25][43/63] Loss_D: nan Loss_G: nan D(x): -27375.7617 D(G(z)): -31083.5820 / -31081.2363 Elapsed 0.31 s\n",
      "[18/25][44/63] Loss_D: nan Loss_G: nan D(x): -27483.0176 D(G(z)): -31093.8066 / -31099.3711 Elapsed 0.32 s\n",
      "[18/25][45/63] Loss_D: nan Loss_G: nan D(x): -27338.2441 D(G(z)): -31120.4688 / -31119.7598 Elapsed 0.30 s\n",
      "[18/25][46/63] Loss_D: nan Loss_G: nan D(x): -27408.0293 D(G(z)): -31082.5332 / -31076.4238 Elapsed 0.30 s\n",
      "[18/25][47/63] Loss_D: nan Loss_G: nan D(x): -27229.8750 D(G(z)): -31076.1797 / -31097.4629 Elapsed 0.32 s\n",
      "[18/25][48/63] Loss_D: nan Loss_G: nan D(x): -27289.5176 D(G(z)): -31120.0605 / -31082.9824 Elapsed 0.30 s\n",
      "[18/25][49/63] Loss_D: nan Loss_G: nan D(x): -27320.1738 D(G(z)): -31139.4844 / -31156.4805 Elapsed 0.31 s\n",
      "[18/25][50/63] Loss_D: nan Loss_G: nan D(x): -27427.4492 D(G(z)): -30999.7910 / -31100.4766 Elapsed 0.32 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/25][51/63] Loss_D: nan Loss_G: nan D(x): -27341.4707 D(G(z)): -31082.0234 / -31095.7676 Elapsed 0.32 s\n",
      "[18/25][52/63] Loss_D: nan Loss_G: nan D(x): -27308.7324 D(G(z)): -31076.0723 / -31173.4160 Elapsed 0.32 s\n",
      "[18/25][53/63] Loss_D: nan Loss_G: nan D(x): -27290.9199 D(G(z)): -31116.4902 / -31144.5781 Elapsed 0.32 s\n",
      "[18/25][54/63] Loss_D: nan Loss_G: nan D(x): -27486.4492 D(G(z)): -31138.0625 / -31044.8184 Elapsed 0.32 s\n",
      "[18/25][55/63] Loss_D: nan Loss_G: nan D(x): -27314.1035 D(G(z)): -31155.4648 / -31177.5215 Elapsed 0.30 s\n",
      "[18/25][56/63] Loss_D: nan Loss_G: nan D(x): -27341.8379 D(G(z)): -31216.9258 / -31080.4277 Elapsed 0.33 s\n",
      "[18/25][57/63] Loss_D: nan Loss_G: nan D(x): -27370.6641 D(G(z)): -31105.9141 / -31095.7949 Elapsed 0.32 s\n",
      "[18/25][58/63] Loss_D: nan Loss_G: nan D(x): -27453.4727 D(G(z)): -31104.7598 / -31134.7578 Elapsed 0.32 s\n",
      "[18/25][59/63] Loss_D: nan Loss_G: nan D(x): -27434.4004 D(G(z)): -31034.5137 / -31119.4805 Elapsed 0.32 s\n",
      "[18/25][60/63] Loss_D: nan Loss_G: nan D(x): -27344.1484 D(G(z)): -31081.3730 / -31148.7266 Elapsed 0.32 s\n",
      "[18/25][61/63] Loss_D: nan Loss_G: nan D(x): -27338.6992 D(G(z)): -31210.1953 / -31142.1309 Elapsed 0.32 s\n",
      "[18/25][62/63] Loss_D: nan Loss_G: nan D(x): -27531.3457 D(G(z)): -31138.8906 / -31169.9961 Elapsed 0.15 s\n",
      "[19/25][0/63] Loss_D: nan Loss_G: nan D(x): -27486.6387 D(G(z)): -31154.0605 / -31155.3574 Elapsed 0.32 s\n",
      "[19/25][1/63] Loss_D: nan Loss_G: nan D(x): -27208.4121 D(G(z)): -31133.4473 / -31160.5078 Elapsed 0.32 s\n",
      "[19/25][2/63] Loss_D: nan Loss_G: nan D(x): -27349.5156 D(G(z)): -31092.2637 / -31082.4609 Elapsed 0.32 s\n",
      "[19/25][3/63] Loss_D: nan Loss_G: nan D(x): -27425.3672 D(G(z)): -31163.2852 / -31162.6621 Elapsed 0.32 s\n",
      "[19/25][4/63] Loss_D: nan Loss_G: nan D(x): -27488.5957 D(G(z)): -31173.0488 / -31084.2422 Elapsed 0.30 s\n",
      "[19/25][5/63] Loss_D: nan Loss_G: nan D(x): -27410.0430 D(G(z)): -31154.2559 / -31155.9023 Elapsed 0.30 s\n",
      "[19/25][6/63] Loss_D: nan Loss_G: nan D(x): -27305.1328 D(G(z)): -31065.3105 / -31135.1230 Elapsed 0.30 s\n",
      "[19/25][7/63] Loss_D: nan Loss_G: nan D(x): -27460.8809 D(G(z)): -31113.0000 / -31195.8594 Elapsed 0.32 s\n",
      "[19/25][8/63] Loss_D: nan Loss_G: nan D(x): -27444.3398 D(G(z)): -31072.1934 / -31119.1016 Elapsed 0.30 s\n",
      "[19/25][9/63] Loss_D: nan Loss_G: nan D(x): -27327.6543 D(G(z)): -31131.4336 / -31113.4648 Elapsed 0.30 s\n",
      "[19/25][10/63] Loss_D: nan Loss_G: nan D(x): -27432.2109 D(G(z)): -31152.3555 / -31100.9414 Elapsed 0.30 s\n",
      "[19/25][11/63] Loss_D: nan Loss_G: nan D(x): -27348.2734 D(G(z)): -31114.7812 / -31143.1348 Elapsed 0.32 s\n",
      "[19/25][12/63] Loss_D: nan Loss_G: nan D(x): -27430.9043 D(G(z)): -31190.6621 / -31202.5840 Elapsed 0.32 s\n",
      "[19/25][13/63] Loss_D: nan Loss_G: nan D(x): -27377.3809 D(G(z)): -31049.8672 / -31131.7734 Elapsed 0.32 s\n",
      "[19/25][14/63] Loss_D: nan Loss_G: nan D(x): -27441.5078 D(G(z)): -31160.3770 / -31140.8613 Elapsed 0.30 s\n",
      "[19/25][15/63] Loss_D: nan Loss_G: nan D(x): -27467.1270 D(G(z)): -31143.5840 / -31136.4277 Elapsed 0.32 s\n",
      "[19/25][16/63] Loss_D: nan Loss_G: nan D(x): -27409.5898 D(G(z)): -31217.9004 / -31072.6875 Elapsed 0.30 s\n",
      "[19/25][17/63] Loss_D: nan Loss_G: nan D(x): -27339.3145 D(G(z)): -31093.2285 / -31140.8066 Elapsed 0.32 s\n",
      "[19/25][18/63] Loss_D: nan Loss_G: nan D(x): -27259.1328 D(G(z)): -31115.4297 / -31177.2539 Elapsed 0.30 s\n",
      "[19/25][19/63] Loss_D: nan Loss_G: nan D(x): -27284.7363 D(G(z)): -31083.6211 / -31185.3145 Elapsed 0.32 s\n",
      "[19/25][20/63] Loss_D: nan Loss_G: nan D(x): -27344.5273 D(G(z)): -31183.6523 / -31011.8496 Elapsed 0.30 s\n",
      "[19/25][21/63] Loss_D: nan Loss_G: nan D(x): -27298.3672 D(G(z)): -31180.6973 / -31136.5410 Elapsed 0.32 s\n",
      "[19/25][22/63] Loss_D: nan Loss_G: nan D(x): -27297.4297 D(G(z)): -31089.3555 / -31163.6719 Elapsed 0.30 s\n",
      "[19/25][23/63] Loss_D: nan Loss_G: nan D(x): -27481.9609 D(G(z)): -31134.4746 / -31211.7852 Elapsed 0.32 s\n",
      "[19/25][24/63] Loss_D: nan Loss_G: nan D(x): -27328.2246 D(G(z)): -31232.5508 / -31106.0820 Elapsed 0.30 s\n",
      "[19/25][25/63] Loss_D: nan Loss_G: nan D(x): -27361.6934 D(G(z)): -31178.1602 / -31144.1465 Elapsed 0.32 s\n",
      "[19/25][26/63] Loss_D: nan Loss_G: nan D(x): -27405.1270 D(G(z)): -31161.2871 / -31159.6875 Elapsed 0.32 s\n",
      "[19/25][27/63] Loss_D: nan Loss_G: nan D(x): -27370.6602 D(G(z)): -31044.7363 / -31128.6562 Elapsed 0.32 s\n",
      "[19/25][28/63] Loss_D: nan Loss_G: nan D(x): -27398.4102 D(G(z)): -31174.2363 / -31115.9844 Elapsed 0.32 s\n",
      "[19/25][29/63] Loss_D: nan Loss_G: nan D(x): -27235.7695 D(G(z)): -31144.3809 / -31121.2344 Elapsed 0.32 s\n",
      "[19/25][30/63] Loss_D: nan Loss_G: nan D(x): -27405.2500 D(G(z)): -31140.2969 / -31077.7344 Elapsed 0.31 s\n",
      "[19/25][31/63] Loss_D: nan Loss_G: nan D(x): -27281.3828 D(G(z)): -31048.3965 / -31178.0508 Elapsed 0.32 s\n",
      "[19/25][32/63] Loss_D: nan Loss_G: nan D(x): -27392.2305 D(G(z)): -31151.2168 / -31181.5312 Elapsed 0.32 s\n",
      "[19/25][33/63] Loss_D: nan Loss_G: nan D(x): -27364.8086 D(G(z)): -31179.0410 / -31158.5059 Elapsed 0.30 s\n",
      "[19/25][34/63] Loss_D: nan Loss_G: nan D(x): -27311.9355 D(G(z)): -31161.5273 / -31199.9453 Elapsed 0.30 s\n",
      "[19/25][35/63] Loss_D: nan Loss_G: nan D(x): -27306.3125 D(G(z)): -31153.0039 / -31062.3965 Elapsed 0.32 s\n",
      "[19/25][36/63] Loss_D: nan Loss_G: nan D(x): -27443.2832 D(G(z)): -31201.8477 / -31134.7266 Elapsed 0.32 s\n",
      "[19/25][37/63] Loss_D: nan Loss_G: nan D(x): -27301.0410 D(G(z)): -31077.7520 / -31079.1758 Elapsed 0.32 s\n",
      "[19/25][38/63] Loss_D: nan Loss_G: nan D(x): -27511.0098 D(G(z)): -31166.6641 / -31123.5723 Elapsed 0.32 s\n",
      "[19/25][39/63] Loss_D: nan Loss_G: nan D(x): -27340.9844 D(G(z)): -31096.4668 / -31168.0410 Elapsed 0.32 s\n",
      "[19/25][40/63] Loss_D: nan Loss_G: nan D(x): -27521.3164 D(G(z)): -31120.6523 / -31153.2461 Elapsed 0.32 s\n",
      "[19/25][41/63] Loss_D: nan Loss_G: nan D(x): -27488.2500 D(G(z)): -31137.9355 / -31074.0469 Elapsed 0.32 s\n",
      "[19/25][42/63] Loss_D: nan Loss_G: nan D(x): -27448.7051 D(G(z)): -31094.5547 / -31117.4980 Elapsed 0.32 s\n",
      "[19/25][43/63] Loss_D: nan Loss_G: nan D(x): -27210.4414 D(G(z)): -31155.7500 / -31135.6426 Elapsed 0.30 s\n",
      "[19/25][44/63] Loss_D: nan Loss_G: nan D(x): -27542.6211 D(G(z)): -31164.6074 / -31120.6465 Elapsed 0.32 s\n",
      "[19/25][45/63] Loss_D: nan Loss_G: nan D(x): -27283.6133 D(G(z)): -31205.8750 / -31151.2383 Elapsed 0.32 s\n",
      "[19/25][46/63] Loss_D: nan Loss_G: nan D(x): -27531.3535 D(G(z)): -31184.4590 / -31105.7617 Elapsed 0.32 s\n",
      "[19/25][47/63] Loss_D: nan Loss_G: nan D(x): -27433.4219 D(G(z)): -31181.5332 / -31113.9492 Elapsed 0.32 s\n",
      "[19/25][48/63] Loss_D: nan Loss_G: nan D(x): -27239.6445 D(G(z)): -31146.8711 / -31099.6758 Elapsed 0.32 s\n",
      "[19/25][49/63] Loss_D: nan Loss_G: nan D(x): -27360.7734 D(G(z)): -31194.4453 / -31202.2168 Elapsed 0.32 s\n",
      "[19/25][50/63] Loss_D: nan Loss_G: nan D(x): -27391.9727 D(G(z)): -31122.7441 / -31182.7266 Elapsed 0.32 s\n",
      "[19/25][51/63] Loss_D: nan Loss_G: nan D(x): -27329.9590 D(G(z)): -31097.6426 / -31179.6953 Elapsed 0.30 s\n",
      "[19/25][52/63] Loss_D: nan Loss_G: nan D(x): -27415.6660 D(G(z)): -31089.2734 / -31154.6875 Elapsed 0.32 s\n",
      "[19/25][53/63] Loss_D: nan Loss_G: nan D(x): -27321.9609 D(G(z)): -31224.1914 / -31105.0918 Elapsed 0.31 s\n",
      "[19/25][54/63] Loss_D: nan Loss_G: nan D(x): -27387.9512 D(G(z)): -31103.5273 / -31199.4004 Elapsed 0.31 s\n",
      "[19/25][55/63] Loss_D: nan Loss_G: nan D(x): -27357.7949 D(G(z)): -31148.0508 / -31093.3574 Elapsed 0.32 s\n",
      "[19/25][56/63] Loss_D: nan Loss_G: nan D(x): -27301.6172 D(G(z)): -31005.1113 / -31148.3672 Elapsed 0.32 s\n",
      "[19/25][57/63] Loss_D: nan Loss_G: nan D(x): -27457.4922 D(G(z)): -31155.8184 / -31154.2559 Elapsed 0.30 s\n",
      "[19/25][58/63] Loss_D: nan Loss_G: nan D(x): -27416.9688 D(G(z)): -31102.9980 / -31137.1211 Elapsed 0.32 s\n",
      "[19/25][59/63] Loss_D: nan Loss_G: nan D(x): -27426.4727 D(G(z)): -31134.7852 / -31132.9004 Elapsed 0.30 s\n",
      "[19/25][60/63] Loss_D: nan Loss_G: nan D(x): -27418.6133 D(G(z)): -31118.0879 / -31163.0352 Elapsed 0.32 s\n",
      "[19/25][61/63] Loss_D: nan Loss_G: nan D(x): -27382.3281 D(G(z)): -31053.6777 / -31080.1465 Elapsed 0.32 s\n",
      "[19/25][62/63] Loss_D: nan Loss_G: nan D(x): -27333.6406 D(G(z)): -31140.0020 / -31088.6172 Elapsed 0.17 s\n",
      "[20/25][0/63] Loss_D: nan Loss_G: nan D(x): -27574.6562 D(G(z)): -31100.0859 / -31118.0293 Elapsed 0.33 s\n",
      "[20/25][1/63] Loss_D: nan Loss_G: nan D(x): -27295.1504 D(G(z)): -31088.9785 / -31132.5273 Elapsed 0.30 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/25][2/63] Loss_D: nan Loss_G: nan D(x): -27408.6113 D(G(z)): -31227.2363 / -31110.3379 Elapsed 0.30 s\n",
      "[20/25][3/63] Loss_D: nan Loss_G: nan D(x): -27478.9492 D(G(z)): -31128.3535 / -31029.7266 Elapsed 0.30 s\n",
      "[20/25][4/63] Loss_D: nan Loss_G: nan D(x): -27458.2227 D(G(z)): -31139.4727 / -31160.3086 Elapsed 0.32 s\n",
      "[20/25][5/63] Loss_D: nan Loss_G: nan D(x): -27309.9141 D(G(z)): -31063.4160 / -31236.1895 Elapsed 0.30 s\n",
      "[20/25][6/63] Loss_D: nan Loss_G: nan D(x): -27512.5820 D(G(z)): -31125.0762 / -31039.2695 Elapsed 0.32 s\n",
      "[20/25][7/63] Loss_D: nan Loss_G: nan D(x): -27714.3789 D(G(z)): -31101.5352 / -31102.1523 Elapsed 0.32 s\n",
      "[20/25][8/63] Loss_D: nan Loss_G: nan D(x): -27359.6016 D(G(z)): -31216.0195 / -31095.2051 Elapsed 0.30 s\n",
      "[20/25][9/63] Loss_D: nan Loss_G: nan D(x): -27267.9746 D(G(z)): -31165.0117 / -30991.8145 Elapsed 0.32 s\n",
      "[20/25][10/63] Loss_D: nan Loss_G: nan D(x): -27253.3320 D(G(z)): -31095.7812 / -31151.9160 Elapsed 0.30 s\n",
      "[20/25][11/63] Loss_D: nan Loss_G: nan D(x): -27330.3320 D(G(z)): -31136.3750 / -31067.9844 Elapsed 0.32 s\n",
      "[20/25][12/63] Loss_D: nan Loss_G: nan D(x): -27327.9883 D(G(z)): -31122.4336 / -31082.7188 Elapsed 0.30 s\n",
      "[20/25][13/63] Loss_D: nan Loss_G: nan D(x): -27393.8496 D(G(z)): -31102.4160 / -31153.9062 Elapsed 0.31 s\n",
      "[20/25][14/63] Loss_D: nan Loss_G: nan D(x): -27454.4062 D(G(z)): -31136.7832 / -31182.6582 Elapsed 0.30 s\n",
      "[20/25][15/63] Loss_D: nan Loss_G: nan D(x): -27429.5156 D(G(z)): -31119.6172 / -31068.6934 Elapsed 0.32 s\n",
      "[20/25][16/63] Loss_D: nan Loss_G: nan D(x): -27217.4902 D(G(z)): -31146.9258 / -31070.4258 Elapsed 0.32 s\n",
      "[20/25][17/63] Loss_D: nan Loss_G: nan D(x): -27398.8301 D(G(z)): -31209.7812 / -31120.8594 Elapsed 0.30 s\n",
      "[20/25][18/63] Loss_D: nan Loss_G: nan D(x): -27394.2930 D(G(z)): -31160.3379 / -31111.2715 Elapsed 0.32 s\n",
      "[20/25][19/63] Loss_D: nan Loss_G: nan D(x): -27352.5664 D(G(z)): -31227.6035 / -31140.7930 Elapsed 0.32 s\n",
      "[20/25][20/63] Loss_D: nan Loss_G: nan D(x): -27441.3418 D(G(z)): -31133.1035 / -31185.7734 Elapsed 0.33 s\n",
      "[20/25][21/63] Loss_D: nan Loss_G: nan D(x): -27598.2461 D(G(z)): -31191.6074 / -31050.8418 Elapsed 0.32 s\n",
      "[20/25][22/63] Loss_D: nan Loss_G: nan D(x): -27429.2012 D(G(z)): -31125.4902 / -31213.0137 Elapsed 0.32 s\n",
      "[20/25][23/63] Loss_D: nan Loss_G: nan D(x): -27123.7090 D(G(z)): -31129.1621 / -31119.2754 Elapsed 0.32 s\n",
      "[20/25][24/63] Loss_D: nan Loss_G: nan D(x): -27463.6152 D(G(z)): -31125.9844 / -31180.6797 Elapsed 0.31 s\n",
      "[20/25][25/63] Loss_D: nan Loss_G: nan D(x): -27452.5898 D(G(z)): -31131.3496 / -31144.9883 Elapsed 0.30 s\n",
      "[20/25][26/63] Loss_D: nan Loss_G: nan D(x): -27287.0820 D(G(z)): -31175.9805 / -31176.0586 Elapsed 0.32 s\n",
      "[20/25][27/63] Loss_D: nan Loss_G: nan D(x): -27581.4121 D(G(z)): -31195.6602 / -31158.1758 Elapsed 0.30 s\n",
      "[20/25][28/63] Loss_D: nan Loss_G: nan D(x): -27327.5059 D(G(z)): -31223.7578 / -31068.1562 Elapsed 0.32 s\n",
      "[20/25][29/63] Loss_D: nan Loss_G: nan D(x): -27424.3105 D(G(z)): -31097.3496 / -31158.3574 Elapsed 0.32 s\n",
      "[20/25][30/63] Loss_D: nan Loss_G: nan D(x): -27342.3223 D(G(z)): -31133.5410 / -31106.6426 Elapsed 0.34 s\n",
      "[20/25][31/63] Loss_D: nan Loss_G: nan D(x): -27367.6992 D(G(z)): -31183.9043 / -31088.7539 Elapsed 0.32 s\n",
      "[20/25][32/63] Loss_D: nan Loss_G: nan D(x): -27290.4336 D(G(z)): -31036.8359 / -31120.4082 Elapsed 0.31 s\n",
      "[20/25][33/63] Loss_D: nan Loss_G: nan D(x): -27257.3223 D(G(z)): -31156.3535 / -31101.5625 Elapsed 0.33 s\n",
      "[20/25][34/63] Loss_D: nan Loss_G: nan D(x): -27313.8438 D(G(z)): -31186.1973 / -31122.2793 Elapsed 0.32 s\n",
      "[20/25][35/63] Loss_D: nan Loss_G: nan D(x): -27440.4160 D(G(z)): -31062.0352 / -31178.3672 Elapsed 0.32 s\n",
      "[20/25][36/63] Loss_D: nan Loss_G: nan D(x): -27442.3438 D(G(z)): -31079.2227 / -31086.6211 Elapsed 0.31 s\n",
      "[20/25][37/63] Loss_D: nan Loss_G: nan D(x): -27309.5527 D(G(z)): -31117.2891 / -31163.4473 Elapsed 0.32 s\n",
      "[20/25][38/63] Loss_D: nan Loss_G: nan D(x): -27551.4688 D(G(z)): -31174.0957 / -31122.0039 Elapsed 0.32 s\n",
      "[20/25][39/63] Loss_D: nan Loss_G: nan D(x): -27334.4238 D(G(z)): -31159.9727 / -31135.8164 Elapsed 0.30 s\n",
      "[20/25][40/63] Loss_D: nan Loss_G: nan D(x): -27314.3184 D(G(z)): -31204.7773 / -31109.4844 Elapsed 0.32 s\n",
      "[20/25][41/63] Loss_D: nan Loss_G: nan D(x): -27366.4043 D(G(z)): -31139.5684 / -31018.6758 Elapsed 0.30 s\n",
      "[20/25][42/63] Loss_D: nan Loss_G: nan D(x): -27218.9492 D(G(z)): -31188.9590 / -31157.6484 Elapsed 0.31 s\n",
      "[20/25][43/63] Loss_D: nan Loss_G: nan D(x): -27213.2363 D(G(z)): -31105.8750 / -31164.7578 Elapsed 0.31 s\n",
      "[20/25][44/63] Loss_D: nan Loss_G: nan D(x): -27344.3887 D(G(z)): -31172.1992 / -31061.7832 Elapsed 0.30 s\n",
      "[20/25][45/63] Loss_D: nan Loss_G: nan D(x): -27295.1406 D(G(z)): -31109.1328 / -31071.0527 Elapsed 0.30 s\n",
      "[20/25][46/63] Loss_D: nan Loss_G: nan D(x): -27350.7051 D(G(z)): -31147.1562 / -31130.4824 Elapsed 0.32 s\n",
      "[20/25][47/63] Loss_D: nan Loss_G: nan D(x): -27389.1895 D(G(z)): -31122.4238 / -31174.8906 Elapsed 0.32 s\n",
      "[20/25][48/63] Loss_D: nan Loss_G: nan D(x): -27387.4922 D(G(z)): -31122.3477 / -31076.7930 Elapsed 0.32 s\n",
      "[20/25][49/63] Loss_D: nan Loss_G: nan D(x): -27476.0195 D(G(z)): -31137.1465 / -31062.3008 Elapsed 0.32 s\n",
      "[20/25][50/63] Loss_D: nan Loss_G: nan D(x): -27511.0859 D(G(z)): -31086.3672 / -31188.4492 Elapsed 0.32 s\n",
      "[20/25][51/63] Loss_D: nan Loss_G: nan D(x): -27373.0977 D(G(z)): -31228.6074 / -31123.8789 Elapsed 0.32 s\n",
      "[20/25][52/63] Loss_D: nan Loss_G: nan D(x): -27420.3496 D(G(z)): -31130.1309 / -31038.6719 Elapsed 0.32 s\n",
      "[20/25][53/63] Loss_D: nan Loss_G: nan D(x): -27498.0898 D(G(z)): -31090.0703 / -31193.7930 Elapsed 0.30 s\n",
      "[20/25][54/63] Loss_D: nan Loss_G: nan D(x): -27330.7812 D(G(z)): -31139.8301 / -31185.0117 Elapsed 0.30 s\n",
      "[20/25][55/63] Loss_D: nan Loss_G: nan D(x): -27545.6895 D(G(z)): -31196.0020 / -31148.0566 Elapsed 0.32 s\n",
      "[20/25][56/63] Loss_D: nan Loss_G: nan D(x): -27410.2715 D(G(z)): -31047.5195 / -31061.2070 Elapsed 0.32 s\n",
      "[20/25][57/63] Loss_D: nan Loss_G: nan D(x): -27381.5430 D(G(z)): -31154.0508 / -31125.3555 Elapsed 0.32 s\n",
      "[20/25][58/63] Loss_D: nan Loss_G: nan D(x): -27299.5293 D(G(z)): -31097.7715 / -31176.7461 Elapsed 0.32 s\n",
      "[20/25][59/63] Loss_D: nan Loss_G: nan D(x): -27266.7070 D(G(z)): -31094.7695 / -31170.7734 Elapsed 0.30 s\n",
      "[20/25][60/63] Loss_D: nan Loss_G: nan D(x): -27289.0625 D(G(z)): -31246.4512 / -31126.9844 Elapsed 0.32 s\n",
      "[20/25][61/63] Loss_D: nan Loss_G: nan D(x): -27523.7051 D(G(z)): -31137.0078 / -31087.9355 Elapsed 0.32 s\n",
      "[20/25][62/63] Loss_D: nan Loss_G: nan D(x): -27492.1211 D(G(z)): -31225.8613 / -31086.7715 Elapsed 0.17 s\n",
      "[21/25][0/63] Loss_D: nan Loss_G: nan D(x): -27377.0332 D(G(z)): -31179.4512 / -31132.6777 Elapsed 0.32 s\n",
      "[21/25][1/63] Loss_D: nan Loss_G: nan D(x): -27376.6875 D(G(z)): -31058.6738 / -31120.9453 Elapsed 0.32 s\n",
      "[21/25][2/63] Loss_D: nan Loss_G: nan D(x): -27453.1738 D(G(z)): -31144.4219 / -31134.3223 Elapsed 0.32 s\n",
      "[21/25][3/63] Loss_D: nan Loss_G: nan D(x): -27458.7852 D(G(z)): -31098.0840 / -31198.1230 Elapsed 0.33 s\n",
      "[21/25][4/63] Loss_D: nan Loss_G: nan D(x): -27532.3008 D(G(z)): -31109.6328 / -31237.1289 Elapsed 0.32 s\n",
      "[21/25][5/63] Loss_D: nan Loss_G: nan D(x): -27183.7715 D(G(z)): -31039.2363 / -31107.6797 Elapsed 0.32 s\n",
      "[21/25][6/63] Loss_D: nan Loss_G: nan D(x): -27342.4980 D(G(z)): -31127.4961 / -31102.8086 Elapsed 0.30 s\n",
      "[21/25][7/63] Loss_D: nan Loss_G: nan D(x): -27440.2930 D(G(z)): -31115.0977 / -31152.4492 Elapsed 0.30 s\n",
      "[21/25][8/63] Loss_D: nan Loss_G: nan D(x): -27458.3008 D(G(z)): -31129.1094 / -31122.7793 Elapsed 0.32 s\n",
      "[21/25][9/63] Loss_D: nan Loss_G: nan D(x): -27391.3477 D(G(z)): -31161.5391 / -31097.3477 Elapsed 0.32 s\n",
      "[21/25][10/63] Loss_D: nan Loss_G: nan D(x): -27378.9395 D(G(z)): -31125.1016 / -31107.9023 Elapsed 0.30 s\n",
      "[21/25][11/63] Loss_D: nan Loss_G: nan D(x): -27627.3574 D(G(z)): -31111.0898 / -31200.2715 Elapsed 0.31 s\n",
      "[21/25][12/63] Loss_D: nan Loss_G: nan D(x): -27328.0566 D(G(z)): -31096.7422 / -31126.0645 Elapsed 0.30 s\n",
      "[21/25][13/63] Loss_D: nan Loss_G: nan D(x): -27378.1641 D(G(z)): -31170.3438 / -31098.4355 Elapsed 0.30 s\n",
      "[21/25][14/63] Loss_D: nan Loss_G: nan D(x): -27259.0332 D(G(z)): -31114.5234 / -31188.5078 Elapsed 0.32 s\n",
      "[21/25][15/63] Loss_D: nan Loss_G: nan D(x): -27391.8379 D(G(z)): -31151.7344 / -31120.0234 Elapsed 0.30 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/25][16/63] Loss_D: nan Loss_G: nan D(x): -27476.3223 D(G(z)): -31132.3750 / -31155.9160 Elapsed 0.30 s\n",
      "[21/25][17/63] Loss_D: nan Loss_G: nan D(x): -27373.4512 D(G(z)): -31215.3438 / -31111.7383 Elapsed 0.30 s\n",
      "[21/25][18/63] Loss_D: nan Loss_G: nan D(x): -27435.6426 D(G(z)): -31161.5234 / -31077.8848 Elapsed 0.30 s\n",
      "[21/25][19/63] Loss_D: nan Loss_G: nan D(x): -27531.3184 D(G(z)): -31148.3047 / -31215.4961 Elapsed 0.30 s\n",
      "[21/25][20/63] Loss_D: nan Loss_G: nan D(x): -27457.8789 D(G(z)): -31197.5000 / -31158.3984 Elapsed 0.32 s\n",
      "[21/25][21/63] Loss_D: nan Loss_G: nan D(x): -27172.0195 D(G(z)): -31128.5234 / -31123.6484 Elapsed 0.30 s\n",
      "[21/25][22/63] Loss_D: nan Loss_G: nan D(x): -27301.6094 D(G(z)): -31127.2227 / -31054.3770 Elapsed 0.30 s\n",
      "[21/25][23/63] Loss_D: nan Loss_G: nan D(x): -27345.1523 D(G(z)): -31115.6289 / -31203.3750 Elapsed 0.30 s\n",
      "[21/25][24/63] Loss_D: nan Loss_G: nan D(x): -27298.9902 D(G(z)): -31110.2930 / -31105.7988 Elapsed 0.32 s\n",
      "[21/25][25/63] Loss_D: nan Loss_G: nan D(x): -27273.4434 D(G(z)): -31052.8281 / -31073.4355 Elapsed 0.32 s\n",
      "[21/25][26/63] Loss_D: nan Loss_G: nan D(x): -27395.6816 D(G(z)): -31148.1660 / -31240.0293 Elapsed 0.30 s\n",
      "[21/25][27/63] Loss_D: nan Loss_G: nan D(x): -27439.3887 D(G(z)): -31125.3008 / -31129.5039 Elapsed 0.32 s\n",
      "[21/25][28/63] Loss_D: nan Loss_G: nan D(x): -27493.3203 D(G(z)): -31193.6367 / -31295.8555 Elapsed 0.30 s\n",
      "[21/25][29/63] Loss_D: nan Loss_G: nan D(x): -27336.1641 D(G(z)): -31140.6172 / -31170.1211 Elapsed 0.30 s\n",
      "[21/25][30/63] Loss_D: nan Loss_G: nan D(x): -27374.7969 D(G(z)): -31143.0938 / -31101.5039 Elapsed 0.30 s\n",
      "[21/25][31/63] Loss_D: nan Loss_G: nan D(x): -27311.2129 D(G(z)): -31149.3945 / -31141.5996 Elapsed 0.30 s\n",
      "[21/25][32/63] Loss_D: nan Loss_G: nan D(x): -27431.0371 D(G(z)): -31134.2246 / -31091.9062 Elapsed 0.30 s\n",
      "[21/25][33/63] Loss_D: nan Loss_G: nan D(x): -27212.9805 D(G(z)): -31172.7363 / -31239.1035 Elapsed 0.30 s\n",
      "[21/25][34/63] Loss_D: nan Loss_G: nan D(x): -27363.3145 D(G(z)): -31169.9414 / -31067.1484 Elapsed 0.30 s\n",
      "[21/25][35/63] Loss_D: nan Loss_G: nan D(x): -27389.8027 D(G(z)): -31223.2324 / -31119.1797 Elapsed 0.30 s\n",
      "[21/25][36/63] Loss_D: nan Loss_G: nan D(x): -27390.9609 D(G(z)): -31089.1562 / -31123.0059 Elapsed 0.32 s\n",
      "[21/25][37/63] Loss_D: nan Loss_G: nan D(x): -27401.1211 D(G(z)): -31234.6191 / -31094.3574 Elapsed 0.30 s\n",
      "[21/25][38/63] Loss_D: nan Loss_G: nan D(x): -27398.4180 D(G(z)): -31171.9375 / -31089.5996 Elapsed 0.32 s\n",
      "[21/25][39/63] Loss_D: nan Loss_G: nan D(x): -27430.4004 D(G(z)): -31142.6445 / -31159.1680 Elapsed 0.32 s\n",
      "[21/25][40/63] Loss_D: nan Loss_G: nan D(x): -27520.4980 D(G(z)): -31115.4297 / -31162.1016 Elapsed 0.30 s\n",
      "[21/25][41/63] Loss_D: nan Loss_G: nan D(x): -27447.0488 D(G(z)): -31210.3145 / -31209.0703 Elapsed 0.32 s\n",
      "[21/25][42/63] Loss_D: nan Loss_G: nan D(x): -27391.5684 D(G(z)): -31093.1523 / -31074.3633 Elapsed 0.32 s\n",
      "[21/25][43/63] Loss_D: nan Loss_G: nan D(x): -27355.2422 D(G(z)): -31164.5078 / -31127.3730 Elapsed 0.30 s\n",
      "[21/25][44/63] Loss_D: nan Loss_G: nan D(x): -27278.0938 D(G(z)): -31216.0371 / -31097.7656 Elapsed 0.30 s\n",
      "[21/25][45/63] Loss_D: nan Loss_G: nan D(x): -27488.5195 D(G(z)): -31174.0723 / -31169.2656 Elapsed 0.32 s\n",
      "[21/25][46/63] Loss_D: nan Loss_G: nan D(x): -27212.5508 D(G(z)): -31204.0000 / -31115.8594 Elapsed 0.32 s\n",
      "[21/25][47/63] Loss_D: nan Loss_G: nan D(x): -27587.9336 D(G(z)): -31087.3125 / -31148.8926 Elapsed 0.30 s\n",
      "[21/25][48/63] Loss_D: nan Loss_G: nan D(x): -27466.1250 D(G(z)): -31105.7754 / -31133.9941 Elapsed 0.31 s\n",
      "[21/25][49/63] Loss_D: nan Loss_G: nan D(x): -27553.4160 D(G(z)): -31131.8691 / -31108.8496 Elapsed 0.32 s\n",
      "[21/25][50/63] Loss_D: nan Loss_G: nan D(x): -27450.2109 D(G(z)): -31142.0820 / -31090.4199 Elapsed 0.32 s\n",
      "[21/25][51/63] Loss_D: nan Loss_G: nan D(x): -27484.4668 D(G(z)): -31129.3008 / -31134.5371 Elapsed 0.32 s\n",
      "[21/25][52/63] Loss_D: nan Loss_G: nan D(x): -27471.1855 D(G(z)): -31132.8281 / -31153.0234 Elapsed 0.30 s\n",
      "[21/25][53/63] Loss_D: nan Loss_G: nan D(x): -27252.2285 D(G(z)): -31109.4336 / -31157.8281 Elapsed 0.32 s\n",
      "[21/25][54/63] Loss_D: nan Loss_G: nan D(x): -27399.3066 D(G(z)): -31124.7812 / -31130.1680 Elapsed 0.32 s\n",
      "[21/25][55/63] Loss_D: nan Loss_G: nan D(x): -27415.2129 D(G(z)): -31098.2637 / -31122.6270 Elapsed 0.30 s\n",
      "[21/25][56/63] Loss_D: nan Loss_G: nan D(x): -27393.0566 D(G(z)): -31197.3926 / -31238.3750 Elapsed 0.32 s\n",
      "[21/25][57/63] Loss_D: nan Loss_G: nan D(x): -27456.3477 D(G(z)): -31060.7129 / -31181.3008 Elapsed 0.32 s\n",
      "[21/25][58/63] Loss_D: nan Loss_G: nan D(x): -27473.6914 D(G(z)): -31147.4609 / -31070.6055 Elapsed 0.32 s\n",
      "[21/25][59/63] Loss_D: nan Loss_G: nan D(x): -27412.3320 D(G(z)): -31123.1914 / -31124.7461 Elapsed 0.30 s\n",
      "[21/25][60/63] Loss_D: nan Loss_G: nan D(x): -27301.9160 D(G(z)): -31180.3926 / -31077.6777 Elapsed 0.31 s\n",
      "[21/25][61/63] Loss_D: nan Loss_G: nan D(x): -27380.2480 D(G(z)): -31172.9570 / -31140.4004 Elapsed 0.32 s\n",
      "[21/25][62/63] Loss_D: nan Loss_G: nan D(x): -27389.6465 D(G(z)): -31128.0898 / -31224.6953 Elapsed 0.15 s\n",
      "[22/25][0/63] Loss_D: nan Loss_G: nan D(x): -27330.6387 D(G(z)): -31066.9746 / -31142.0117 Elapsed 0.33 s\n",
      "[22/25][1/63] Loss_D: nan Loss_G: nan D(x): -27401.0410 D(G(z)): -31092.0098 / -31147.2305 Elapsed 0.32 s\n",
      "[22/25][2/63] Loss_D: nan Loss_G: nan D(x): -27288.4531 D(G(z)): -31116.0684 / -31133.6113 Elapsed 0.32 s\n",
      "[22/25][3/63] Loss_D: nan Loss_G: nan D(x): -27418.6680 D(G(z)): -31143.4141 / -31150.9570 Elapsed 0.30 s\n",
      "[22/25][4/63] Loss_D: nan Loss_G: nan D(x): -27347.6504 D(G(z)): -31153.2070 / -31144.8027 Elapsed 0.30 s\n",
      "[22/25][5/63] Loss_D: nan Loss_G: nan D(x): -27401.3809 D(G(z)): -31124.2559 / -31137.9785 Elapsed 0.32 s\n",
      "[22/25][6/63] Loss_D: nan Loss_G: nan D(x): -27381.4492 D(G(z)): -31138.5332 / -31139.0098 Elapsed 0.33 s\n",
      "[22/25][7/63] Loss_D: nan Loss_G: nan D(x): -27457.0820 D(G(z)): -31139.0996 / -31094.6387 Elapsed 0.30 s\n",
      "[22/25][8/63] Loss_D: nan Loss_G: nan D(x): -27331.3574 D(G(z)): -31118.4043 / -31148.4375 Elapsed 0.32 s\n",
      "[22/25][9/63] Loss_D: nan Loss_G: nan D(x): -27377.0957 D(G(z)): -31107.8770 / -31117.3066 Elapsed 0.31 s\n",
      "[22/25][10/63] Loss_D: nan Loss_G: nan D(x): -27291.1270 D(G(z)): -31044.4375 / -31204.7559 Elapsed 0.32 s\n",
      "[22/25][11/63] Loss_D: nan Loss_G: nan D(x): -27175.4102 D(G(z)): -31068.6191 / -31088.3242 Elapsed 0.32 s\n",
      "[22/25][12/63] Loss_D: nan Loss_G: nan D(x): -27592.4102 D(G(z)): -31132.0039 / -31138.9590 Elapsed 0.32 s\n",
      "[22/25][13/63] Loss_D: nan Loss_G: nan D(x): -27373.4805 D(G(z)): -31188.7285 / -31126.7188 Elapsed 0.32 s\n",
      "[22/25][14/63] Loss_D: nan Loss_G: nan D(x): -27337.6465 D(G(z)): -31177.7324 / -31164.5078 Elapsed 0.32 s\n",
      "[22/25][15/63] Loss_D: nan Loss_G: nan D(x): -27645.6816 D(G(z)): -31092.7090 / -31093.9375 Elapsed 0.32 s\n",
      "[22/25][16/63] Loss_D: nan Loss_G: nan D(x): -27403.1289 D(G(z)): -31144.9180 / -31199.1816 Elapsed 0.31 s\n",
      "[22/25][17/63] Loss_D: nan Loss_G: nan D(x): -27316.9785 D(G(z)): -31157.5078 / -31082.5645 Elapsed 0.32 s\n",
      "[22/25][18/63] Loss_D: nan Loss_G: nan D(x): -27277.1348 D(G(z)): -31162.7559 / -31115.6309 Elapsed 0.32 s\n",
      "[22/25][19/63] Loss_D: nan Loss_G: nan D(x): -27350.6895 D(G(z)): -31095.0312 / -31177.8535 Elapsed 0.32 s\n",
      "[22/25][20/63] Loss_D: nan Loss_G: nan D(x): -27377.0703 D(G(z)): -31196.4023 / -31077.2656 Elapsed 0.30 s\n",
      "[22/25][21/63] Loss_D: nan Loss_G: nan D(x): -27467.3477 D(G(z)): -31214.3477 / -31127.1914 Elapsed 0.32 s\n",
      "[22/25][22/63] Loss_D: nan Loss_G: nan D(x): -27314.2754 D(G(z)): -31228.2266 / -31141.1582 Elapsed 0.32 s\n",
      "[22/25][23/63] Loss_D: nan Loss_G: nan D(x): -27441.4258 D(G(z)): -31114.6582 / -31113.3340 Elapsed 0.33 s\n",
      "[22/25][24/63] Loss_D: nan Loss_G: nan D(x): -27571.7637 D(G(z)): -31117.0918 / -31215.3242 Elapsed 0.31 s\n",
      "[22/25][25/63] Loss_D: nan Loss_G: nan D(x): -27384.3184 D(G(z)): -31144.0898 / -31107.2227 Elapsed 0.30 s\n",
      "[22/25][26/63] Loss_D: nan Loss_G: nan D(x): -27309.7422 D(G(z)): -31102.9258 / -31153.2969 Elapsed 0.30 s\n",
      "[22/25][27/63] Loss_D: nan Loss_G: nan D(x): -27462.8203 D(G(z)): -31138.9375 / -31166.7285 Elapsed 0.32 s\n",
      "[22/25][28/63] Loss_D: nan Loss_G: nan D(x): -27332.7539 D(G(z)): -31081.5938 / -31130.7754 Elapsed 0.32 s\n",
      "[22/25][29/63] Loss_D: nan Loss_G: nan D(x): -27318.6582 D(G(z)): -31077.8770 / -31102.4102 Elapsed 0.30 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/25][30/63] Loss_D: nan Loss_G: nan D(x): -27473.5605 D(G(z)): -31192.3301 / -31073.6152 Elapsed 0.30 s\n",
      "[22/25][31/63] Loss_D: nan Loss_G: nan D(x): -27360.8066 D(G(z)): -31137.2617 / -31293.1855 Elapsed 0.32 s\n",
      "[22/25][32/63] Loss_D: nan Loss_G: nan D(x): -27362.8984 D(G(z)): -31196.8867 / -31045.0039 Elapsed 0.30 s\n",
      "[22/25][33/63] Loss_D: nan Loss_G: nan D(x): -27510.0742 D(G(z)): -31123.7969 / -31149.2812 Elapsed 0.34 s\n",
      "[22/25][34/63] Loss_D: nan Loss_G: nan D(x): -27325.2695 D(G(z)): -31066.9805 / -31070.4512 Elapsed 0.32 s\n",
      "[22/25][35/63] Loss_D: nan Loss_G: nan D(x): -27365.0117 D(G(z)): -31144.4277 / -31156.0312 Elapsed 0.32 s\n",
      "[22/25][36/63] Loss_D: nan Loss_G: nan D(x): -27329.3359 D(G(z)): -31064.1641 / -31146.5625 Elapsed 0.32 s\n",
      "[22/25][37/63] Loss_D: nan Loss_G: nan D(x): -27346.3398 D(G(z)): -31146.7480 / -31137.1895 Elapsed 0.32 s\n",
      "[22/25][38/63] Loss_D: nan Loss_G: nan D(x): -27261.1387 D(G(z)): -31117.1406 / -31127.5898 Elapsed 0.32 s\n",
      "[22/25][39/63] Loss_D: nan Loss_G: nan D(x): -27358.7129 D(G(z)): -31137.0840 / -31107.1250 Elapsed 0.30 s\n",
      "[22/25][40/63] Loss_D: nan Loss_G: nan D(x): -27279.8184 D(G(z)): -31144.1660 / -31145.7773 Elapsed 0.32 s\n",
      "[22/25][41/63] Loss_D: nan Loss_G: nan D(x): -27249.7129 D(G(z)): -31182.5332 / -31162.9668 Elapsed 0.30 s\n",
      "[22/25][42/63] Loss_D: nan Loss_G: nan D(x): -27341.0664 D(G(z)): -31104.7207 / -31091.4629 Elapsed 0.32 s\n",
      "[22/25][43/63] Loss_D: nan Loss_G: nan D(x): -27223.9141 D(G(z)): -31078.7207 / -31054.3242 Elapsed 0.32 s\n",
      "[22/25][44/63] Loss_D: nan Loss_G: nan D(x): -27306.5410 D(G(z)): -31134.4531 / -31101.7656 Elapsed 0.32 s\n",
      "[22/25][45/63] Loss_D: nan Loss_G: nan D(x): -27431.6133 D(G(z)): -31194.7617 / -31130.8281 Elapsed 0.32 s\n",
      "[22/25][46/63] Loss_D: nan Loss_G: nan D(x): -27454.7910 D(G(z)): -31068.4551 / -31111.8535 Elapsed 0.30 s\n",
      "[22/25][47/63] Loss_D: nan Loss_G: nan D(x): -27401.2520 D(G(z)): -31112.5996 / -31157.4414 Elapsed 0.32 s\n",
      "[22/25][48/63] Loss_D: nan Loss_G: nan D(x): -27340.5137 D(G(z)): -31169.4473 / -31141.0977 Elapsed 0.31 s\n",
      "[22/25][49/63] Loss_D: nan Loss_G: nan D(x): -27301.9375 D(G(z)): -31085.0605 / -31096.5820 Elapsed 0.32 s\n",
      "[22/25][50/63] Loss_D: nan Loss_G: nan D(x): -27430.8320 D(G(z)): -31161.8906 / -31107.0156 Elapsed 0.32 s\n",
      "[22/25][51/63] Loss_D: nan Loss_G: nan D(x): -27240.6914 D(G(z)): -31159.5664 / -31092.4453 Elapsed 0.32 s\n",
      "[22/25][52/63] Loss_D: nan Loss_G: nan D(x): -27417.0215 D(G(z)): -31170.6172 / -31108.4785 Elapsed 0.32 s\n",
      "[22/25][53/63] Loss_D: nan Loss_G: nan D(x): -27449.5020 D(G(z)): -31137.8438 / -31091.4570 Elapsed 0.32 s\n",
      "[22/25][54/63] Loss_D: nan Loss_G: nan D(x): -27326.7422 D(G(z)): -31131.6113 / -31144.9707 Elapsed 0.32 s\n",
      "[22/25][55/63] Loss_D: nan Loss_G: nan D(x): -27380.6016 D(G(z)): -31128.5742 / -31115.4043 Elapsed 0.30 s\n",
      "[22/25][56/63] Loss_D: nan Loss_G: nan D(x): -27527.9805 D(G(z)): -31160.1641 / -31080.3730 Elapsed 0.32 s\n",
      "[22/25][57/63] Loss_D: nan Loss_G: nan D(x): -27281.0488 D(G(z)): -31128.9043 / -31167.6309 Elapsed 0.32 s\n",
      "[22/25][58/63] Loss_D: nan Loss_G: nan D(x): -27355.9102 D(G(z)): -31104.6055 / -31134.0020 Elapsed 0.32 s\n",
      "[22/25][59/63] Loss_D: nan Loss_G: nan D(x): -27423.8789 D(G(z)): -31100.3438 / -31061.7754 Elapsed 0.32 s\n",
      "[22/25][60/63] Loss_D: nan Loss_G: nan D(x): -27357.5371 D(G(z)): -31005.7090 / -31186.7070 Elapsed 0.32 s\n",
      "[22/25][61/63] Loss_D: nan Loss_G: nan D(x): -27368.6660 D(G(z)): -31152.7598 / -31123.9648 Elapsed 0.32 s\n",
      "[22/25][62/63] Loss_D: nan Loss_G: nan D(x): -27375.9902 D(G(z)): -31141.4961 / -31172.1094 Elapsed 0.17 s\n",
      "[23/25][0/63] Loss_D: nan Loss_G: nan D(x): -27233.9414 D(G(z)): -31067.5215 / -31170.1582 Elapsed 0.32 s\n",
      "[23/25][1/63] Loss_D: nan Loss_G: nan D(x): -27429.8711 D(G(z)): -31239.3848 / -31176.0410 Elapsed 0.30 s\n",
      "[23/25][2/63] Loss_D: nan Loss_G: nan D(x): -27346.5586 D(G(z)): -31164.4395 / -31095.5254 Elapsed 0.30 s\n",
      "[23/25][3/63] Loss_D: nan Loss_G: nan D(x): -27316.4258 D(G(z)): -31166.4844 / -31126.4375 Elapsed 0.32 s\n",
      "[23/25][4/63] Loss_D: nan Loss_G: nan D(x): -27258.6348 D(G(z)): -31098.7480 / -31116.5020 Elapsed 0.30 s\n",
      "[23/25][5/63] Loss_D: nan Loss_G: nan D(x): -27404.6875 D(G(z)): -31112.6758 / -31107.9824 Elapsed 0.30 s\n",
      "[23/25][6/63] Loss_D: nan Loss_G: nan D(x): -27398.4492 D(G(z)): -31115.6328 / -31111.4316 Elapsed 0.30 s\n",
      "[23/25][7/63] Loss_D: nan Loss_G: nan D(x): -27423.4062 D(G(z)): -31128.0859 / -31151.5879 Elapsed 0.32 s\n",
      "[23/25][8/63] Loss_D: nan Loss_G: nan D(x): -27372.0742 D(G(z)): -31124.9355 / -31214.4004 Elapsed 0.30 s\n",
      "[23/25][9/63] Loss_D: nan Loss_G: nan D(x): -27407.1211 D(G(z)): -31055.2793 / -31120.1113 Elapsed 0.30 s\n",
      "[23/25][10/63] Loss_D: nan Loss_G: nan D(x): -27404.1230 D(G(z)): -31131.7988 / -31226.5605 Elapsed 0.30 s\n",
      "[23/25][11/63] Loss_D: nan Loss_G: nan D(x): -27369.4629 D(G(z)): -31198.9434 / -31108.1113 Elapsed 0.30 s\n",
      "[23/25][12/63] Loss_D: nan Loss_G: nan D(x): -27465.8457 D(G(z)): -31115.6895 / -31205.4609 Elapsed 0.32 s\n",
      "[23/25][13/63] Loss_D: nan Loss_G: nan D(x): -27432.9258 D(G(z)): -31128.3535 / -31123.3652 Elapsed 0.32 s\n",
      "[23/25][14/63] Loss_D: nan Loss_G: nan D(x): -27361.4883 D(G(z)): -31131.0625 / -31100.7266 Elapsed 0.30 s\n",
      "[23/25][15/63] Loss_D: nan Loss_G: nan D(x): -27343.8867 D(G(z)): -31154.1777 / -31172.5820 Elapsed 0.30 s\n",
      "[23/25][16/63] Loss_D: nan Loss_G: nan D(x): -27470.4688 D(G(z)): -31155.9062 / -31082.6230 Elapsed 0.31 s\n",
      "[23/25][17/63] Loss_D: nan Loss_G: nan D(x): -27261.0215 D(G(z)): -31158.8887 / -31079.8965 Elapsed 0.31 s\n",
      "[23/25][18/63] Loss_D: nan Loss_G: nan D(x): -27361.1660 D(G(z)): -31166.9355 / -31152.3047 Elapsed 0.31 s\n",
      "[23/25][19/63] Loss_D: nan Loss_G: nan D(x): -27306.4512 D(G(z)): -31145.8438 / -31155.8848 Elapsed 0.32 s\n",
      "[23/25][20/63] Loss_D: nan Loss_G: nan D(x): -27401.9883 D(G(z)): -31110.8867 / -31090.5781 Elapsed 0.30 s\n",
      "[23/25][21/63] Loss_D: nan Loss_G: nan D(x): -27294.1621 D(G(z)): -31123.3145 / -31135.2383 Elapsed 0.32 s\n",
      "[23/25][22/63] Loss_D: nan Loss_G: nan D(x): -27358.9316 D(G(z)): -31118.2539 / -31201.1953 Elapsed 0.32 s\n",
      "[23/25][23/63] Loss_D: nan Loss_G: nan D(x): -27420.1016 D(G(z)): -31109.5410 / -31128.2832 Elapsed 0.32 s\n",
      "[23/25][24/63] Loss_D: nan Loss_G: nan D(x): -27413.1953 D(G(z)): -31085.7168 / -31143.7852 Elapsed 0.32 s\n",
      "[23/25][25/63] Loss_D: nan Loss_G: nan D(x): -27469.4844 D(G(z)): -31146.3125 / -31092.8223 Elapsed 0.30 s\n",
      "[23/25][26/63] Loss_D: nan Loss_G: nan D(x): -27472.0820 D(G(z)): -31110.5195 / -31076.4863 Elapsed 0.30 s\n",
      "[23/25][27/63] Loss_D: nan Loss_G: nan D(x): -27307.5840 D(G(z)): -31112.4121 / -31164.7461 Elapsed 0.30 s\n",
      "[23/25][28/63] Loss_D: nan Loss_G: nan D(x): -27411.2051 D(G(z)): -31154.4180 / -31062.0508 Elapsed 0.30 s\n",
      "[23/25][29/63] Loss_D: nan Loss_G: nan D(x): -27384.2852 D(G(z)): -31170.4863 / -31105.4961 Elapsed 0.32 s\n",
      "[23/25][30/63] Loss_D: nan Loss_G: nan D(x): -27447.3496 D(G(z)): -31194.8496 / -31126.6289 Elapsed 0.32 s\n",
      "[23/25][31/63] Loss_D: nan Loss_G: nan D(x): -27340.1074 D(G(z)): -31146.4102 / -31220.3613 Elapsed 0.32 s\n",
      "[23/25][32/63] Loss_D: nan Loss_G: nan D(x): -27339.2539 D(G(z)): -31095.9648 / -31091.3906 Elapsed 0.30 s\n",
      "[23/25][33/63] Loss_D: nan Loss_G: nan D(x): -27293.7344 D(G(z)): -31046.0684 / -31124.8066 Elapsed 0.32 s\n",
      "[23/25][34/63] Loss_D: nan Loss_G: nan D(x): -27505.0625 D(G(z)): -31184.5566 / -31150.2637 Elapsed 0.32 s\n",
      "[23/25][35/63] Loss_D: nan Loss_G: nan D(x): -27486.0723 D(G(z)): -31157.1719 / -31096.9336 Elapsed 0.30 s\n",
      "[23/25][36/63] Loss_D: nan Loss_G: nan D(x): -27446.0957 D(G(z)): -31096.3574 / -31265.7285 Elapsed 0.32 s\n",
      "[23/25][37/63] Loss_D: nan Loss_G: nan D(x): -27395.2070 D(G(z)): -31127.9707 / -31111.8184 Elapsed 0.30 s\n",
      "[23/25][38/63] Loss_D: nan Loss_G: nan D(x): -27405.3789 D(G(z)): -31167.3320 / -31135.3281 Elapsed 0.32 s\n",
      "[23/25][39/63] Loss_D: nan Loss_G: nan D(x): -27164.3613 D(G(z)): -31049.7168 / -31103.5312 Elapsed 0.30 s\n",
      "[23/25][40/63] Loss_D: nan Loss_G: nan D(x): -27251.6094 D(G(z)): -31040.0449 / -31162.7578 Elapsed 0.30 s\n",
      "[23/25][41/63] Loss_D: nan Loss_G: nan D(x): -27436.0176 D(G(z)): -31147.6426 / -31104.2070 Elapsed 0.32 s\n",
      "[23/25][42/63] Loss_D: nan Loss_G: nan D(x): -27379.2793 D(G(z)): -31178.5371 / -31159.0176 Elapsed 0.30 s\n",
      "[23/25][43/63] Loss_D: nan Loss_G: nan D(x): -27483.5684 D(G(z)): -31095.7441 / -31107.1973 Elapsed 0.30 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23/25][44/63] Loss_D: nan Loss_G: nan D(x): -27240.4824 D(G(z)): -31052.5605 / -31218.2773 Elapsed 0.30 s\n",
      "[23/25][45/63] Loss_D: nan Loss_G: nan D(x): -27427.3242 D(G(z)): -31158.7598 / -31094.3848 Elapsed 0.32 s\n",
      "[23/25][46/63] Loss_D: nan Loss_G: nan D(x): -27486.7852 D(G(z)): -31161.2246 / -31177.2383 Elapsed 0.30 s\n",
      "[23/25][47/63] Loss_D: nan Loss_G: nan D(x): -27377.7910 D(G(z)): -31134.0176 / -31119.7480 Elapsed 0.30 s\n",
      "[23/25][48/63] Loss_D: nan Loss_G: nan D(x): -27398.6816 D(G(z)): -31097.8008 / -31141.5820 Elapsed 0.30 s\n",
      "[23/25][49/63] Loss_D: nan Loss_G: nan D(x): -27439.4043 D(G(z)): -31204.9980 / -31230.0801 Elapsed 0.32 s\n",
      "[23/25][50/63] Loss_D: nan Loss_G: nan D(x): -27344.3320 D(G(z)): -31131.2090 / -31098.7734 Elapsed 0.32 s\n",
      "[23/25][51/63] Loss_D: nan Loss_G: nan D(x): -27177.4844 D(G(z)): -31222.6172 / -31206.6992 Elapsed 0.32 s\n",
      "[23/25][52/63] Loss_D: nan Loss_G: nan D(x): -27453.3711 D(G(z)): -31074.6328 / -31078.7637 Elapsed 0.32 s\n",
      "[23/25][53/63] Loss_D: nan Loss_G: nan D(x): -27414.7871 D(G(z)): -31140.0977 / -31120.6504 Elapsed 0.30 s\n",
      "[23/25][54/63] Loss_D: nan Loss_G: nan D(x): -27276.1348 D(G(z)): -31118.3203 / -31124.6035 Elapsed 0.32 s\n",
      "[23/25][55/63] Loss_D: nan Loss_G: nan D(x): -27487.1465 D(G(z)): -31037.4199 / -31056.4551 Elapsed 0.32 s\n",
      "[23/25][56/63] Loss_D: nan Loss_G: nan D(x): -27454.7051 D(G(z)): -31057.1719 / -31106.2891 Elapsed 0.30 s\n",
      "[23/25][57/63] Loss_D: nan Loss_G: nan D(x): -27415.9805 D(G(z)): -31224.2383 / -31171.7852 Elapsed 0.32 s\n",
      "[23/25][58/63] Loss_D: nan Loss_G: nan D(x): -27402.7617 D(G(z)): -31098.6250 / -31074.0840 Elapsed 0.32 s\n",
      "[23/25][59/63] Loss_D: nan Loss_G: nan D(x): -27413.2578 D(G(z)): -31170.2871 / -31200.5312 Elapsed 0.30 s\n",
      "[23/25][60/63] Loss_D: nan Loss_G: nan D(x): -27399.3906 D(G(z)): -31147.3809 / -31120.1914 Elapsed 0.32 s\n",
      "[23/25][61/63] Loss_D: nan Loss_G: nan D(x): -27343.2266 D(G(z)): -31127.0664 / -31121.7695 Elapsed 0.32 s\n",
      "[23/25][62/63] Loss_D: nan Loss_G: nan D(x): -27444.3203 D(G(z)): -31093.6797 / -31023.1504 Elapsed 0.18 s\n",
      "[24/25][0/63] Loss_D: nan Loss_G: nan D(x): -27363.1699 D(G(z)): -31123.7949 / -31153.7207 Elapsed 0.33 s\n",
      "[24/25][1/63] Loss_D: nan Loss_G: nan D(x): -27436.1094 D(G(z)): -31148.1426 / -31104.1914 Elapsed 0.33 s\n",
      "[24/25][2/63] Loss_D: nan Loss_G: nan D(x): -27415.5723 D(G(z)): -31093.3867 / -31180.1680 Elapsed 0.37 s\n",
      "[24/25][3/63] Loss_D: nan Loss_G: nan D(x): -27364.4473 D(G(z)): -31224.9707 / -31230.5703 Elapsed 0.37 s\n",
      "[24/25][4/63] Loss_D: nan Loss_G: nan D(x): -27485.6582 D(G(z)): -31113.9863 / -31144.7715 Elapsed 0.34 s\n",
      "[24/25][5/63] Loss_D: nan Loss_G: nan D(x): -27396.2012 D(G(z)): -31186.5098 / -31146.2910 Elapsed 0.31 s\n",
      "[24/25][6/63] Loss_D: nan Loss_G: nan D(x): -27442.0391 D(G(z)): -31069.3086 / -31207.1543 Elapsed 0.30 s\n",
      "[24/25][7/63] Loss_D: nan Loss_G: nan D(x): -27332.9102 D(G(z)): -31165.7832 / -31113.5840 Elapsed 0.30 s\n",
      "[24/25][8/63] Loss_D: nan Loss_G: nan D(x): -27494.8535 D(G(z)): -31124.0723 / -31130.5430 Elapsed 0.32 s\n",
      "[24/25][9/63] Loss_D: nan Loss_G: nan D(x): -27423.0957 D(G(z)): -31190.6465 / -31165.0039 Elapsed 0.33 s\n",
      "[24/25][10/63] Loss_D: nan Loss_G: nan D(x): -27318.2578 D(G(z)): -31138.5195 / -31048.3672 Elapsed 0.37 s\n",
      "[24/25][11/63] Loss_D: nan Loss_G: nan D(x): -27447.5137 D(G(z)): -31131.0742 / -31136.9023 Elapsed 0.33 s\n",
      "[24/25][12/63] Loss_D: nan Loss_G: nan D(x): -27293.4082 D(G(z)): -31124.0625 / -31122.1621 Elapsed 0.36 s\n",
      "[24/25][13/63] Loss_D: nan Loss_G: nan D(x): -27523.5195 D(G(z)): -31202.5820 / -31118.6016 Elapsed 0.33 s\n",
      "[24/25][14/63] Loss_D: nan Loss_G: nan D(x): -27287.4043 D(G(z)): -31212.9980 / -31150.3613 Elapsed 0.33 s\n",
      "[24/25][15/63] Loss_D: nan Loss_G: nan D(x): -27463.6055 D(G(z)): -31062.0059 / -31060.7832 Elapsed 0.35 s\n",
      "[24/25][16/63] Loss_D: nan Loss_G: nan D(x): -27387.2773 D(G(z)): -31171.2383 / -31074.0527 Elapsed 0.35 s\n",
      "[24/25][17/63] Loss_D: nan Loss_G: nan D(x): -27250.8633 D(G(z)): -31154.3535 / -31105.3887 Elapsed 0.33 s\n",
      "[24/25][18/63] Loss_D: nan Loss_G: nan D(x): -27558.7031 D(G(z)): -31164.7480 / -31171.0586 Elapsed 0.32 s\n",
      "[24/25][19/63] Loss_D: nan Loss_G: nan D(x): -27433.1836 D(G(z)): -31113.0996 / -31199.0723 Elapsed 0.32 s\n",
      "[24/25][20/63] Loss_D: nan Loss_G: nan D(x): -27362.2539 D(G(z)): -31183.5547 / -31172.7988 Elapsed 0.32 s\n",
      "[24/25][21/63] Loss_D: nan Loss_G: nan D(x): -27344.5000 D(G(z)): -31085.8398 / -31124.4570 Elapsed 0.32 s\n",
      "[24/25][22/63] Loss_D: nan Loss_G: nan D(x): -27377.6738 D(G(z)): -31162.2500 / -31164.2578 Elapsed 0.32 s\n",
      "[24/25][23/63] Loss_D: nan Loss_G: nan D(x): -27243.8516 D(G(z)): -31080.8691 / -31161.0137 Elapsed 0.32 s\n",
      "[24/25][24/63] Loss_D: nan Loss_G: nan D(x): -27410.3262 D(G(z)): -31140.7559 / -31100.9004 Elapsed 0.31 s\n",
      "[24/25][25/63] Loss_D: nan Loss_G: nan D(x): -27320.3027 D(G(z)): -31155.9531 / -31151.1562 Elapsed 0.30 s\n",
      "[24/25][26/63] Loss_D: nan Loss_G: nan D(x): -27292.2461 D(G(z)): -31077.4141 / -31151.9570 Elapsed 0.31 s\n",
      "[24/25][27/63] Loss_D: nan Loss_G: nan D(x): -27309.6875 D(G(z)): -31183.4551 / -31156.3320 Elapsed 0.32 s\n",
      "[24/25][28/63] Loss_D: nan Loss_G: nan D(x): -27330.4590 D(G(z)): -31157.0840 / -31090.9023 Elapsed 0.32 s\n",
      "[24/25][29/63] Loss_D: nan Loss_G: nan D(x): -27476.3652 D(G(z)): -31046.4922 / -31190.9883 Elapsed 0.35 s\n",
      "[24/25][30/63] Loss_D: nan Loss_G: nan D(x): -27420.1758 D(G(z)): -31169.9121 / -31175.6973 Elapsed 0.32 s\n",
      "[24/25][31/63] Loss_D: nan Loss_G: nan D(x): -27232.3867 D(G(z)): -30995.7617 / -31134.1270 Elapsed 0.34 s\n",
      "[24/25][32/63] Loss_D: nan Loss_G: nan D(x): -27366.9707 D(G(z)): -31110.2852 / -31146.6250 Elapsed 0.33 s\n",
      "[24/25][33/63] Loss_D: nan Loss_G: nan D(x): -27269.4844 D(G(z)): -31110.7910 / -31149.3105 Elapsed 0.33 s\n",
      "[24/25][34/63] Loss_D: nan Loss_G: nan D(x): -27322.2617 D(G(z)): -31103.0195 / -31114.7949 Elapsed 0.34 s\n",
      "[24/25][35/63] Loss_D: nan Loss_G: nan D(x): -27345.3770 D(G(z)): -31113.3496 / -31137.2734 Elapsed 0.32 s\n",
      "[24/25][36/63] Loss_D: nan Loss_G: nan D(x): -27337.6934 D(G(z)): -31167.0625 / -31115.2852 Elapsed 0.33 s\n",
      "[24/25][37/63] Loss_D: nan Loss_G: nan D(x): -27400.3223 D(G(z)): -31186.4648 / -31171.8398 Elapsed 0.32 s\n",
      "[24/25][38/63] Loss_D: nan Loss_G: nan D(x): -27417.2930 D(G(z)): -31152.3848 / -31067.4531 Elapsed 0.30 s\n",
      "[24/25][39/63] Loss_D: nan Loss_G: nan D(x): -27506.3457 D(G(z)): -31091.7793 / -31105.8730 Elapsed 0.32 s\n",
      "[24/25][40/63] Loss_D: nan Loss_G: nan D(x): -27379.0977 D(G(z)): -31105.5488 / -31105.6484 Elapsed 0.32 s\n",
      "[24/25][41/63] Loss_D: nan Loss_G: nan D(x): -27158.0859 D(G(z)): -31153.2441 / -31152.4199 Elapsed 0.32 s\n",
      "[24/25][42/63] Loss_D: nan Loss_G: nan D(x): -27370.7676 D(G(z)): -31203.7695 / -31173.9551 Elapsed 0.33 s\n",
      "[24/25][43/63] Loss_D: nan Loss_G: nan D(x): -27435.6504 D(G(z)): -31185.3125 / -31203.6855 Elapsed 0.32 s\n",
      "[24/25][44/63] Loss_D: nan Loss_G: nan D(x): -27487.6152 D(G(z)): -31160.5527 / -31173.2383 Elapsed 0.30 s\n",
      "[24/25][45/63] Loss_D: nan Loss_G: nan D(x): -27454.3926 D(G(z)): -31154.2930 / -31182.6621 Elapsed 0.32 s\n",
      "[24/25][46/63] Loss_D: nan Loss_G: nan D(x): -27305.4160 D(G(z)): -31197.0332 / -31168.8379 Elapsed 0.33 s\n",
      "[24/25][47/63] Loss_D: nan Loss_G: nan D(x): -27415.2461 D(G(z)): -31151.6973 / -31157.2324 Elapsed 0.32 s\n",
      "[24/25][48/63] Loss_D: nan Loss_G: nan D(x): -27505.6504 D(G(z)): -31150.4004 / -31102.6738 Elapsed 0.32 s\n",
      "[24/25][49/63] Loss_D: nan Loss_G: nan D(x): -27362.3379 D(G(z)): -31063.9375 / -31068.4805 Elapsed 0.33 s\n",
      "[24/25][50/63] Loss_D: nan Loss_G: nan D(x): -27194.7402 D(G(z)): -31124.0430 / -31149.8320 Elapsed 0.32 s\n",
      "[24/25][51/63] Loss_D: nan Loss_G: nan D(x): -27259.8828 D(G(z)): -31107.8887 / -31094.9277 Elapsed 0.32 s\n",
      "[24/25][52/63] Loss_D: nan Loss_G: nan D(x): -27288.6621 D(G(z)): -31116.1953 / -31197.6328 Elapsed 0.33 s\n",
      "[24/25][53/63] Loss_D: nan Loss_G: nan D(x): -27425.3145 D(G(z)): -31155.0938 / -31077.4648 Elapsed 0.32 s\n",
      "[24/25][54/63] Loss_D: nan Loss_G: nan D(x): -27361.3066 D(G(z)): -31094.6582 / -31192.4023 Elapsed 0.32 s\n",
      "[24/25][55/63] Loss_D: nan Loss_G: nan D(x): -27308.7773 D(G(z)): -31179.6445 / -31185.0723 Elapsed 0.32 s\n",
      "[24/25][56/63] Loss_D: nan Loss_G: nan D(x): -27344.0430 D(G(z)): -31134.4141 / -31140.1484 Elapsed 0.32 s\n",
      "[24/25][57/63] Loss_D: nan Loss_G: nan D(x): -27372.3008 D(G(z)): -31090.5234 / -31069.0098 Elapsed 0.30 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24/25][58/63] Loss_D: nan Loss_G: nan D(x): -27456.0879 D(G(z)): -31117.3262 / -31155.1953 Elapsed 0.32 s\n",
      "[24/25][59/63] Loss_D: nan Loss_G: nan D(x): -27294.6875 D(G(z)): -31085.3379 / -31048.6094 Elapsed 0.31 s\n",
      "[24/25][60/63] Loss_D: nan Loss_G: nan D(x): -27288.2129 D(G(z)): -31210.2070 / -31111.8145 Elapsed 0.30 s\n",
      "[24/25][61/63] Loss_D: nan Loss_G: nan D(x): -27404.2871 D(G(z)): -31131.5312 / -31174.8691 Elapsed 0.31 s\n",
      "[24/25][62/63] Loss_D: nan Loss_G: nan D(x): -27412.5898 D(G(z)): -31093.9277 / -31106.1445 Elapsed 0.17 s\n"
     ]
    }
   ],
   "source": [
    "train_both_networks(num_epochs=25, dataloader=dataloaders['train'], netD=D, netG=G, d_labelSmooth=0.1,\n",
    "                    outputDir='./generated_images', model_option=1, binary = False, epoch_interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
