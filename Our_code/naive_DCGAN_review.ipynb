{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fake_2 = fake.detach()\n",
    "\n",
    "#Usar o fixed_noise para salvar as imagens!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System properties and libs currently in use\n",
    "- We have developed using python 3.5.x, pytorch 0.2.1\n",
    "- No significant attention was given to backwards compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__Python VERSION: 3.5.3 |Anaconda 4.4.0 (64-bit)| (default, Mar  6 2017, 11:58:13) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
      "__pyTorch VERSION: 0.2.0_4\n",
      "__CUDA VERSION\n",
      "__CUDNN VERSION: 6021\n",
      "__Number CUDA Devices: 1\n",
      "__Devices\n",
      "Active CUDA Device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "print('Active CUDA Device: GPU', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities\n",
    "- Saving images and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_images(netG, fixed_noise, outputDir,epoch):\n",
    "    '''\n",
    "    Generates a batch of images from the given 'noise'.\n",
    "    Saves 64 of the generated samples to 'outputDir' system path.\n",
    "    Inputs are the network (netG), a 'noise' input, system path to which images will be saved (outputDir) and current 'epoch'.\n",
    "    '''\n",
    "    assert isinstance(fixed_noise,torch.autograd.variable.Variable)\n",
    "    netG.eval()\n",
    "    fake = netG(noise)\n",
    "    netG.train()\n",
    "    vutils.save_image(fake.data[0:64,:,:,:],'%s/fake_samples_epoch_%03d.png' % (outputDir, epoch), nrow=8)\n",
    "\n",
    "def save_models(netG, netD, outputDir, epoch):\n",
    "    '''\n",
    "    Saves model state dictionary for generator and discriminator networks.\n",
    "    Inputs are the networks (netG, netD), the system path in which to save(outputDir) and the current 'epoch'.\n",
    "    '''\n",
    "    torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (outputDir, epoch))\n",
    "    torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (outputDir, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using CUDA. If it is not what you want, manually set this as False!\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "cudnn.benchmark = True\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"You are using CUDA. If it is not what you want, manually set this as False!\")\n",
    "print(use_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Directory\n",
    "This is where images will be saved to.\n",
    "\n",
    "If directory does not exist, it is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS error: [Errno 17] File exists: 'outputdir_train_classifier_teste2'\n"
     ]
    }
   ],
   "source": [
    "outputDir = 'outputdir_train_classifier_teste2'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset definition and hyperparameter setting\n",
    "- Changing dataset name alters network architecture parameters\n",
    "- Currently supporting few datasets\n",
    "- Hyperparameters defined according to Radford et al. (2015)\n",
    "\n",
    "Valores típicos são\n",
    "\n",
    "nc = 3,\n",
    "\n",
    "ngpu = 1,\n",
    "\n",
    "nz = 100,\n",
    "\n",
    "ngf = 64,\n",
    "\n",
    "ndf = 64,\n",
    "\n",
    "n_extra_d = 0,\n",
    "\n",
    "n_extra_g = 1,\n",
    "\n",
    "imageSize = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "chosen_dataset = 'MNIST'\n",
    "\n",
    "datasets = {\n",
    "    'MNIST': torchvision.datasets.MNIST,\n",
    "    'CIFAR10': torchvision.datasets.CIFAR10,\n",
    "    'ANIME': '/home/gabriel/Redes Neurais/Projeto_Final_GANS/Tutorial_2/dataset/min_anime-faces',\n",
    "}\n",
    "\n",
    "dataset = datasets[chosen_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "possible_parameters = {\n",
    "    'MNIST': {\n",
    "        'ndf': 64,\n",
    "        'ngf': 64,\n",
    "        'nz': 100,\n",
    "        'nc': 1,\n",
    "        'imageSize': 28,\n",
    "        'n_classes' : 10,\n",
    "        'ngpu': 1,\n",
    "    },\n",
    "    'CIFAR10': {\n",
    "        'ndf': 64,\n",
    "        'ngf': 64,\n",
    "        'nz': 100,\n",
    "        'nc': 3,\n",
    "        'imageSize' : 64,\n",
    "        'n_classes' : 10,\n",
    "        'ngpu' : 1,\n",
    "    },\n",
    "    'ANIME': {\n",
    "        'nc' : 3,\n",
    "        'ngpu' : 1,\n",
    "        'nz' : 100,\n",
    "        'ngf' : 64,\n",
    "        'ndf' : 64,\n",
    "        'imageSize' : 64,\n",
    "        'n_classes' : 1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngf = possible_parameters[chosen_dataset]['ngf']\n",
    "ndf = possible_parameters[chosen_dataset]['ndf']\n",
    "nz = possible_parameters[chosen_dataset]['nz']\n",
    "nc = possible_parameters[chosen_dataset]['nc']\n",
    "imageSize = possible_parameters[chosen_dataset]['imageSize']\n",
    "n_classes = possible_parameters[chosen_dataset]['n_classes']\n",
    "ngpu = possible_parameters[chosen_dataset]['ngpu']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader length: 938\n",
      "Dataset: <torchvision.datasets.mnist.MNIST object at 0x7ff69e048128>\n"
     ]
    }
   ],
   "source": [
    "if dataset == 'ANIME':\n",
    "    dataset = torchvision.datasets.ImageFolder(\n",
    "        root='/home/gabriel/Redes Neurais/Projeto_Final_GANS/Tutorial_2/dataset/min_anime-faces',\n",
    "        transform=transforms.Compose([\n",
    "                transforms.Scale((imageSize, imageSize)),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "    )\n",
    "else:\n",
    "    transform = transforms.Compose([\n",
    "                    transforms.Scale((imageSize, imageSize)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)), # bring images to (-1,1)\n",
    "                ]) \n",
    "    dataset_done = dataset('./datasets', train=True, download=True, transform=transform)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset_done, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "print('Dataloader length:', len(dataloader))\n",
    "print(\"Dataset:\", dataloader.dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição dos modelos\n",
    "- Model is a DCGAN\n",
    "- Images are sized (nc, 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netD_DCGAN(nn.Module):\n",
    "    def __init__(self, ngpu, nz, nc, ndf, n_classes):\n",
    "        super(_netD_DCGAN, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.conv1 = nn.Conv2d(in_channels = nc, out_channels = ndf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(in_channels = ndf, out_channels = ndf*2, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch2 = nn.BatchNorm2d(ndf * 2)\n",
    "        self.conv3 = nn.Conv2d(in_channels = ndf*2, out_channels = ndf*4, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch3 = nn.BatchNorm2d(ndf * 4)\n",
    "        self.conv4 = nn.Conv2d(in_channels = ndf*4, out_channels = ndf*8, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch4 = nn.BatchNorm2d(ndf * 8)\n",
    "        \n",
    "        #self.final_conv = nn.Conv2d(in_channels=ndf*8, out_channels=n_classes+1,kernel_size=4,stride=1,padding=0,bias=False)\n",
    "        self.final_conv = nn.Conv2d(in_channels=ndf*8, out_channels=1,kernel_size=4,stride=1,padding=0,bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch2(self.conv2(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch3(self.conv3(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch4(self.conv4(x)), 0.2, inplace=True)\n",
    "        x = self.final_conv(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        #x = x.view(-1, 1).squeeze(1)\n",
    "\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netG_DCGAN(nn.Module):\n",
    "    def __init__(self, ngpu, nz, nc , ngf):\n",
    "        super(_netG_DCGAN, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.convt1 = nn.ConvTranspose2d(in_channels=nz, out_channels=ngf * 8, kernel_size=4, stride=1, padding=0, bias=False)\n",
    "        self.batch1 = nn.BatchNorm2d(ngf*8)\n",
    "        self.convt2 = nn.ConvTranspose2d(in_channels=ngf * 8, out_channels=ngf * 4, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch2 = nn.BatchNorm2d(ngf*4)\n",
    "        self.convt3 = nn.ConvTranspose2d(in_channels=ngf * 4, out_channels=ngf * 2, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch3 = nn.BatchNorm2d(ngf*2)\n",
    "        self.convt4 = nn.ConvTranspose2d(in_channels=ngf*2, out_channels=ngf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch4 = nn.BatchNorm2d(ngf)\n",
    "        \n",
    "        self.final_convt = nn.ConvTranspose2d(in_channels=ngf, out_channels=nc, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.batch1(self.convt1(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch2(self.convt2(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch3(self.convt3(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch4(self.convt4(x)), 0.2, inplace=True)\n",
    "        \n",
    "        x = self.final_convt(x)\n",
    "        x = F.tanh(x)\n",
    "        return (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netG_DCGAN_MNIST(nn.Module):\n",
    "    def __init__(self, nz, nc, ngf=64):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(nz, ngf * 4, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # state size. (ngf*4) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # state size. (ngf*2) x 7 x 7\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # state size. (ngf) x 14 x 14\n",
    "            nn.ConvTranspose2d(ngf, nc, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.Tanh()\n",
    "            \n",
    "            # state size. (nc) x 28 x 28\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netD_DCGAN_MNIST(nn.Module):\n",
    "    def __init__(self, nc, ndf=64):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 28 x 28\n",
    "            nn.Conv2d(nc, ndf, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. (ndf) x 14 x 14\n",
    "            nn.Conv2d(ndf, ndf * 2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. (ndf*2) x 7 x 7\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. (ndf*4) x 4 x 4\n",
    "            nn.Conv2d(ndf * 4, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output.view(-1, 1).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#netG = _netG_DCGAN(ngpu, nz, nc, ngf)\n",
    "netG = _netG_DCGAN_MNIST(nz=nz, nc=nc, ngf=64)\n",
    "#netD = _netD_DCGAN(ngpu, nz, nc, ndf, n_classes)\n",
    "netD = _netD_DCGAN_MNIST(nc=nc, ndf=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializador de pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_netG_DCGAN_MNIST (\n",
      "  (main): Sequential (\n",
      "    (0): ConvTranspose2d(100, 256, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU (inplace)\n",
      "    (3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): ReLU (inplace)\n",
      "    (6): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (8): ReLU (inplace)\n",
      "    (9): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): Tanh ()\n",
      "  )\n",
      ") \n",
      " _netD_DCGAN_MNIST (\n",
      "  (main): Sequential (\n",
      "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU (0.2, inplace)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (4): LeakyReLU (0.2, inplace)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (7): LeakyReLU (0.2, inplace)\n",
      "    (8): Conv2d(256, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (9): Sigmoid ()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)\n",
    "print(netG, '\\n', netD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses\n",
    "- Binary Cross-Entropy is used to differentiate real and fake images\n",
    "- Class loss should be Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sizes of the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label = torch.FloatTensor(batch_size)\n",
    "print(label.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input images size: torch.Size([64, 3, 28, 28])\n",
      "Code size: torch.Size([64, 100, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# make our input tensors\n",
    "d_input = torch.FloatTensor(batch_size, 3, imageSize, imageSize)\n",
    "print('Input images size:', d_input.size())\n",
    "#nz its the latent dimension\n",
    "noise = torch.FloatTensor(batch_size, nz, 1, 1)\n",
    "fixed_noise = torch.FloatTensor(batch_size, nz, 1, 1).normal_(0, 1)\n",
    "print('Code size:', noise.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label size: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "#label = torch.LongTensor(batch_size,n_classes)\n",
    "label = torch.LongTensor(batch_size)\n",
    "print('Label size:', label.size())\n",
    "#fake_label = 10\n",
    "fake_label = 0\n",
    "real_label = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcast to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (77) : an illegal memory access was encountered at /opt/conda/conda-bld/pytorch_1503968623488/work/torch/lib/THC/generic/THCTensorCopy.c:18",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-3b8c690c4ec9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mnetD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mnetG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0md_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device_id)\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0mcopied\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \"\"\"\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0;31m# Variables stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0mcopied\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \"\"\"\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (77) : an illegal memory access was encountered at /opt/conda/conda-bld/pytorch_1503968623488/work/torch/lib/THC/generic/THCTensorCopy.c:18"
     ]
    }
   ],
   "source": [
    "if use_gpu:\n",
    "    netD.cuda()\n",
    "    netG.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    d_input,label = d_input.cuda(), label.cuda()\n",
    "    noise, fixed_noise = noise.cuda(), fixed_noise.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning tensors into Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "d_input = Variable(d_input)\n",
    "label = Variable(label)\n",
    "noise = Variable(noise)\n",
    "fixed_noise = Variable(fixed_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer Parameters\n",
    "- Following the lead of Radford et al., 2015:\n",
    "\n",
    "    <b>\n",
    "    1. beta1 = 0.5\n",
    "    2. beta2 = 0.999\n",
    "    3. lr = 0.0002\n",
    "    </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta1, beta2 = 0.5, 0.999\n",
    "lr = 2.0e-4\n",
    "optimizerD = optim.Adam(netD.parameters(), lr = lr, betas = (beta1, beta2))\n",
    "#optimizerD = optim.Adam(netD_parallel.parameters(), lr = lr, betas = (beta1, beta2))\n",
    "\n",
    "optimizerG = optim.Adam(netG.parameters(), lr = lr, betas = (beta1, beta2))\n",
    "#optimizerG = optim.Adam(netG_parallel.parameters(), lr = lr, betas = (beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (77) : an illegal memory access was encountered at /opt/conda/conda-bld/pytorch_1503968623488/work/torch/lib/THC/generic/THCTensorCopy.c:18",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-1e0ccb6b3e8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_input_G\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_input_G\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input_G\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_output_G\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Generator output size:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_output_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mthen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device_id, async)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCudaTransfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torch/autograd/_functions/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i, device_id, async)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (77) : an illegal memory access was encountered at /opt/conda/conda-bld/pytorch_1503968623488/work/torch/lib/THC/generic/THCTensorCopy.c:18"
     ]
    }
   ],
   "source": [
    "test_input_G = torch.randn(64, 100, 1, 1)\n",
    "test_input_G = Variable(test_input_G)\n",
    "test_output_G = netG(test_input_G.cuda())\n",
    "print('Generator output size:', test_output_G.size())\n",
    "then = time.time()\n",
    "test_output_D = netD(test_output_G)\n",
    "now = time.time()\n",
    "print('Discriminator output size:', test_output_D.size())\n",
    "print(\"Time taken: {0:.5f} s\".format(now-then))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Treinamento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(np.random.random_sample())\n",
    "#real_labelSmooth = 0.2\n",
    "#print(real_labelSmooth)\n",
    "#target = torch.from_numpy(np.random.randint(0, n_classes, batch_size)).type(torch.LongTensor).cuda()\n",
    "#print(target.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "print(d_input.size())\n",
    "print(label.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_gan(num_epochs, dataloader, netD, netG, outputDir, label, noise,\n",
    "              real_labelSmooth=0, epoch_interval=100, D_steps=1, G_steps=1):\n",
    "    \n",
    "    # This validation is subjective. WGAN-GP uses 100 steps on the critic (netD).\n",
    "    assert D_steps < 5, \"Keep it low, D_steps is too high.\"\n",
    "    assert G_steps < 3, \"Keep it low, G_steps is too high.\"\n",
    "    #assert batch_size % D_steps == 0, \"Use batch_size multiple of D_steps.\"\n",
    "    real_label = 1\n",
    "    print('Lets train!')\n",
    "    for epoch in range(num_epochs):\n",
    "        start_iter = time.time()  \n",
    "        D_x = 0\n",
    "        D_G_z1 = 0\n",
    "        D_G_z2 = 0\n",
    "        errD_acum = 0\n",
    "        errG_acum = 0\n",
    "\n",
    "        for batch, data in enumerate(dataloader, 0):\n",
    "            if (epoch == 0 and batch == 0):\n",
    "                    vutils.save_image(data[0][0:64,:,:,:], '%s/real_samples.png' % outputDir, nrow=8)\n",
    "            for step in range(D_steps):\n",
    "                #############################################################\n",
    "                # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "                # 1A - Train the detective network in the Real Dataset\n",
    "                #############################################################\n",
    "                netD.zero_grad()\n",
    "                start = step*(int(data[0].size()[0]/D_steps))\n",
    "                end = (step+1)*int(data[0].size()[0]/D_steps)\n",
    "                #real_cpu = data[0][start:end]\n",
    "                #if use_gpu:\n",
    "                    #real_cpu = real_cpu.cuda()\n",
    "                #d_input.resize_as_(data[0][start:end]).copy_(data[0][start:end])\n",
    "                d_input.data.resize_(data[0][start:end].size()).copy_(data[0][start:end])\n",
    "                \n",
    "                batch_size = data[0][start:end].size(0)\n",
    "                #batch_size = real_cpu.size(0)\n",
    "                \n",
    "                #label.data.resize_(batch_size).fill_(real_label - d_labelSmooth) # use smooth label for discriminator\n",
    "                label.data.resize_(batch_size).fill_(real_label)\n",
    "\n",
    "                \n",
    "                #  if np.random.random_sample() > real_labelSmooth:        \n",
    "                #target = data[1][start:end].long().cuda()\n",
    "                #else:\n",
    "                #     target = torch.from_numpy(np.random.randint(0, n_classes, batch_size)).type(torch.LongTensor).cuda()\n",
    "                \n",
    "                #d_input, label = Variable(real_cpu), Variable(target)\n",
    "                \n",
    "                output = netD(d_input)\n",
    "                errD_real = criterion(output.squeeze(),label.float())\n",
    "                #errD_real = criterion(output,label)\n",
    "                \n",
    "                errD_real.backward()\n",
    "                \n",
    "                D_x += output.data.mean()\n",
    "                \n",
    "                #######################################################\n",
    "                # 1B - Train the detective network in the False Dataset\n",
    "                #######################################################\n",
    "                \n",
    "                noise = Variable(torch.FloatTensor(batch_size, nz, 1, 1).normal_(0,1).cuda())\n",
    "                fake = netG(noise)\n",
    "                #label = Variable(torch.ones(batch_size).long().fill_(fake_label).cuda())\n",
    "                label.data.resize_(batch_size).fill_(fake_label)\n",
    "                \n",
    "                output = netD(fake.detach()) # \".detach()\" to avoid backprop through G\n",
    "                \n",
    "                errD_fake = criterion(output.squeeze(), label.float())\n",
    "                errD_fake.backward() # gradients for fake and real data will be accumulated\n",
    "                \n",
    "                D_G_z1 += output.data.mean()\n",
    "                errD_acum += errD_real.data[0] + errD_fake.data[0]\n",
    "                optimizerD.step() # .step() can be called once the gradients are computed\n",
    "\n",
    "            for step in range(G_steps):\n",
    "                ####################################################################################\n",
    "                # (2) Update G network: maximize log(D(G(z)))\n",
    "                # Train the faker with the output from the Detective (but don't train the Detective)\n",
    "                ####################################################################################\n",
    "                \n",
    "                netG.zero_grad()\n",
    "                #tudo 1\n",
    "                #label = Variable(torch.from_numpy(np.random.randint(0, n_classes, batch_size)).type(torch.LongTensor).cuda())\n",
    "                #label = Variable(torch.ones(batch_size).long().fill_(real_label).cuda())\n",
    "                label.data.resize_(batch_size).fill_(real_label)\n",
    "                \n",
    "                output = netD(fake)\n",
    "                errG = criterion(output.squeeze(), label.float())\n",
    "                errG.backward()\n",
    "                \n",
    "                D_G_z2 += output.data.mean()\n",
    "                errG_acum += errG.data[0]\n",
    "                optimizerG.step()\n",
    "            #del input, noise, label, output\n",
    "\n",
    "        print('epoch = ',epoch)\n",
    "\n",
    "        end_iter = time.time()        \n",
    "\n",
    "        print('[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z1)): %.4f D(G(z2)) %.4f Time Elapsed %.2f s'\n",
    "            % (epoch, num_epochs, errD_acum/D_steps, errG_acum/G_steps, D_x, D_G_z1, D_G_z2, end_iter-start_iter))\n",
    "\n",
    "        #Save a grid with the pictures from the dataset, up until 64\n",
    "        save_images(netG = netG, fixed_noise=  fixed_noise, outputDir = outputDir, epoch = epoch)\n",
    "\n",
    "        if epoch % epoch_interval == 0:\n",
    "            # do checkpointing\n",
    "            save_models(netG = netG, netD = netD, outputDir = outputDir, epoch = epoch)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets train!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (77) : an illegal memory access was encountered at /opt/conda/conda-bld/pytorch_1503968623488/work/torch/lib/THC/generic/THCTensorCopy.c:18",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-8480d048f294>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mreal_labelSmooth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnetG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputDir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_labelSmooth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-98-9a68fc8001bf>\u001b[0m in \u001b[0;36mtrain_gan\u001b[0;34m(num_epochs, dataloader, netD, netG, outputDir, label, noise, real_labelSmooth, epoch_interval, D_steps, G_steps)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;31m#######################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0;31m#label = Variable(torch.ones(batch_size).long().fill_(fake_label).cuda())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (77) : an illegal memory access was encountered at /opt/conda/conda-bld/pytorch_1503968623488/work/torch/lib/THC/generic/THCTensorCopy.c:18"
     ]
    }
   ],
   "source": [
    "num_epochs = 25\n",
    "real_labelSmooth = 0.2\n",
    "\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir,label,noise, real_labelSmooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = torch.randn(10,10)\n",
    "teste = Variable(teste)\n",
    "print(teste.data.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
