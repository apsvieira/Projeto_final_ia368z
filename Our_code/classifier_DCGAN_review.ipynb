{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System properties and libs currently in use\n",
    "- We have developed using python 3.5.x, pytorch 0.2.1\n",
    "- No significant attention was given to backwards compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__Python VERSION: 3.5.3 |Anaconda 4.4.0 (64-bit)| (default, Mar  6 2017, 11:58:13) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
      "__pyTorch VERSION: 0.2.0_4\n",
      "__CUDA VERSION\n",
      "__CUDNN VERSION: 6021\n",
      "__Number CUDA Devices: 1\n",
      "__Devices\n",
      "Active CUDA Device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "print('Active CUDA Device: GPU', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities\n",
    "- Saving images and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_images(netG, fixed_noise, outputDir,epoch):\n",
    "    '''\n",
    "    Generates a batch of images from the given 'noise'.\n",
    "    Saves 64 of the generated samples to 'outputDir' system path.\n",
    "    Inputs are the network (netG), a 'noise' input, system path to which images will be saved (outputDir) and current 'epoch'.\n",
    "    '''\n",
    "    noise = Variable(fixed_noise)\n",
    "    netG.eval()\n",
    "    fake = netG(noise)\n",
    "    netG.train()\n",
    "    vutils.save_image(fake.data[0:64,:,:,:],'%s/fake_samples_epoch_%03d.png' % (outputDir, epoch), nrow=8)\n",
    "\n",
    "def save_models(netG, netD, outputDir, epoch):\n",
    "    '''\n",
    "    Saves model state dictionary for generator and discriminator networks.\n",
    "    Inputs are the networks (netG, netD), the system path in which to save(outputDir) and the current 'epoch'.\n",
    "    '''\n",
    "    torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (outputDir, epoch))\n",
    "    torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (outputDir, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using CUDA. If it is not what you want, manually set this as False!\n"
     ]
    }
   ],
   "source": [
    "cudnn.benchmark = True\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"You are using CUDA. If it is not what you want, manually set this as False!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Directory\n",
    "This is where images will be saved to.\n",
    "\n",
    "If directory does not exist, it is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS error: [Errno 17] File exists: 'outputdir_train_classifier_lotufo'\n"
     ]
    }
   ],
   "source": [
    "outputDir = 'outputdir_train_classifier_lotufo'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset definition and hyperparameter setting\n",
    "- Changing dataset name alters network architecture parameters\n",
    "- Currently supporting few datasets\n",
    "- Hyperparameters defined according to Radford et al. (2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "chosen_dataset = 'MNIST'\n",
    "\n",
    "datasets = {\n",
    "    'MNIST': torchvision.datasets.MNIST,\n",
    "    'CIFAR10': torchvision.datasets.CIFAR10,\n",
    "    'ANIME': '/home/gabriel/Redes Neurais/Projeto_Final_GANS/Tutorial_2/dataset/min_anime-faces',\n",
    "}\n",
    "\n",
    "dataset = datasets[chosen_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "possible_parameters = {\n",
    "    'MNIST': {\n",
    "        'ndf': 64,\n",
    "        'ngf': 64,\n",
    "        'nz': 100,\n",
    "        'nc': 1,\n",
    "        'imageSize': 64,\n",
    "        'n_classes' : 10,\n",
    "        'ngpu': 1,\n",
    "    },\n",
    "    'CIFAR10': {\n",
    "        'ndf': 64,\n",
    "        'ngf': 64,\n",
    "        'nz': 100,\n",
    "        'nc': 3,\n",
    "        'imageSize' : 64,\n",
    "        'n_classes' : 10,\n",
    "        'ngpu' : 1,\n",
    "    },\n",
    "    'ANIME': {\n",
    "        'nc' : 3,\n",
    "        'ngpu' : 1,\n",
    "        'nz' : 100,\n",
    "        'ngf' : 64,\n",
    "        'ndf' : 64,\n",
    "        'imageSize' : 64,\n",
    "        'n_classes' : 1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngf = possible_parameters[chosen_dataset]['ngf']\n",
    "ndf = possible_parameters[chosen_dataset]['ndf']\n",
    "nz = possible_parameters[chosen_dataset]['nz']\n",
    "nc = possible_parameters[chosen_dataset]['nc']\n",
    "imageSize = possible_parameters[chosen_dataset]['imageSize']\n",
    "n_classes = possible_parameters[chosen_dataset]['n_classes']\n",
    "ngpu = possible_parameters[chosen_dataset]['ngpu']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader length: 469\n",
      "Dataset: <torchvision.datasets.mnist.MNIST object at 0x7f6b16d912e8>\n"
     ]
    }
   ],
   "source": [
    "if dataset == 'ANIME':\n",
    "    dataset = torchvision.datasets.ImageFolder(\n",
    "        root='/home/gabriel/Redes Neurais/Projeto_Final_GANS/Tutorial_2/dataset/min_anime-faces',\n",
    "        transform=transforms.Compose([\n",
    "                transforms.Scale((imageSize, imageSize)),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "    )\n",
    "else:\n",
    "    transform = transforms.Compose([\n",
    "                    transforms.Scale((imageSize, imageSize)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)), # bring images to (-1,1)\n",
    "                ]) \n",
    "    dataset_done = dataset('./datasets', train=True, download=True, transform=transform)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset_done, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "print('Dataloader length:', len(dataloader))\n",
    "print(\"Dataset:\", dataloader.dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição dos modelos\n",
    "- Model is a DCGAN\n",
    "- Images are sized (nc, 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netD_DCGAN(nn.Module):\n",
    "    def __init__(self, ngpu, nz, nc, ndf, n_classes):\n",
    "        super(_netD_DCGAN, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.conv1 = nn.Conv2d(in_channels = nc, out_channels = ndf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(in_channels = ndf, out_channels = ndf*2, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch2 = nn.BatchNorm2d(ndf * 2)\n",
    "        self.conv3 = nn.Conv2d(in_channels = ndf*2, out_channels = ndf*4, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch3 = nn.BatchNorm2d(ndf * 4)\n",
    "        self.conv4 = nn.Conv2d(in_channels = ndf*4, out_channels = ndf*8, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch4 = nn.BatchNorm2d(ndf * 8)\n",
    "        \n",
    "        self.final_conv = nn.Conv2d(in_channels=ndf*8, out_channels=n_classes+1,kernel_size=4,stride=1,padding=0,bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch2(self.conv2(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch3(self.conv3(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch4(self.conv4(x)), 0.2, inplace=True)\n",
    "        \n",
    "        x = self.final_conv(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netG_DCGAN(nn.Module):\n",
    "    def __init__(self, ngpu, nz, nc , ngf):\n",
    "        super(_netG_DCGAN, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.convt1 = nn.ConvTranspose2d(in_channels=nz, out_channels=ngf * 8, kernel_size=4, stride=1, padding=0, bias=False)\n",
    "        self.batch1 = nn.BatchNorm2d(ngf*8)\n",
    "        self.convt2 = nn.ConvTranspose2d(in_channels=ngf * 8, out_channels=ngf * 4, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch2 = nn.BatchNorm2d(ngf*4)\n",
    "        self.convt3 = nn.ConvTranspose2d(in_channels=ngf * 4, out_channels=ngf * 2, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch3 = nn.BatchNorm2d(ngf*2)\n",
    "        self.convt4 = nn.ConvTranspose2d(in_channels=ngf*2, out_channels=ngf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch4 = nn.BatchNorm2d(ngf)\n",
    "        \n",
    "        self.final_convt = nn.ConvTranspose2d(in_channels=ngf, out_channels=nc, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.batch1(self.convt1(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch2(self.convt2(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch3(self.convt3(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch4(self.convt4(x)), 0.2, inplace=True)\n",
    "        \n",
    "        x = self.final_convt(x)\n",
    "        x = F.tanh(x)\n",
    "        return (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netG = _netG_DCGAN(ngpu, nz, nc, ngf)\n",
    "netD = _netD_DCGAN(ngpu, nz, nc, ndf, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializador de pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_netG_DCGAN (\n",
      "  (convt1): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "  (batch1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (convt2): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (convt3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (convt4): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (final_convt): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      ") \n",
      " _netD_DCGAN (\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (conv3): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (conv4): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (final_conv): Conv2d(512, 11, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)\n",
    "print(netG, '\\n', netD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses\n",
    "- Binary Cross-Entropy is used to differentiate real and fake images\n",
    "- Class loss should be Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sizes of the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input images size: torch.Size([128, 3, 64, 64])\n",
      "Code size: torch.Size([128, 100, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "input = torch.FloatTensor(batch_size, 3, imageSize, imageSize)\n",
    "print('Input images size:', input.size())\n",
    "noise = torch.FloatTensor(batch_size, nz, 1, 1)\n",
    "fixed_noise = torch.FloatTensor(batch_size, nz, 1, 1).normal_(0, 1)\n",
    "print('Code size:', noise.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label size: torch.Size([128, 10])\n"
     ]
    }
   ],
   "source": [
    "label = torch.LongTensor(batch_size,n_classes)\n",
    "print('Label size:', label.size())\n",
    "fake_label = 10\n",
    "real_label = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcast to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    netD.cuda()\n",
    "    netG.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    input,label = input.cuda(), label.cuda()\n",
    "    noise, fixed_noise = noise.cuda(), fixed_noise.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer Parameters\n",
    "- Following the lead of Radford et al., 2015:\n",
    "\n",
    "    <b>\n",
    "    1. beta1 = 0.5\n",
    "    2. beta2 = 0.999\n",
    "    3. lr = 0.0002\n",
    "    </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta1, beta2 = 0.5, 0.999\n",
    "lr = 2.0e-4\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr = lr, betas = (beta1, beta2))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr = lr, betas = (beta1, beta2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Treinamento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_gan(num_epochs, dataloader, netD, netG, outputDir,\n",
    "              real_labelSmooth=0, epoch_interval=100, D_steps=1, G_steps=1, decay = 0.05):\n",
    "    \n",
    "    # This validation is subjective. WGAN-GP uses 100 steps on the critic (netD).\n",
    "    assert D_steps < 5, \"Keep it low, D_steps is too high.\"\n",
    "    assert G_steps < 3, \"Keep it low, G_steps is too high.\"\n",
    "    #assert batch_size % D_steps == 0, \"Use batch_size multiple of D_steps.\"\n",
    "    real_label = 1\n",
    "    print('Lets train!')\n",
    "    for epoch in range(num_epochs):\n",
    "        start_iter = time.time()  \n",
    "        D_x = 0\n",
    "        D_G_z1 = 0\n",
    "        D_G_z2 = 0\n",
    "        errD_acum = 0\n",
    "        errG_acum = 0\n",
    "        \n",
    "        print('In epoch = ', epoch, 'real_label_smooth = ',real_labelSmooth )\n",
    "        for batch, data in enumerate(dataloader, 0):\n",
    "            if (epoch == 0 and batch == 0):\n",
    "                    vutils.save_image(data[0][0:64,:,:,:], '%s/real_samples.png' % outputDir, nrow=8)\n",
    "            if epoch < 25:   \n",
    "                real_labelSmooth = np.maximum(real_labelSmooth * (1 - 0.05*epoch), 0)\n",
    "            else:\n",
    "                real_labelSmooth = 0\n",
    "            for step in range(D_steps):\n",
    "                #############################################################\n",
    "                # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "                # 1A - Train the detective network in the Real Dataset\n",
    "                #############################################################\n",
    "                netD.zero_grad()\n",
    "                start = step*(int(data[0].size()[0]/D_steps))\n",
    "                end = (step+1)*int(data[0].size()[0]/D_steps)\n",
    "                \n",
    "                real_cpu = data[0][start:end]\n",
    "                real_cpu = real_cpu.cuda()\n",
    "                batch_size = real_cpu.size(0)\n",
    "                if np.random.random_sample() > real_labelSmooth:\n",
    "                    target = data[1][start:end].long().cuda()\n",
    "                else:\n",
    "                     target = torch.from_numpy(np.random.randint(0, n_classes, batch_size)).type(torch.LongTensor).cuda()\n",
    "                \n",
    "                input, label = Variable(real_cpu), Variable(target)\n",
    "\n",
    "                output = netD(input)\n",
    "                errD_real = criterion(output.squeeze(),label)\n",
    "                errD_real.backward()\n",
    "                \n",
    "                D_x += output.data.mean()\n",
    "                \n",
    "                #######################################################\n",
    "                # 1B - Train the detective network in the False Dataset\n",
    "                #######################################################\n",
    "                \n",
    "                noise = Variable(torch.FloatTensor(batch_size, nz, 1, 1).normal_(0,1).cuda())\n",
    "                fake = netG(noise)\n",
    "                label = Variable(torch.ones(batch_size).long().fill_(fake_label).cuda())\n",
    "                output = netD(fake.detach()) # \".detach()\" to avoid backprop through G\n",
    "                errD_fake = criterion(output.squeeze(), label)\n",
    "                errD_fake.backward() # gradients for fake and real data will be accumulated\n",
    "                \n",
    "                D_G_z1 += output.data.mean()\n",
    "                errD_acum += errD_real.data[0] + errD_fake.data[0]\n",
    "                optimizerD.step()\n",
    "\n",
    "            for step in range(G_steps):\n",
    "                ####################################################################################\n",
    "                # (2) Update G network: maximize log(D(G(z)))\n",
    "                # Train the faker with the output from the Detective (but don't train the Detective)\n",
    "                ####################################################################################\n",
    "                \n",
    "                netG.zero_grad()\n",
    "                label = Variable(torch.from_numpy(np.random.randint(0, n_classes, batch_size)).type(torch.LongTensor).cuda())\n",
    "                output = netD(fake)\n",
    "                errG = criterion(output.squeeze(), label)\n",
    "                errG.backward()\n",
    "                \n",
    "                D_G_z2 += output.data.mean()\n",
    "                errG_acum += errG.data[0]\n",
    "                optimizerG.step()\n",
    "\n",
    "        print('epoch = ',epoch)\n",
    "\n",
    "        end_iter = time.time()        \n",
    "\n",
    "        print('[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f Elapsed %.2f s'\n",
    "              % (epoch, num_epochs, errD_acum/D_steps, errG_acum/G_steps, D_x, D_G_z1, D_G_z2, end_iter-start_iter))\n",
    "\n",
    "        #Save a grid with the pictures from the dataset, up until 64\n",
    "        save_images(netG = netG, fixed_noise=  fixed_noise, outputDir = outputDir, epoch = epoch)\n",
    "\n",
    "        if epoch % epoch_interval == 0:\n",
    "            # do checkpointing\n",
    "            save_models(netG = netG, netD = netD, outputDir = outputDir, epoch = epoch)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outputDir = 'outputdir_train_classifier_0d25'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "num_epochs = 25\n",
    "real_labelSmooth = 0.25\n",
    "decay = 0.025\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth, decay = decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outputDir = 'outputdir_train_classifier_0d15'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))\n",
    "    \n",
    "num_epochs = 100\n",
    "real_labelSmooth = 0.15\n",
    "\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outputDir = 'outputdir_train_classifier_0d20'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))\n",
    "    \n",
    "num_epochs = 100\n",
    "real_labelSmooth = 0.20\n",
    "\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outputDir = 'outputdir_train_classifier_0d10'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))\n",
    "    \n",
    "num_epochs = 100\n",
    "real_labelSmooth = 0.10\n",
    "\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outputDir = 'outputdir_train_classifier_decay_0d025_label_0d1'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))\n",
    "num_epochs = 40\n",
    "real_labelSmooth = 0.1\n",
    "decay = 0.025\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth, decay = decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outputDir = 'outputdir_train_classifier_decay_0d025_label_0d15'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))\n",
    "num_epochs = 40\n",
    "real_labelSmooth = 0.15\n",
    "decay = 0.025\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth, decay = decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outputDir = 'outputdir_train_classifier_decay_0d025_label_0d20'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))\n",
    "num_epochs = 40\n",
    "real_labelSmooth = 0.20\n",
    "decay = 0.025\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth, decay = decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outputDir = 'outputdir_train_classifier_decay_0d025_label_0d25'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))\n",
    "num_epochs = 40\n",
    "real_labelSmooth = 0.25\n",
    "decay = 0.025\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth, decay = decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outputDir = 'outputdir_train_classifier_decay_0d025_label_0d30'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))\n",
    "num_epochs = 40\n",
    "real_labelSmooth = 0.30\n",
    "decay = 0.025\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth, decay = decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outputDir = 'outputdir_train_classifier_decay_0d025_label_0d15'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))\n",
    "num_epochs = 40\n",
    "real_labelSmooth = 0.15\n",
    "decay = 0.025\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth, decay = decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outputDir = 'outputdir_train_classifier_decay_0d025_label_0d10'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))\n",
    "num_epochs = 40\n",
    "real_labelSmooth = 0.10\n",
    "decay = 0.025\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth, decay = decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outputDir = 'outputdir_train_classifier_decay_0d018_label_0d10'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))\n",
    "num_epochs = 40\n",
    "real_labelSmooth = 0.10\n",
    "decay = 0.018\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth, decay = decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outputDir = 'outputdir_train_classifier_decay_0d025_label_0d15'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))\n",
    "num_epochs = 40\n",
    "real_labelSmooth = 0.10\n",
    "decay = 0.018\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth, decay = decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets train!\n",
      "In epoch =  0 real_label_smooth =  0.15\n",
      "epoch =  0\n",
      "[0/40] Loss_D: 683.4500 Loss_G: 3620.1620 D(x): -400.8651 D(G(z)): -445.6175 / -453.9886 Elapsed 46.25 s\n",
      "In epoch =  1 real_label_smooth =  0.15\n",
      "epoch =  1\n",
      "[1/40] Loss_D: 174.6914 Loss_G: 4018.7320 D(x): -521.3670 D(G(z)): -552.2424 / -554.4528 Elapsed 44.45 s\n",
      "In epoch =  2 real_label_smooth =  5.35133500423e-12\n",
      "epoch =  2\n",
      "[2/40] Loss_D: 147.4305 Loss_G: 4895.4638 D(x): -809.0297 D(G(z)): -841.2120 / -843.0898 Elapsed 44.47 s\n",
      "In epoch =  3 real_label_smooth =  1.85438141721e-33\n",
      "epoch =  3\n",
      "[3/40] Loss_D: 115.6441 Loss_G: 5433.3562 D(x): -960.9524 D(G(z)): -997.7818 / -1000.2700 Elapsed 44.49 s\n",
      "In epoch =  4 real_label_smooth =  1.46445228692e-66\n",
      "epoch =  4\n",
      "[4/40] Loss_D: 152.1810 Loss_G: 5542.4809 D(x): -1138.0070 D(G(z)): -1168.1835 / -1171.3924 Elapsed 44.49 s\n",
      "In epoch =  5 real_label_smooth =  5.18655664962e-112\n",
      "epoch =  5\n",
      "[5/40] Loss_D: 116.6636 Loss_G: 5959.3384 D(x): -1339.5754 D(G(z)): -1382.4511 / -1385.3886 Elapsed 44.48 s\n",
      "In epoch =  6 real_label_smooth =  1.31404929176e-170\n",
      "epoch =  6\n",
      "[6/40] Loss_D: 118.6410 Loss_G: 6159.0135 D(x): -1404.0162 D(G(z)): -1449.5526 / -1454.6440 Elapsed 44.62 s\n",
      "In epoch =  7 real_label_smooth =  2.94844087419e-243\n",
      "epoch =  7\n",
      "[7/40] Loss_D: 119.5920 Loss_G: 6279.1202 D(x): -1492.6193 D(G(z)): -1550.3707 / -1553.7042 Elapsed 44.79 s\n",
      "In epoch =  8 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  8\n",
      "[8/40] Loss_D: 92.5818 Loss_G: 6383.0167 D(x): -1589.7095 D(G(z)): -1627.1281 / -1630.5100 Elapsed 44.98 s\n",
      "In epoch =  9 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  9\n",
      "[9/40] Loss_D: 113.4656 Loss_G: 6492.9888 D(x): -1715.9164 D(G(z)): -1762.2513 / -1766.2770 Elapsed 45.10 s\n",
      "In epoch =  10 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  10\n",
      "[10/40] Loss_D: 72.0593 Loss_G: 6758.6819 D(x): -1811.5534 D(G(z)): -1875.4799 / -1879.9272 Elapsed 45.14 s\n",
      "In epoch =  11 real_label_smooth =  0.0\n",
      "epoch =  11\n",
      "[11/40] Loss_D: 113.4045 Loss_G: 6803.4621 D(x): -1926.1914 D(G(z)): -1977.2755 / -1981.1643 Elapsed 45.10 s\n",
      "In epoch =  12 real_label_smooth =  0.0\n",
      "epoch =  12\n",
      "[12/40] Loss_D: 100.3327 Loss_G: 6898.4557 D(x): -1887.7341 D(G(z)): -1945.1011 / -1950.4713 Elapsed 45.03 s\n",
      "In epoch =  13 real_label_smooth =  0.0\n",
      "epoch =  13\n",
      "[13/40] Loss_D: 71.5284 Loss_G: 6979.4809 D(x): -2090.9214 D(G(z)): -2158.8121 / -2163.2841 Elapsed 45.10 s\n",
      "In epoch =  14 real_label_smooth =  0.0\n",
      "epoch =  14\n",
      "[14/40] Loss_D: 90.7801 Loss_G: 7110.2401 D(x): -2093.0738 D(G(z)): -2177.8421 / -2182.3298 Elapsed 45.31 s\n",
      "In epoch =  15 real_label_smooth =  0.0\n",
      "epoch =  15\n",
      "[15/40] Loss_D: 61.0146 Loss_G: 7330.0693 D(x): -2200.0341 D(G(z)): -2302.0282 / -2307.7672 Elapsed 45.16 s\n",
      "In epoch =  16 real_label_smooth =  0.0\n",
      "epoch =  16\n",
      "[16/40] Loss_D: 101.4153 Loss_G: 7245.9199 D(x): -2159.2125 D(G(z)): -2250.4353 / -2254.1680 Elapsed 45.25 s\n",
      "In epoch =  17 real_label_smooth =  0.0\n",
      "epoch =  17\n",
      "[17/40] Loss_D: 65.5137 Loss_G: 7375.4871 D(x): -2340.5161 D(G(z)): -2406.1049 / -2412.3087 Elapsed 45.35 s\n",
      "In epoch =  18 real_label_smooth =  0.0\n",
      "epoch =  18\n",
      "[18/40] Loss_D: 95.7124 Loss_G: 7603.2111 D(x): -2346.7340 D(G(z)): -2447.8036 / -2451.8204 Elapsed 45.24 s\n",
      "In epoch =  19 real_label_smooth =  0.0\n",
      "epoch =  19\n",
      "[19/40] Loss_D: 51.7640 Loss_G: 7725.3128 D(x): -2446.3012 D(G(z)): -2538.7040 / -2544.6447 Elapsed 45.38 s\n",
      "In epoch =  20 real_label_smooth =  0.0\n",
      "epoch =  20\n",
      "[20/40] Loss_D: 121.6611 Loss_G: 7606.8128 D(x): -2378.3227 D(G(z)): -2478.2139 / -2483.1530 Elapsed 45.44 s\n",
      "In epoch =  21 real_label_smooth =  0.0\n",
      "epoch =  21\n",
      "[21/40] Loss_D: 83.4852 Loss_G: 7714.8501 D(x): -2272.8665 D(G(z)): -2402.1570 / -2407.9385 Elapsed 45.48 s\n",
      "In epoch =  22 real_label_smooth =  -0.0\n",
      "epoch =  22\n",
      "[22/40] Loss_D: 81.9134 Loss_G: 7576.4607 D(x): -2339.6228 D(G(z)): -2396.3104 / -2401.6911 Elapsed 45.31 s\n",
      "In epoch =  23 real_label_smooth =  0.0\n",
      "epoch =  23\n",
      "[23/40] Loss_D: 64.8042 Loss_G: 7929.3088 D(x): -2427.9695 D(G(z)): -2536.9272 / -2542.0741 Elapsed 45.43 s\n",
      "In epoch =  24 real_label_smooth =  -0.0\n",
      "epoch =  24\n",
      "[24/40] Loss_D: 54.4951 Loss_G: 7922.5260 D(x): -2454.4307 D(G(z)): -2534.9111 / -2541.0979 Elapsed 45.40 s\n",
      "In epoch =  25 real_label_smooth =  0.0\n",
      "epoch =  25\n",
      "[25/40] Loss_D: 71.5432 Loss_G: 8115.3120 D(x): -2429.6164 D(G(z)): -2540.9023 / -2546.0376 Elapsed 45.24 s\n",
      "In epoch =  26 real_label_smooth =  0\n",
      "epoch =  26\n",
      "[26/40] Loss_D: 50.7335 Loss_G: 8387.5785 D(x): -2447.9467 D(G(z)): -2601.6119 / -2609.0415 Elapsed 45.41 s\n",
      "In epoch =  27 real_label_smooth =  0\n",
      "epoch =  27\n",
      "[27/40] Loss_D: 95.1853 Loss_G: 8017.3216 D(x): -2523.2590 D(G(z)): -2605.8939 / -2611.6167 Elapsed 45.46 s\n",
      "In epoch =  28 real_label_smooth =  0\n",
      "epoch =  28\n",
      "[28/40] Loss_D: 45.8822 Loss_G: 8313.5218 D(x): -2631.6898 D(G(z)): -2753.3145 / -2761.5971 Elapsed 45.46 s\n",
      "In epoch =  29 real_label_smooth =  0\n",
      "epoch =  29\n",
      "[29/40] Loss_D: 54.2675 Loss_G: 8411.5845 D(x): -2593.0280 D(G(z)): -2747.6149 / -2754.1362 Elapsed 45.41 s\n",
      "In epoch =  30 real_label_smooth =  0\n",
      "epoch =  30\n",
      "[30/40] Loss_D: 72.6111 Loss_G: 8384.0671 D(x): -2586.9515 D(G(z)): -2757.5392 / -2762.5424 Elapsed 45.58 s\n",
      "In epoch =  31 real_label_smooth =  0\n",
      "epoch =  31\n",
      "[31/40] Loss_D: 55.0266 Loss_G: 8402.0136 D(x): -2539.8183 D(G(z)): -2693.5153 / -2700.6814 Elapsed 45.57 s\n",
      "In epoch =  32 real_label_smooth =  0\n",
      "epoch =  32\n",
      "[32/40] Loss_D: 48.3299 Loss_G: 8673.8422 D(x): -2637.6013 D(G(z)): -2821.6075 / -2827.8911 Elapsed 45.52 s\n",
      "In epoch =  33 real_label_smooth =  0\n",
      "epoch =  33\n",
      "[33/40] Loss_D: 22.9796 Loss_G: 8521.7273 D(x): -2650.4332 D(G(z)): -2804.9846 / -2811.5898 Elapsed 45.57 s\n",
      "In epoch =  34 real_label_smooth =  0\n",
      "epoch =  34\n",
      "[34/40] Loss_D: 64.8744 Loss_G: 8767.3711 D(x): -2539.5959 D(G(z)): -2804.4869 / -2809.7768 Elapsed 45.58 s\n",
      "In epoch =  35 real_label_smooth =  0\n",
      "epoch =  35\n",
      "[35/40] Loss_D: 57.3503 Loss_G: 8549.3021 D(x): -2676.2179 D(G(z)): -2759.1286 / -2769.8468 Elapsed 45.62 s\n",
      "In epoch =  36 real_label_smooth =  0\n",
      "epoch =  36\n",
      "[36/40] Loss_D: 32.1758 Loss_G: 8953.0284 D(x): -2683.8091 D(G(z)): -2908.4380 / -2916.9944 Elapsed 45.66 s\n",
      "In epoch =  37 real_label_smooth =  0\n",
      "epoch =  37\n",
      "[37/40] Loss_D: 32.5803 Loss_G: 9077.9135 D(x): -2704.6302 D(G(z)): -2981.7494 / -2988.9966 Elapsed 45.59 s\n",
      "In epoch =  38 real_label_smooth =  0\n",
      "epoch =  38\n",
      "[38/40] Loss_D: 72.8968 Loss_G: 8739.7910 D(x): -2689.7028 D(G(z)): -2841.6261 / -2849.5641 Elapsed 45.70 s\n",
      "In epoch =  39 real_label_smooth =  0\n",
      "epoch =  39\n",
      "[39/40] Loss_D: 55.2638 Loss_G: 8888.5687 D(x): -2642.7814 D(G(z)): -2891.9954 / -2902.0973 Elapsed 45.50 s\n"
     ]
    }
   ],
   "source": [
    "outputDir = 'outputdir_train_classifier_decay_0d018_label_0d15'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))\n",
    "num_epochs = 40\n",
    "real_labelSmooth = 0.15\n",
    "decay = 0.018\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth, decay = decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets train!\n",
      "In epoch =  0 real_label_smooth =  0.2\n",
      "epoch =  0\n",
      "[0/40] Loss_D: 1008.1055 Loss_G: 2696.7562 D(x): -218.5605 D(G(z)): -273.4744 / -277.5046 Elapsed 45.66 s\n",
      "In epoch =  1 real_label_smooth =  0.2\n",
      "epoch =  1\n",
      "[1/40] Loss_D: 99.9920 Loss_G: 5067.1949 D(x): -851.7914 D(G(z)): -1025.8148 / -1038.1201 Elapsed 45.64 s\n",
      "In epoch =  2 real_label_smooth =  7.13511333898e-12\n",
      "epoch =  2\n",
      "[2/40] Loss_D: 63.8840 Loss_G: 6540.9229 D(x): -1260.8770 D(G(z)): -1458.2403 / -1464.9842 Elapsed 45.60 s\n",
      "In epoch =  3 real_label_smooth =  2.47250855628e-33\n",
      "epoch =  3\n",
      "[3/40] Loss_D: 40.4819 Loss_G: 7146.6697 D(x): -1499.2905 D(G(z)): -1719.7395 / -1725.8787 Elapsed 45.69 s\n",
      "In epoch =  4 real_label_smooth =  1.95260304923e-66\n",
      "epoch =  4\n",
      "[4/40] Loss_D: 46.8678 Loss_G: 7307.9216 D(x): -1478.4319 D(G(z)): -1714.4891 / -1724.3263 Elapsed 45.71 s\n",
      "In epoch =  5 real_label_smooth =  6.91540886616e-112\n",
      "epoch =  5\n",
      "[5/40] Loss_D: 4.4276 Loss_G: 8256.0018 D(x): -1581.1736 D(G(z)): -2104.8753 / -2110.7320 Elapsed 45.59 s\n",
      "In epoch =  6 real_label_smooth =  1.75206572235e-170\n",
      "epoch =  6\n",
      "[6/40] Loss_D: 92.4355 Loss_G: 7300.2142 D(x): -1448.6861 D(G(z)): -1628.6612 / -1634.6701 Elapsed 45.58 s\n",
      "In epoch =  7 real_label_smooth =  3.93125449892e-243\n",
      "epoch =  7\n",
      "[7/40] Loss_D: 36.4894 Loss_G: 7926.5454 D(x): -1754.3350 D(G(z)): -2017.8323 / -2028.8965 Elapsed 45.71 s\n",
      "In epoch =  8 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  8\n",
      "[8/40] Loss_D: 66.5325 Loss_G: 8101.7828 D(x): -1724.1329 D(G(z)): -2017.4498 / -2025.0898 Elapsed 45.66 s\n",
      "In epoch =  9 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  9\n",
      "[9/40] Loss_D: 37.3823 Loss_G: 8073.7012 D(x): -1928.6907 D(G(z)): -2149.7300 / -2158.7467 Elapsed 45.65 s\n",
      "In epoch =  10 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  10\n",
      "[10/40] Loss_D: 47.0093 Loss_G: 8196.1394 D(x): -1830.6810 D(G(z)): -2135.0582 / -2142.9609 Elapsed 45.66 s\n",
      "In epoch =  11 real_label_smooth =  0.0\n",
      "epoch =  11\n",
      "[11/40] Loss_D: 53.7550 Loss_G: 8457.3405 D(x): -1924.2741 D(G(z)): -2243.4498 / -2251.8217 Elapsed 45.68 s\n",
      "In epoch =  12 real_label_smooth =  0.0\n",
      "epoch =  12\n",
      "[12/40] Loss_D: 33.5021 Loss_G: 8476.2950 D(x): -1988.9003 D(G(z)): -2237.1976 / -2249.3915 Elapsed 45.73 s\n",
      "In epoch =  13 real_label_smooth =  0.0\n",
      "epoch =  13\n",
      "[13/40] Loss_D: 39.4936 Loss_G: 8861.5375 D(x): -1913.7983 D(G(z)): -2368.0787 / -2375.7036 Elapsed 45.65 s\n",
      "In epoch =  14 real_label_smooth =  0.0\n",
      "epoch =  14\n",
      "[14/40] Loss_D: 53.1903 Loss_G: 8527.5578 D(x): -2108.5092 D(G(z)): -2323.8133 / -2333.9458 Elapsed 45.69 s\n",
      "In epoch =  15 real_label_smooth =  0.0\n",
      "epoch =  15\n",
      "[15/40] Loss_D: 29.3608 Loss_G: 9040.7002 D(x): -2008.2287 D(G(z)): -2456.6541 / -2470.1109 Elapsed 45.74 s\n",
      "In epoch =  16 real_label_smooth =  0.0\n",
      "epoch =  16\n",
      "[16/40] Loss_D: 62.0433 Loss_G: 8612.2839 D(x): -1871.6906 D(G(z)): -2183.6935 / -2190.6787 Elapsed 45.68 s\n",
      "In epoch =  17 real_label_smooth =  0.0\n",
      "epoch =  17\n",
      "[17/40] Loss_D: 52.8705 Loss_G: 8703.0023 D(x): -2199.1394 D(G(z)): -2334.3314 / -2345.0601 Elapsed 45.76 s\n",
      "In epoch =  18 real_label_smooth =  0.0\n",
      "epoch =  18\n",
      "[18/40] Loss_D: 3.2457 Loss_G: 9704.6553 D(x): -2176.0518 D(G(z)): -2783.9465 / -2791.1165 Elapsed 45.65 s\n",
      "In epoch =  19 real_label_smooth =  0.0\n",
      "epoch =  19\n",
      "[19/40] Loss_D: 35.9898 Loss_G: 9156.6711 D(x): -2181.8145 D(G(z)): -2528.2363 / -2537.0525 Elapsed 45.70 s\n",
      "In epoch =  20 real_label_smooth =  0.0\n",
      "epoch =  20\n",
      "[20/40] Loss_D: 39.5455 Loss_G: 9198.3204 D(x): -2199.3445 D(G(z)): -2547.9388 / -2559.7650 Elapsed 45.58 s\n",
      "In epoch =  21 real_label_smooth =  0.0\n",
      "epoch =  21\n",
      "[21/40] Loss_D: 44.5164 Loss_G: 9220.7065 D(x): -2224.0708 D(G(z)): -2561.2900 / -2571.3333 Elapsed 45.67 s\n",
      "In epoch =  22 real_label_smooth =  -0.0\n",
      "epoch =  22\n",
      "[22/40] Loss_D: 34.5443 Loss_G: 9223.4957 D(x): -2204.2696 D(G(z)): -2561.8254 / -2570.7858 Elapsed 45.63 s\n",
      "In epoch =  23 real_label_smooth =  0.0\n",
      "epoch =  23\n",
      "[23/40] Loss_D: 3.2496 Loss_G: 10046.1613 D(x): -2169.1613 D(G(z)): -2878.8851 / -2890.1927 Elapsed 45.60 s\n",
      "In epoch =  24 real_label_smooth =  -0.0\n",
      "epoch =  24\n",
      "[24/40] Loss_D: 69.7562 Loss_G: 8974.8196 D(x): -2113.0813 D(G(z)): -2320.7080 / -2330.0175 Elapsed 45.76 s\n",
      "In epoch =  25 real_label_smooth =  0.0\n",
      "epoch =  25\n",
      "[25/40] Loss_D: 16.2739 Loss_G: 9741.6806 D(x): -2231.4509 D(G(z)): -2699.4038 / -2708.8305 Elapsed 45.60 s\n",
      "In epoch =  26 real_label_smooth =  0\n",
      "epoch =  26\n",
      "[26/40] Loss_D: 1.5013 Loss_G: 10322.9097 D(x): -2118.6315 D(G(z)): -2891.4139 / -2896.7658 Elapsed 45.65 s\n",
      "In epoch =  27 real_label_smooth =  0\n",
      "epoch =  27\n",
      "[27/40] Loss_D: 0.6287 Loss_G: 10132.2194 D(x): -2119.2498 D(G(z)): -2925.5830 / -2929.8451 Elapsed 45.70 s\n",
      "In epoch =  28 real_label_smooth =  0\n",
      "epoch =  28\n",
      "[28/40] Loss_D: 0.5180 Loss_G: 10296.2903 D(x): -2106.6489 D(G(z)): -2954.9032 / -2959.7573 Elapsed 45.70 s\n",
      "In epoch =  29 real_label_smooth =  0\n",
      "epoch =  29\n",
      "[29/40] Loss_D: 81.7875 Loss_G: 8885.7432 D(x): -1647.0703 D(G(z)): -1999.1207 / -2011.4401 Elapsed 45.71 s\n",
      "In epoch =  30 real_label_smooth =  0\n",
      "epoch =  30\n",
      "[30/40] Loss_D: 4.2166 Loss_G: 7626.0999 D(x): -1653.9103 D(G(z)): -1721.8639 / -1734.9491 Elapsed 45.62 s\n",
      "In epoch =  31 real_label_smooth =  0\n",
      "epoch =  31\n",
      "[31/40] Loss_D: 0.8855 Loss_G: 5514.4049 D(x): -1728.9575 D(G(z)): -1245.1103 / -1251.5718 Elapsed 45.63 s\n",
      "In epoch =  32 real_label_smooth =  0\n",
      "epoch =  32\n",
      "[32/40] Loss_D: 0.6915 Loss_G: 5774.2127 D(x): -1898.0846 D(G(z)): -1150.2243 / -1154.8778 Elapsed 45.60 s\n",
      "In epoch =  33 real_label_smooth =  0\n",
      "epoch =  33\n",
      "[33/40] Loss_D: 0.3898 Loss_G: 6583.4728 D(x): -2008.5048 D(G(z)): -1275.1113 / -1277.9664 Elapsed 45.56 s\n",
      "In epoch =  34 real_label_smooth =  0\n",
      "epoch =  34\n",
      "[34/40] Loss_D: 0.2847 Loss_G: 6593.1651 D(x): -2056.8090 D(G(z)): -1266.5511 / -1268.9668 Elapsed 45.68 s\n",
      "In epoch =  35 real_label_smooth =  0\n",
      "epoch =  35\n",
      "[35/40] Loss_D: 0.2781 Loss_G: 7201.8324 D(x): -2055.0779 D(G(z)): -1390.0016 / -1393.4573 Elapsed 45.67 s\n",
      "In epoch =  36 real_label_smooth =  0\n",
      "epoch =  36\n",
      "[36/40] Loss_D: 27.4453 Loss_G: 7681.6986 D(x): -1702.3316 D(G(z)): -1400.9537 / -1422.8570 Elapsed 45.63 s\n",
      "In epoch =  37 real_label_smooth =  0\n",
      "epoch =  37\n",
      "[37/40] Loss_D: 12.6025 Loss_G: 8312.4641 D(x): -1682.0365 D(G(z)): -1706.9943 / -1736.2950 Elapsed 45.58 s\n",
      "In epoch =  38 real_label_smooth =  0\n",
      "epoch =  38\n",
      "[38/40] Loss_D: 2.8762 Loss_G: 8635.1862 D(x): -1720.1622 D(G(z)): -2028.3717 / -2040.6323 Elapsed 45.61 s\n",
      "In epoch =  39 real_label_smooth =  0\n",
      "epoch =  39\n",
      "[39/40] Loss_D: 1.3223 Loss_G: 9318.7483 D(x): -1797.9148 D(G(z)): -1816.3751 / -1820.6363 Elapsed 45.64 s\n"
     ]
    }
   ],
   "source": [
    "outputDir = 'outputdir_train_classifier_decay_0d018_label_0d20'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))\n",
    "num_epochs = 40\n",
    "real_labelSmooth = 0.20\n",
    "decay = 0.018\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth, decay = decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets train!\n",
      "In epoch =  0 real_label_smooth =  0.25\n",
      "epoch =  0\n",
      "[0/40] Loss_D: 836.9469 Loss_G: 4431.8725 D(x): 2238.3878 D(G(z)): 1584.0503 / 1528.8859 Elapsed 45.71 s\n",
      "In epoch =  1 real_label_smooth =  0.25\n",
      "epoch =  1\n",
      "[1/40] Loss_D: 86.3262 Loss_G: 4581.8311 D(x): 1653.3874 D(G(z)): 1242.0588 / 1226.4449 Elapsed 45.66 s\n",
      "In epoch =  2 real_label_smooth =  8.91889167372e-12\n",
      "epoch =  2\n",
      "[2/40] Loss_D: 12.4761 Loss_G: 6448.4066 D(x): 55.5296 D(G(z)): -19.6827 / -25.1500 Elapsed 45.61 s\n",
      "In epoch =  3 real_label_smooth =  3.09063569535e-33\n",
      "epoch =  3\n",
      "[3/40] Loss_D: 4.4477 Loss_G: 7580.6765 D(x): -373.3870 D(G(z)): -709.0254 / -715.4986 Elapsed 45.76 s\n",
      "In epoch =  4 real_label_smooth =  2.44075381154e-66\n",
      "epoch =  4\n",
      "[4/40] Loss_D: 29.8472 Loss_G: 7073.6220 D(x): 32.5563 D(G(z)): -148.9114 / -153.4238 Elapsed 45.66 s\n",
      "In epoch =  5 real_label_smooth =  8.6442610827e-112\n",
      "epoch =  5\n",
      "[5/40] Loss_D: 4.2858 Loss_G: 8018.0917 D(x): -301.7691 D(G(z)): -576.1989 / -583.0968 Elapsed 45.65 s\n",
      "In epoch =  6 real_label_smooth =  2.19008215293e-170\n",
      "epoch =  6\n",
      "[6/40] Loss_D: 1.6342 Loss_G: 8302.6734 D(x): -583.4542 D(G(z)): -888.7166 / -893.9314 Elapsed 45.74 s\n",
      "In epoch =  7 real_label_smooth =  4.91406812365e-243\n",
      "epoch =  7\n",
      "[7/40] Loss_D: 1.2547 Loss_G: 8735.5210 D(x): -671.3869 D(G(z)): -1008.9413 / -1013.3301 Elapsed 45.68 s\n",
      "In epoch =  8 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  8\n",
      "[8/40] Loss_D: 29.4420 Loss_G: 8117.4993 D(x): -267.1412 D(G(z)): -431.5213 / -436.5795 Elapsed 45.48 s\n",
      "In epoch =  9 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  9\n",
      "[9/40] Loss_D: 20.3537 Loss_G: 8454.9424 D(x): -312.0506 D(G(z)): -481.1046 / -487.9455 Elapsed 45.66 s\n",
      "In epoch =  10 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  10\n",
      "[10/40] Loss_D: 10.4034 Loss_G: 9016.1313 D(x): -252.7347 D(G(z)): -678.1282 / -690.6730 Elapsed 45.66 s\n",
      "In epoch =  11 real_label_smooth =  0.0\n",
      "epoch =  11\n",
      "[11/40] Loss_D: 14.3538 Loss_G: 9372.1276 D(x): -625.3590 D(G(z)): -960.1643 / -969.0349 Elapsed 45.67 s\n",
      "In epoch =  12 real_label_smooth =  0.0\n",
      "epoch =  12\n",
      "[12/40] Loss_D: 28.1074 Loss_G: 9244.7611 D(x): -915.7053 D(G(z)): -1004.7075 / -1012.0615 Elapsed 45.67 s\n",
      "In epoch =  13 real_label_smooth =  0.0\n",
      "epoch =  13\n",
      "[13/40] Loss_D: 26.7583 Loss_G: 10023.4826 D(x): -793.2707 D(G(z)): -1193.7199 / -1202.3800 Elapsed 45.72 s\n",
      "In epoch =  14 real_label_smooth =  0.0\n",
      "epoch =  14\n",
      "[14/40] Loss_D: 11.8372 Loss_G: 9431.5744 D(x): -891.0588 D(G(z)): -955.5255 / -961.1040 Elapsed 45.70 s\n",
      "In epoch =  15 real_label_smooth =  0.0\n",
      "epoch =  15\n",
      "[15/40] Loss_D: 2.7680 Loss_G: 9994.1003 D(x): -990.0750 D(G(z)): -1359.6806 / -1365.1462 Elapsed 45.73 s\n",
      "In epoch =  16 real_label_smooth =  0.0\n",
      "epoch =  16\n",
      "[16/40] Loss_D: 40.0314 Loss_G: 9546.0356 D(x): -833.0514 D(G(z)): -944.0773 / -951.4522 Elapsed 45.58 s\n",
      "In epoch =  17 real_label_smooth =  0.0\n",
      "epoch =  17\n",
      "[17/40] Loss_D: 5.7939 Loss_G: 9869.4002 D(x): -1132.4673 D(G(z)): -1213.6883 / -1217.1288 Elapsed 45.65 s\n",
      "In epoch =  18 real_label_smooth =  0.0\n",
      "epoch =  18\n",
      "[18/40] Loss_D: 16.4329 Loss_G: 10229.9422 D(x): -1131.8963 D(G(z)): -1446.1605 / -1454.3430 Elapsed 45.69 s\n",
      "In epoch =  19 real_label_smooth =  0.0\n",
      "epoch =  19\n",
      "[19/40] Loss_D: 13.8170 Loss_G: 10265.6159 D(x): -1056.7493 D(G(z)): -1361.4071 / -1368.1698 Elapsed 45.55 s\n",
      "In epoch =  20 real_label_smooth =  0.0\n",
      "epoch =  20\n",
      "[20/40] Loss_D: 1.8555 Loss_G: 10546.6662 D(x): -982.0760 D(G(z)): -1476.5926 / -1483.2147 Elapsed 45.57 s\n",
      "In epoch =  21 real_label_smooth =  0.0\n",
      "epoch =  21\n",
      "[21/40] Loss_D: 39.9837 Loss_G: 10697.8258 D(x): -1252.2298 D(G(z)): -1548.6817 / -1556.7651 Elapsed 45.48 s\n",
      "In epoch =  22 real_label_smooth =  -0.0\n",
      "epoch =  22\n",
      "[22/40] Loss_D: 11.7258 Loss_G: 9803.7381 D(x): -977.5103 D(G(z)): -987.1851 / -993.9235 Elapsed 45.65 s\n",
      "In epoch =  23 real_label_smooth =  0.0\n",
      "epoch =  23\n",
      "[23/40] Loss_D: 22.1431 Loss_G: 10133.8304 D(x): -1177.1382 D(G(z)): -1286.2425 / -1290.9186 Elapsed 45.54 s\n",
      "In epoch =  24 real_label_smooth =  -0.0\n",
      "epoch =  24\n",
      "[24/40] Loss_D: 14.6870 Loss_G: 10598.0106 D(x): -1340.7856 D(G(z)): -1604.2391 / -1611.1277 Elapsed 45.58 s\n",
      "In epoch =  25 real_label_smooth =  0.0\n",
      "epoch =  25\n",
      "[25/40] Loss_D: 37.6827 Loss_G: 10649.9695 D(x): -1237.0691 D(G(z)): -1550.6649 / -1560.3328 Elapsed 45.59 s\n",
      "In epoch =  26 real_label_smooth =  0\n",
      "epoch =  26\n",
      "[26/40] Loss_D: 9.3985 Loss_G: 10460.7841 D(x): -1321.0493 D(G(z)): -1582.8960 / -1590.0649 Elapsed 45.54 s\n",
      "In epoch =  27 real_label_smooth =  0\n",
      "epoch =  27\n",
      "[27/40] Loss_D: 24.2208 Loss_G: 10373.9723 D(x): -1119.4109 D(G(z)): -1364.0292 / -1370.5815 Elapsed 45.61 s\n",
      "In epoch =  28 real_label_smooth =  0\n",
      "epoch =  28\n",
      "[28/40] Loss_D: 18.0751 Loss_G: 10581.4556 D(x): -1201.9397 D(G(z)): -1515.4250 / -1523.5033 Elapsed 45.51 s\n",
      "In epoch =  29 real_label_smooth =  0\n",
      "epoch =  29\n",
      "[29/40] Loss_D: 33.3591 Loss_G: 10640.2559 D(x): -1365.2192 D(G(z)): -1636.8969 / -1642.7767 Elapsed 46.25 s\n",
      "In epoch =  30 real_label_smooth =  0\n",
      "epoch =  30\n",
      "[30/40] Loss_D: 8.6642 Loss_G: 10571.0669 D(x): -1355.5216 D(G(z)): -1622.8487 / -1628.3885 Elapsed 45.50 s\n",
      "In epoch =  31 real_label_smooth =  0\n",
      "epoch =  31\n",
      "[31/40] Loss_D: 22.0374 Loss_G: 10792.0113 D(x): -1335.1482 D(G(z)): -1656.0650 / -1664.8046 Elapsed 45.53 s\n",
      "In epoch =  32 real_label_smooth =  0\n",
      "epoch =  32\n",
      "[32/40] Loss_D: 38.2507 Loss_G: 10913.8496 D(x): -1263.7737 D(G(z)): -1617.5012 / -1626.4729 Elapsed 45.67 s\n",
      "In epoch =  33 real_label_smooth =  0\n",
      "epoch =  33\n",
      "[33/40] Loss_D: 18.4694 Loss_G: 11159.2204 D(x): -1321.3893 D(G(z)): -1891.8098 / -1899.9941 Elapsed 45.58 s\n",
      "In epoch =  34 real_label_smooth =  0\n",
      "epoch =  34\n",
      "[34/40] Loss_D: 14.9545 Loss_G: 10641.6858 D(x): -1524.0664 D(G(z)): -1558.0931 / -1562.4801 Elapsed 45.58 s\n",
      "In epoch =  35 real_label_smooth =  0\n",
      "epoch =  35\n",
      "[35/40] Loss_D: 50.9814 Loss_G: 10749.3416 D(x): -1256.3273 D(G(z)): -1571.9127 / -1577.4150 Elapsed 45.56 s\n",
      "In epoch =  36 real_label_smooth =  0\n",
      "epoch =  36\n",
      "[36/40] Loss_D: 8.6112 Loss_G: 10497.3652 D(x): -1176.6508 D(G(z)): -1492.5171 / -1499.2062 Elapsed 45.64 s\n",
      "In epoch =  37 real_label_smooth =  0\n",
      "epoch =  37\n",
      "[37/40] Loss_D: 41.3797 Loss_G: 10668.4649 D(x): -1326.8822 D(G(z)): -1645.2976 / -1653.5232 Elapsed 45.56 s\n",
      "In epoch =  38 real_label_smooth =  0\n",
      "epoch =  38\n",
      "[38/40] Loss_D: 25.0825 Loss_G: 10846.7768 D(x): -1356.3556 D(G(z)): -1682.7581 / -1689.6559 Elapsed 45.55 s\n",
      "In epoch =  39 real_label_smooth =  0\n",
      "epoch =  39\n",
      "[39/40] Loss_D: 32.7929 Loss_G: 10572.6015 D(x): -1262.1856 D(G(z)): -1576.4616 / -1583.5039 Elapsed 45.60 s\n"
     ]
    }
   ],
   "source": [
    "outputDir = 'outputdir_train_classifier_decay_0d018_label_0d25'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))\n",
    "num_epochs = 40\n",
    "real_labelSmooth = 0.25\n",
    "decay = 0.018\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth, decay = decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets train!\n",
      "In epoch =  0 real_label_smooth =  0.3\n",
      "epoch =  0\n",
      "[0/40] Loss_D: 1181.7568 Loss_G: 2779.1538 D(x): 3188.0879 D(G(z)): 3023.7077 / 3016.8053 Elapsed 45.64 s\n",
      "In epoch =  1 real_label_smooth =  0.3\n",
      "epoch =  1\n",
      "[1/40] Loss_D: 69.2264 Loss_G: 4987.9738 D(x): 2419.3645 D(G(z)): 1979.3055 / 1964.2221 Elapsed 45.56 s\n",
      "In epoch =  2 real_label_smooth =  1.07026700085e-11\n",
      "epoch =  2\n",
      "[2/40] Loss_D: 3.6412 Loss_G: 6421.1169 D(x): 1858.3558 D(G(z)): 1175.3466 / 1169.9474 Elapsed 45.47 s\n",
      "In epoch =  3 real_label_smooth =  3.70876283442e-33\n",
      "epoch =  3\n",
      "[3/40] Loss_D: 1.9290 Loss_G: 7132.7592 D(x): 1514.8070 D(G(z)): 799.6234 / 795.0361 Elapsed 45.64 s\n",
      "In epoch =  4 real_label_smooth =  2.92890457385e-66\n",
      "epoch =  4\n",
      "[4/40] Loss_D: 1.5477 Loss_G: 7475.5311 D(x): 1284.1282 D(G(z)): 602.5216 / 597.5237 Elapsed 45.59 s\n",
      "In epoch =  5 real_label_smooth =  1.03731132992e-111\n",
      "epoch =  5\n",
      "[5/40] Loss_D: 1.2855 Loss_G: 7757.9888 D(x): 1131.1874 D(G(z)): 410.3077 / 404.3236 Elapsed 45.53 s\n",
      "In epoch =  6 real_label_smooth =  2.62809858352e-170\n",
      "epoch =  6\n",
      "[6/40] Loss_D: 25.2368 Loss_G: 7227.8961 D(x): 745.8541 D(G(z)): 757.8867 / 752.8380 Elapsed 45.61 s\n",
      "In epoch =  7 real_label_smooth =  5.89688174838e-243\n",
      "epoch =  7\n",
      "[7/40] Loss_D: 2.5324 Loss_G: 7865.2843 D(x): 100.2721 D(G(z)): 181.8432 / 178.0485 Elapsed 45.50 s\n",
      "In epoch =  8 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  8\n",
      "[8/40] Loss_D: 29.0298 Loss_G: 7562.5444 D(x): 680.9440 D(G(z)): 475.5732 / 471.5077 Elapsed 45.63 s\n",
      "In epoch =  9 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  9\n",
      "[9/40] Loss_D: 3.9156 Loss_G: 7826.9763 D(x): 1134.3366 D(G(z)): 581.0156 / 568.2433 Elapsed 45.59 s\n",
      "In epoch =  10 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  10\n",
      "[10/40] Loss_D: 0.7020 Loss_G: 7808.0594 D(x): 878.4314 D(G(z)): -594.4455 / -609.9463 Elapsed 45.54 s\n",
      "In epoch =  11 real_label_smooth =  0.0\n",
      "epoch =  11\n",
      "[11/40] Loss_D: 0.4318 Loss_G: 5368.5054 D(x): 733.5857 D(G(z)): -276.0573 / -280.3171 Elapsed 45.63 s\n",
      "In epoch =  12 real_label_smooth =  0.0\n",
      "epoch =  12\n",
      "[12/40] Loss_D: 0.3531 Loss_G: 5825.9352 D(x): 509.3251 D(G(z)): -646.8847 / -649.3826 Elapsed 45.53 s\n",
      "In epoch =  13 real_label_smooth =  0.0\n",
      "epoch =  13\n",
      "[13/40] Loss_D: 0.1641 Loss_G: 6167.2637 D(x): 362.6724 D(G(z)): -733.4756 / -734.8851 Elapsed 45.63 s\n",
      "In epoch =  14 real_label_smooth =  0.0\n",
      "epoch =  14\n",
      "[14/40] Loss_D: 0.1864 Loss_G: 6477.5525 D(x): 267.7366 D(G(z)): -858.1158 / -859.8130 Elapsed 45.62 s\n",
      "In epoch =  15 real_label_smooth =  0.0\n",
      "epoch =  15\n",
      "[15/40] Loss_D: 0.0809 Loss_G: 6554.2110 D(x): 352.0453 D(G(z)): -797.4585 / -798.8809 Elapsed 45.52 s\n",
      "In epoch =  16 real_label_smooth =  0.0\n",
      "epoch =  16\n",
      "[16/40] Loss_D: 0.0433 Loss_G: 7088.3004 D(x): 222.7867 D(G(z)): -920.4262 / -921.4423 Elapsed 45.61 s\n",
      "In epoch =  17 real_label_smooth =  0.0\n",
      "epoch =  17\n",
      "[17/40] Loss_D: 0.0340 Loss_G: 7063.8375 D(x): 147.0584 D(G(z)): -959.5477 / -960.7347 Elapsed 45.52 s\n",
      "In epoch =  18 real_label_smooth =  0.0\n",
      "epoch =  18\n",
      "[18/40] Loss_D: 0.0230 Loss_G: 7289.6048 D(x): 118.0382 D(G(z)): -1022.7202 / -1023.3472 Elapsed 45.61 s\n",
      "In epoch =  19 real_label_smooth =  0.0\n",
      "epoch =  19\n",
      "[19/40] Loss_D: 0.0183 Loss_G: 7305.4110 D(x): 83.9615 D(G(z)): -1062.2397 / -1062.9498 Elapsed 45.53 s\n",
      "In epoch =  20 real_label_smooth =  0.0\n",
      "epoch =  20\n",
      "[20/40] Loss_D: 0.0151 Loss_G: 7454.0735 D(x): 55.5599 D(G(z)): -1076.6910 / -1077.4454 Elapsed 45.56 s\n",
      "In epoch =  21 real_label_smooth =  0.0\n",
      "epoch =  21\n",
      "[21/40] Loss_D: 0.0119 Loss_G: 7602.2504 D(x): 28.5121 D(G(z)): -1079.1369 / -1079.8102 Elapsed 45.60 s\n",
      "In epoch =  22 real_label_smooth =  -0.0\n",
      "epoch =  22\n",
      "[22/40] Loss_D: 0.0111 Loss_G: 7841.7981 D(x): -18.1612 D(G(z)): -1104.6085 / -1105.3972 Elapsed 45.57 s\n",
      "In epoch =  23 real_label_smooth =  0.0\n",
      "epoch =  23\n",
      "[23/40] Loss_D: 0.0084 Loss_G: 8142.8761 D(x): -42.4905 D(G(z)): -1150.9400 / -1151.5251 Elapsed 45.53 s\n",
      "In epoch =  24 real_label_smooth =  -0.0\n",
      "epoch =  24\n",
      "[24/40] Loss_D: 0.0065 Loss_G: 8340.9194 D(x): -66.2244 D(G(z)): -1205.9510 / -1206.4267 Elapsed 45.57 s\n",
      "In epoch =  25 real_label_smooth =  0.0\n",
      "epoch =  25\n",
      "[25/40] Loss_D: 0.0055 Loss_G: 8281.5733 D(x): -118.3478 D(G(z)): -1241.8532 / -1242.4924 Elapsed 45.57 s\n",
      "In epoch =  26 real_label_smooth =  0\n",
      "epoch =  26\n",
      "[26/40] Loss_D: 0.0043 Loss_G: 8347.4306 D(x): -145.3205 D(G(z)): -1293.0238 / -1293.4287 Elapsed 45.56 s\n",
      "In epoch =  27 real_label_smooth =  0\n",
      "epoch =  27\n",
      "[27/40] Loss_D: 19.0976 Loss_G: 8419.3801 D(x): 1278.4745 D(G(z)): 104.6571 / 37.0521 Elapsed 45.56 s\n",
      "In epoch =  28 real_label_smooth =  0\n",
      "epoch =  28\n",
      "[28/40] Loss_D: 1.2919 Loss_G: 7701.3539 D(x): 788.5370 D(G(z)): 595.0207 / 568.3631 Elapsed 45.64 s\n",
      "In epoch =  29 real_label_smooth =  0\n",
      "epoch =  29\n",
      "[29/40] Loss_D: 0.4177 Loss_G: 7573.5802 D(x): 460.8986 D(G(z)): 578.5976 / 564.2211 Elapsed 45.55 s\n",
      "In epoch =  30 real_label_smooth =  0\n",
      "epoch =  30\n",
      "[30/40] Loss_D: 0.3769 Loss_G: 9086.9022 D(x): 483.3136 D(G(z)): 802.9721 / 793.3758 Elapsed 45.57 s\n",
      "In epoch =  31 real_label_smooth =  0\n",
      "epoch =  31\n",
      "[31/40] Loss_D: 0.0511 Loss_G: 8040.3284 D(x): 469.0993 D(G(z)): 637.7228 / 631.6876 Elapsed 45.64 s\n",
      "In epoch =  32 real_label_smooth =  0\n",
      "epoch =  32\n",
      "[32/40] Loss_D: 0.0232 Loss_G: 8083.7418 D(x): 385.9771 D(G(z)): 196.8319 / 192.0076 Elapsed 45.58 s\n",
      "In epoch =  33 real_label_smooth =  0\n",
      "epoch =  33\n",
      "[33/40] Loss_D: 0.0177 Loss_G: 8222.6917 D(x): 339.2949 D(G(z)): 347.0980 / 342.2444 Elapsed 45.63 s\n",
      "In epoch =  34 real_label_smooth =  0\n",
      "epoch =  34\n",
      "[34/40] Loss_D: 0.0132 Loss_G: 7837.9042 D(x): 335.6123 D(G(z)): 1083.3615 / 1080.1986 Elapsed 45.55 s\n",
      "In epoch =  35 real_label_smooth =  0\n",
      "epoch =  35\n",
      "[35/40] Loss_D: 0.0100 Loss_G: 7835.1128 D(x): 361.4493 D(G(z)): 1263.1514 / 1260.7965 Elapsed 45.61 s\n",
      "In epoch =  36 real_label_smooth =  0\n",
      "epoch =  36\n",
      "[36/40] Loss_D: 0.0078 Loss_G: 8211.0744 D(x): 370.5400 D(G(z)): 1194.2090 / 1192.1778 Elapsed 45.60 s\n",
      "In epoch =  37 real_label_smooth =  0\n",
      "epoch =  37\n",
      "[37/40] Loss_D: 0.0066 Loss_G: 8408.3557 D(x): 333.6289 D(G(z)): 1190.1983 / 1188.1367 Elapsed 45.59 s\n",
      "In epoch =  38 real_label_smooth =  0\n",
      "epoch =  38\n",
      "[38/40] Loss_D: 0.0051 Loss_G: 8613.4791 D(x): 316.6519 D(G(z)): 1029.7528 / 1028.2629 Elapsed 45.65 s\n",
      "In epoch =  39 real_label_smooth =  0\n",
      "epoch =  39\n",
      "[39/40] Loss_D: 0.0043 Loss_G: 8562.0022 D(x): 290.3489 D(G(z)): 898.2567 / 897.0365 Elapsed 45.60 s\n"
     ]
    }
   ],
   "source": [
    "outputDir = 'outputdir_train_classifier_decay_0d018_label_0d30'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))\n",
    "num_epochs = 40\n",
    "real_labelSmooth = 0.30\n",
    "decay = 0.018\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth, decay = decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
