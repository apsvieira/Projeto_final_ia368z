{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System properties and libs currently in use\n",
    "- We have developed using python 3.5.x, pytorch 0.2.1\n",
    "- No significant attention was given to backwards compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__Python VERSION: 3.5.3 |Anaconda 4.4.0 (64-bit)| (default, Mar  6 2017, 11:58:13) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
      "__pyTorch VERSION: 0.2.0_4\n",
      "__CUDA VERSION\n",
      "__CUDNN VERSION: 6021\n",
      "__Number CUDA Devices: 1\n",
      "__Devices\n",
      "Active CUDA Device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "print('Active CUDA Device: GPU', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities\n",
    "- Saving images and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_images(netG, fixed_noise, outputDir,epoch):\n",
    "    '''\n",
    "    Generates a batch of images from the given 'noise'.\n",
    "    Saves 64 of the generated samples to 'outputDir' system path.\n",
    "    Inputs are the network (netG), a 'noise' input, system path to which images will be saved (outputDir) and current 'epoch'.\n",
    "    '''\n",
    "    noise = Variable(fixed_noise)\n",
    "    netG.eval()\n",
    "    fake = netG(noise)\n",
    "    netG.train()\n",
    "    vutils.save_image(fake.data[0:64,:,:,:],'%s/fake_samples_epoch_%03d.png' % (outputDir, epoch), nrow=8)\n",
    "\n",
    "def save_models(netG, netD, outputDir, epoch):\n",
    "    '''\n",
    "    Saves model state dictionary for generator and discriminator networks.\n",
    "    Inputs are the networks (netG, netD), the system path in which to save(outputDir) and the current 'epoch'.\n",
    "    '''\n",
    "    torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (outputDir, epoch))\n",
    "    torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (outputDir, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using CUDA. If it is not what you want, manually set this as False!\n"
     ]
    }
   ],
   "source": [
    "cudnn.benchmark = True\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"You are using CUDA. If it is not what you want, manually set this as False!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Directory\n",
    "This is where images will be saved to.\n",
    "\n",
    "If directory does not exist, it is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS error: [Errno 17] File exists: 'outputdir_train_classifier_lotufo'\n"
     ]
    }
   ],
   "source": [
    "outputDir = 'outputdir_train_classifier_lotufo'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset definition and hyperparameter setting\n",
    "- Changing dataset name alters network architecture parameters\n",
    "- Currently supporting few datasets\n",
    "- Hyperparameters defined according to Radford et al. (2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "chosen_dataset = 'MNIST'\n",
    "\n",
    "datasets = {\n",
    "    'MNIST': torchvision.datasets.MNIST,\n",
    "    'CIFAR10': torchvision.datasets.CIFAR10,\n",
    "    'ANIME': '/home/gabriel/Redes Neurais/Projeto_Final_GANS/Tutorial_2/dataset/min_anime-faces',\n",
    "}\n",
    "\n",
    "dataset = datasets[chosen_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "possible_parameters = {\n",
    "    'MNIST': {\n",
    "        'ndf': 64,\n",
    "        'ngf': 64,\n",
    "        'nz': 100,\n",
    "        'nc': 1,\n",
    "        'imageSize': 64,\n",
    "        'n_classes' : 10,\n",
    "        'ngpu': 1,\n",
    "    },\n",
    "    'CIFAR10': {\n",
    "        'ndf': 64,\n",
    "        'ngf': 64,\n",
    "        'nz': 100,\n",
    "        'nc': 3,\n",
    "        'imageSize' : 64,\n",
    "        'n_classes' : 10,\n",
    "        'ngpu' : 1,\n",
    "    },\n",
    "    'ANIME': {\n",
    "        'nc' : 3,\n",
    "        'ngpu' : 1,\n",
    "        'nz' : 100,\n",
    "        'ngf' : 64,\n",
    "        'ndf' : 64,\n",
    "        'imageSize' : 64,\n",
    "        'n_classes' : 1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngf = possible_parameters[chosen_dataset]['ngf']\n",
    "ndf = possible_parameters[chosen_dataset]['ndf']\n",
    "nz = possible_parameters[chosen_dataset]['nz']\n",
    "nc = possible_parameters[chosen_dataset]['nc']\n",
    "imageSize = possible_parameters[chosen_dataset]['imageSize']\n",
    "n_classes = possible_parameters[chosen_dataset]['n_classes']\n",
    "ngpu = possible_parameters[chosen_dataset]['ngpu']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader length: 469\n",
      "Dataset: <torchvision.datasets.mnist.MNIST object at 0x7f89137322e8>\n"
     ]
    }
   ],
   "source": [
    "if dataset == 'ANIME':\n",
    "    dataset = torchvision.datasets.ImageFolder(\n",
    "        root='/home/gabriel/Redes Neurais/Projeto_Final_GANS/Tutorial_2/dataset/min_anime-faces',\n",
    "        transform=transforms.Compose([\n",
    "                transforms.Scale((imageSize, imageSize)),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "    )\n",
    "else:\n",
    "    transform = transforms.Compose([\n",
    "                    transforms.Scale((imageSize, imageSize)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)), # bring images to (-1,1)\n",
    "                ]) \n",
    "    dataset_done = dataset('./datasets', train=True, download=True, transform=transform)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset_done, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "print('Dataloader length:', len(dataloader))\n",
    "print(\"Dataset:\", dataloader.dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição dos modelos\n",
    "- Model is a DCGAN\n",
    "- Images are sized (nc, 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netD_DCGAN(nn.Module):\n",
    "    def __init__(self, ngpu, nz, nc, ndf, n_classes):\n",
    "        super(_netD_DCGAN, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.conv1 = nn.Conv2d(in_channels = nc, out_channels = ndf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(in_channels = ndf, out_channels = ndf*2, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch2 = nn.BatchNorm2d(ndf * 2)\n",
    "        self.conv3 = nn.Conv2d(in_channels = ndf*2, out_channels = ndf*4, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch3 = nn.BatchNorm2d(ndf * 4)\n",
    "        self.conv4 = nn.Conv2d(in_channels = ndf*4, out_channels = ndf*8, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch4 = nn.BatchNorm2d(ndf * 8)\n",
    "        \n",
    "        self.final_conv = nn.Conv2d(in_channels=ndf*8, out_channels=n_classes+1,kernel_size=4,stride=1,padding=0,bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch2(self.conv2(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch3(self.conv3(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch4(self.conv4(x)), 0.2, inplace=True)\n",
    "        \n",
    "        x = self.final_conv(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netG_DCGAN(nn.Module):\n",
    "    def __init__(self, ngpu, nz, nc , ngf):\n",
    "        super(_netG_DCGAN, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.convt1 = nn.ConvTranspose2d(in_channels=nz, out_channels=ngf * 8, kernel_size=4, stride=1, padding=0, bias=False)\n",
    "        self.batch1 = nn.BatchNorm2d(ngf*8)\n",
    "        self.convt2 = nn.ConvTranspose2d(in_channels=ngf * 8, out_channels=ngf * 4, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch2 = nn.BatchNorm2d(ngf*4)\n",
    "        self.convt3 = nn.ConvTranspose2d(in_channels=ngf * 4, out_channels=ngf * 2, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch3 = nn.BatchNorm2d(ngf*2)\n",
    "        self.convt4 = nn.ConvTranspose2d(in_channels=ngf*2, out_channels=ngf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch4 = nn.BatchNorm2d(ngf)\n",
    "        \n",
    "        self.final_convt = nn.ConvTranspose2d(in_channels=ngf, out_channels=nc, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.batch1(self.convt1(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch2(self.convt2(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch3(self.convt3(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch4(self.convt4(x)), 0.2, inplace=True)\n",
    "        \n",
    "        x = self.final_convt(x)\n",
    "        x = F.tanh(x)\n",
    "        return (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netG = _netG_DCGAN(ngpu, nz, nc, ngf)\n",
    "netD = _netD_DCGAN(ngpu, nz, nc, ndf, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializador de pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_netG_DCGAN (\n",
      "  (convt1): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "  (batch1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (convt2): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (convt3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (convt4): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (final_convt): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      ") \n",
      " _netD_DCGAN (\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (conv3): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (conv4): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (final_conv): Conv2d(512, 11, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)\n",
    "print(netG, '\\n', netD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses\n",
    "- Binary Cross-Entropy is used to differentiate real and fake images\n",
    "- Class loss should be Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sizes of the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input images size: torch.Size([128, 3, 64, 64])\n",
      "Code size: torch.Size([128, 100, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "input = torch.FloatTensor(batch_size, 3, imageSize, imageSize)\n",
    "print('Input images size:', input.size())\n",
    "noise = torch.FloatTensor(batch_size, nz, 1, 1)\n",
    "fixed_noise = torch.FloatTensor(batch_size, nz, 1, 1).normal_(0, 1)\n",
    "print('Code size:', noise.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label size: torch.Size([128, 10])\n"
     ]
    }
   ],
   "source": [
    "label = torch.LongTensor(batch_size,n_classes)\n",
    "print('Label size:', label.size())\n",
    "fake_label = 10\n",
    "real_label = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcast to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    netD.cuda()\n",
    "    netG.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    input,label = input.cuda(), label.cuda()\n",
    "    noise, fixed_noise = noise.cuda(), fixed_noise.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer Parameters\n",
    "- Following the lead of Radford et al., 2015:\n",
    "\n",
    "    <b>\n",
    "    1. beta1 = 0.5\n",
    "    2. beta2 = 0.999\n",
    "    3. lr = 0.0002\n",
    "    </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta1, beta2 = 0.5, 0.999\n",
    "lr = 2.0e-4\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr = lr, betas = (beta1, beta2))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr = lr, betas = (beta1, beta2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Treinamento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_gan(num_epochs, dataloader, netD, netG, outputDir,\n",
    "              real_labelSmooth=0, epoch_interval=100, D_steps=1, G_steps=1, decay = 0.05):\n",
    "    \n",
    "    # This validation is subjective. WGAN-GP uses 100 steps on the critic (netD).\n",
    "    assert D_steps < 5, \"Keep it low, D_steps is too high.\"\n",
    "    assert G_steps < 3, \"Keep it low, G_steps is too high.\"\n",
    "    #assert batch_size % D_steps == 0, \"Use batch_size multiple of D_steps.\"\n",
    "    real_label = 1\n",
    "    print('Lets train!')\n",
    "    for epoch in range(num_epochs):\n",
    "        start_iter = time.time()  \n",
    "        D_x = 0\n",
    "        D_G_z1 = 0\n",
    "        D_G_z2 = 0\n",
    "        errD_acum = 0\n",
    "        errG_acum = 0\n",
    "        \n",
    "        print('In epoch = ', epoch, 'real_label_smooth = ',real_labelSmooth )\n",
    "        for batch, data in enumerate(dataloader, 0):\n",
    "            if (epoch == 0 and batch == 0):\n",
    "                    vutils.save_image(data[0][0:64,:,:,:], '%s/real_samples.png' % outputDir, nrow=8)\n",
    "            if epoch < 25:   \n",
    "                real_labelSmooth = np.maximum(real_labelSmooth * (1 - 0.05*epoch), 0)\n",
    "            else:\n",
    "                real_labelSmooth = 0\n",
    "            for step in range(D_steps):\n",
    "                #############################################################\n",
    "                # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "                # 1A - Train the detective network in the Real Dataset\n",
    "                #############################################################\n",
    "                netD.zero_grad()\n",
    "                start = step*(int(data[0].size()[0]/D_steps))\n",
    "                end = (step+1)*int(data[0].size()[0]/D_steps)\n",
    "                \n",
    "                real_cpu = data[0][start:end]\n",
    "                real_cpu = real_cpu.cuda()\n",
    "                batch_size = real_cpu.size(0)\n",
    "                if np.random.random_sample() > real_labelSmooth:\n",
    "                    target = data[1][start:end].long().cuda()\n",
    "                else:\n",
    "                     target = torch.from_numpy(np.random.randint(0, n_classes, batch_size)).type(torch.LongTensor).cuda()\n",
    "                \n",
    "                input, label = Variable(real_cpu), Variable(target)\n",
    "\n",
    "                output = netD(input)\n",
    "                errD_real = criterion(output.squeeze(),label)\n",
    "                errD_real.backward()\n",
    "                \n",
    "                D_x += output.data.mean()\n",
    "                \n",
    "                #######################################################\n",
    "                # 1B - Train the detective network in the False Dataset\n",
    "                #######################################################\n",
    "                \n",
    "                noise = Variable(torch.FloatTensor(batch_size, nz, 1, 1).normal_(0,1).cuda())\n",
    "                fake = netG(noise)\n",
    "                label = Variable(torch.ones(batch_size).long().fill_(fake_label).cuda())\n",
    "                output = netD(fake.detach()) # \".detach()\" to avoid backprop through G\n",
    "                errD_fake = criterion(output.squeeze(), label)\n",
    "                errD_fake.backward() # gradients for fake and real data will be accumulated\n",
    "                \n",
    "                D_G_z1 += output.data.mean()\n",
    "                errD_acum += errD_real.data[0] + errD_fake.data[0]\n",
    "                optimizerD.step()\n",
    "\n",
    "            for step in range(G_steps):\n",
    "                ####################################################################################\n",
    "                # (2) Update G network: maximize log(D(G(z)))\n",
    "                # Train the faker with the output from the Detective (but don't train the Detective)\n",
    "                ####################################################################################\n",
    "                \n",
    "                netG.zero_grad()\n",
    "                label = Variable(torch.from_numpy(np.random.randint(0, n_classes, batch_size)).type(torch.LongTensor).cuda())\n",
    "                output = netD(fake)\n",
    "                errG = criterion(output.squeeze(), label)\n",
    "                errG.backward()\n",
    "                \n",
    "                D_G_z2 += output.data.mean()\n",
    "                errG_acum += errG.data[0]\n",
    "                optimizerG.step()\n",
    "\n",
    "        print('epoch = ',epoch)\n",
    "\n",
    "        end_iter = time.time()        \n",
    "\n",
    "        print('[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f Elapsed %.2f s'\n",
    "              % (epoch, num_epochs, errD_acum/D_steps, errG_acum/G_steps, D_x, D_G_z1, D_G_z2, end_iter-start_iter))\n",
    "\n",
    "        #Save a grid with the pictures from the dataset, up until 64\n",
    "        save_images(netG = netG, fixed_noise=  fixed_noise, outputDir = outputDir, epoch = epoch)\n",
    "\n",
    "        if epoch % epoch_interval == 0:\n",
    "            # do checkpointing\n",
    "            save_models(netG = netG, netD = netD, outputDir = outputDir, epoch = epoch)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputDir = 'outputdir_train_classifier_0d25'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets train!\n",
      "In epoch =  0 real_label_smooth =  0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-3:\n",
      "Process Process-1:\n",
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-4:\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-ccde10e341be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mreal_labelSmooth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdecay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.025\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnetG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputDir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_labelSmooth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-7c7a3172cc33>\u001b[0m in \u001b[0;36mtrain_gan\u001b[0;34m(num_epochs, dataloader, netD, netG, outputDir, real_labelSmooth, epoch_interval, D_steps, G_steps, decay)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                 \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# \".detach()\" to avoid backprop through G\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-934ff557426a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvt1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvt2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvt3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torch/nn/_functions/thnn/auto.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, input, *params)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"missing required argument '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0margs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madditional_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;31m# If the module is working in-place its output will be set to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 25\n",
    "real_labelSmooth = 0.25\n",
    "decay = 0.025\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth, decay = decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputDir = 'outputdir_train_classifier_0d15'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))\n",
    "    \n",
    "num_epochs = 100\n",
    "real_labelSmooth = 0.15\n",
    "\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputDir = 'outputdir_train_classifier_0d20'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))\n",
    "    \n",
    "num_epochs = 100\n",
    "real_labelSmooth = 0.20\n",
    "\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets train!\n",
      "In epoch =  0 real_label_smooth =  0.1\n",
      "epoch =  0\n",
      "[0/100] Loss_D: 489.9057 Loss_G: 6355.2549 D(x): 1892.3792 D(G(z)): 1325.7127 / 1266.0529 Elapsed 43.89 s\n",
      "In epoch =  1 real_label_smooth =  0.1\n",
      "epoch =  1\n",
      "[1/100] Loss_D: 24.7583 Loss_G: 4765.3966 D(x): 1001.4163 D(G(z)): 762.1362 / 735.1085 Elapsed 44.00 s\n",
      "In epoch =  2 real_label_smooth =  3.56755666949e-12\n",
      "epoch =  2\n",
      "[2/100] Loss_D: 2.0290 Loss_G: 5438.1060 D(x): 74.0035 D(G(z)): 246.1375 / 228.5548 Elapsed 43.79 s\n",
      "In epoch =  3 real_label_smooth =  1.23625427814e-33\n",
      "epoch =  3\n",
      "[3/100] Loss_D: 0.9688 Loss_G: 5460.8529 D(x): -367.6159 D(G(z)): -327.2970 / -339.1286 Elapsed 44.12 s\n",
      "In epoch =  4 real_label_smooth =  9.76301524616e-67\n",
      "epoch =  4\n",
      "[4/100] Loss_D: 0.5046 Loss_G: 6229.2302 D(x): -588.4061 D(G(z)): -683.5881 / -691.7062 Elapsed 43.93 s\n",
      "In epoch =  5 real_label_smooth =  3.45770443308e-112\n",
      "epoch =  5\n",
      "[5/100] Loss_D: 27.2388 Loss_G: 5803.1441 D(x): -238.4102 D(G(z)): -440.2289 / -473.9404 Elapsed 44.07 s\n",
      "In epoch =  6 real_label_smooth =  8.76032861174e-171\n",
      "epoch =  6\n",
      "[6/100] Loss_D: 2.7067 Loss_G: 5486.2711 D(x): 76.0938 D(G(z)): -132.1805 / -151.6482 Elapsed 44.10 s\n",
      "In epoch =  7 real_label_smooth =  1.96562724946e-243\n",
      "epoch =  7\n",
      "[7/100] Loss_D: 0.9173 Loss_G: 5999.6532 D(x): -322.5276 D(G(z)): -550.0090 / -566.2004 Elapsed 43.81 s\n",
      "In epoch =  8 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  8\n",
      "[8/100] Loss_D: 0.2831 Loss_G: 6649.1815 D(x): -524.1441 D(G(z)): -1585.1392 / -1590.5149 Elapsed 44.08 s\n",
      "In epoch =  9 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  9\n",
      "[9/100] Loss_D: 0.1235 Loss_G: 6910.7491 D(x): -598.4732 D(G(z)): -1545.2778 / -1547.1007 Elapsed 44.12 s\n",
      "In epoch =  10 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  10\n",
      "[10/100] Loss_D: 0.0851 Loss_G: 7293.8715 D(x): -665.6087 D(G(z)): -1684.0578 / -1685.7546 Elapsed 44.23 s\n",
      "In epoch =  11 real_label_smooth =  0.0\n",
      "epoch =  11\n",
      "[11/100] Loss_D: 0.0665 Loss_G: 7266.2501 D(x): -754.4257 D(G(z)): -1477.6120 / -1479.5347 Elapsed 43.87 s\n",
      "In epoch =  12 real_label_smooth =  0.0\n",
      "epoch =  12\n",
      "[12/100] Loss_D: 0.0568 Loss_G: 7111.0566 D(x): -845.3038 D(G(z)): -1499.0050 / -1502.2722 Elapsed 44.04 s\n",
      "In epoch =  13 real_label_smooth =  0.0\n",
      "epoch =  13\n",
      "[13/100] Loss_D: 0.0446 Loss_G: 8170.9565 D(x): -913.3268 D(G(z)): -1360.8645 / -1363.3460 Elapsed 44.28 s\n",
      "In epoch =  14 real_label_smooth =  0.0\n",
      "epoch =  14\n",
      "[14/100] Loss_D: 0.0347 Loss_G: 8608.8749 D(x): -974.3797 D(G(z)): -1877.3959 / -1879.4047 Elapsed 44.14 s\n",
      "In epoch =  15 real_label_smooth =  0.0\n",
      "epoch =  15\n",
      "[15/100] Loss_D: 0.0283 Loss_G: 8915.0014 D(x): -1045.6783 D(G(z)): -2096.3235 / -2098.0637 Elapsed 44.21 s\n",
      "In epoch =  16 real_label_smooth =  0.0\n",
      "epoch =  16\n",
      "[16/100] Loss_D: 0.0218 Loss_G: 9006.5070 D(x): -1094.1013 D(G(z)): -2321.8901 / -2322.8472 Elapsed 44.09 s\n",
      "In epoch =  17 real_label_smooth =  0.0\n",
      "epoch =  17\n",
      "[17/100] Loss_D: 0.0167 Loss_G: 9024.8865 D(x): -1163.5914 D(G(z)): -2488.9285 / -2489.8026 Elapsed 44.08 s\n",
      "In epoch =  18 real_label_smooth =  0.0\n",
      "epoch =  18\n",
      "[18/100] Loss_D: 0.0136 Loss_G: 8332.8591 D(x): -1217.6206 D(G(z)): -2289.0404 / -2289.8173 Elapsed 44.00 s\n",
      "In epoch =  19 real_label_smooth =  0.0\n",
      "epoch =  19\n",
      "[19/100] Loss_D: 11.4988 Loss_G: 9348.7131 D(x): -935.8502 D(G(z)): -1822.8692 / -1839.0028 Elapsed 44.12 s\n",
      "In epoch =  20 real_label_smooth =  0.0\n",
      "epoch =  20\n",
      "[20/100] Loss_D: 19.9957 Loss_G: 7844.4223 D(x): -188.7098 D(G(z)): -976.9305 / -1025.2055 Elapsed 43.97 s\n",
      "In epoch =  21 real_label_smooth =  0.0\n",
      "epoch =  21\n",
      "[21/100] Loss_D: 3.0610 Loss_G: 7747.1243 D(x): -441.8682 D(G(z)): -615.7140 / -628.1630 Elapsed 44.16 s\n",
      "In epoch =  22 real_label_smooth =  -0.0\n",
      "epoch =  22\n",
      "[22/100] Loss_D: 1.5735 Loss_G: 8185.9881 D(x): -528.2560 D(G(z)): -586.9958 / -600.6907 Elapsed 44.04 s\n",
      "In epoch =  23 real_label_smooth =  0.0\n",
      "epoch =  23\n",
      "[23/100] Loss_D: 0.6706 Loss_G: 8096.7028 D(x): -716.0552 D(G(z)): -1826.3520 / -1836.5327 Elapsed 43.97 s\n",
      "In epoch =  24 real_label_smooth =  -0.0\n",
      "epoch =  24\n",
      "[24/100] Loss_D: 0.2888 Loss_G: 7484.3533 D(x): -839.0414 D(G(z)): -1074.9518 / -1081.4998 Elapsed 44.09 s\n",
      "In epoch =  25 real_label_smooth =  0.0\n",
      "epoch =  25\n",
      "[25/100] Loss_D: 0.6286 Loss_G: 9559.9871 D(x): -898.2532 D(G(z)): -709.4535 / -720.1863 Elapsed 44.02 s\n",
      "In epoch =  26 real_label_smooth =  0\n",
      "epoch =  26\n",
      "[26/100] Loss_D: 4.4222 Loss_G: 9377.4626 D(x): -614.7308 D(G(z)): -945.6035 / -963.9444 Elapsed 43.97 s\n",
      "In epoch =  27 real_label_smooth =  0\n",
      "epoch =  27\n",
      "[27/100] Loss_D: 2.9004 Loss_G: 8205.5929 D(x): -768.5281 D(G(z)): -802.8799 / -813.8518 Elapsed 43.94 s\n",
      "In epoch =  28 real_label_smooth =  0\n",
      "epoch =  28\n",
      "[28/100] Loss_D: 0.9667 Loss_G: 8920.4256 D(x): -766.2820 D(G(z)): -690.8933 / -699.0066 Elapsed 44.12 s\n",
      "In epoch =  29 real_label_smooth =  0\n",
      "epoch =  29\n",
      "[29/100] Loss_D: 2.6093 Loss_G: 9862.9920 D(x): -976.4488 D(G(z)): -1327.1646 / -1347.1695 Elapsed 43.89 s\n",
      "In epoch =  30 real_label_smooth =  0\n",
      "epoch =  30\n",
      "[30/100] Loss_D: 2.5712 Loss_G: 9982.6585 D(x): -970.9238 D(G(z)): -1094.5466 / -1117.2681 Elapsed 44.08 s\n",
      "In epoch =  31 real_label_smooth =  0\n",
      "epoch =  31\n",
      "[31/100] Loss_D: 15.9078 Loss_G: 9683.9523 D(x): -793.8221 D(G(z)): -1409.1568 / -1442.8780 Elapsed 43.97 s\n",
      "In epoch =  32 real_label_smooth =  0\n",
      "epoch =  32\n",
      "[32/100] Loss_D: 3.1572 Loss_G: 9165.7562 D(x): -637.3912 D(G(z)): -1326.1204 / -1348.0807 Elapsed 44.20 s\n",
      "In epoch =  33 real_label_smooth =  0\n",
      "epoch =  33\n",
      "[33/100] Loss_D: 0.7352 Loss_G: 10199.5846 D(x): -893.3780 D(G(z)): -1158.4848 / -1170.3237 Elapsed 44.13 s\n",
      "In epoch =  34 real_label_smooth =  0\n",
      "epoch =  34\n",
      "[34/100] Loss_D: 0.1849 Loss_G: 10483.7821 D(x): -987.5055 D(G(z)): -2382.5755 / -2390.5223 Elapsed 44.32 s\n",
      "In epoch =  35 real_label_smooth =  0\n",
      "epoch =  35\n",
      "[35/100] Loss_D: 0.0531 Loss_G: 10897.5040 D(x): -982.8390 D(G(z)): -2445.0143 / -2447.7242 Elapsed 44.63 s\n",
      "In epoch =  36 real_label_smooth =  0\n",
      "epoch =  36\n",
      "[36/100] Loss_D: 0.0283 Loss_G: 9427.0569 D(x): -1007.1470 D(G(z)): -2467.5312 / -2468.0958 Elapsed 44.31 s\n",
      "In epoch =  37 real_label_smooth =  0\n",
      "epoch =  37\n",
      "[37/100] Loss_D: 0.0210 Loss_G: 8684.8456 D(x): -981.0894 D(G(z)): -2329.7988 / -2330.1483 Elapsed 44.51 s\n",
      "In epoch =  38 real_label_smooth =  0\n",
      "epoch =  38\n",
      "[38/100] Loss_D: 0.0284 Loss_G: 8590.8143 D(x): -1004.6273 D(G(z)): -2362.3079 / -2362.7138 Elapsed 58.58 s\n",
      "In epoch =  39 real_label_smooth =  0\n",
      "epoch =  39\n",
      "[39/100] Loss_D: 0.0139 Loss_G: 8758.6850 D(x): -1010.8965 D(G(z)): -2443.4248 / -2443.9221 Elapsed 65.77 s\n",
      "In epoch =  40 real_label_smooth =  0\n",
      "epoch =  40\n",
      "[40/100] Loss_D: 0.0106 Loss_G: 8766.4324 D(x): -1031.6511 D(G(z)): -2502.3647 / -2502.8261 Elapsed 43.86 s\n",
      "In epoch =  41 real_label_smooth =  0\n",
      "epoch =  41\n",
      "[41/100] Loss_D: 0.0088 Loss_G: 8737.8420 D(x): -1046.2750 D(G(z)): -2578.9317 / -2579.3395 Elapsed 44.04 s\n",
      "In epoch =  42 real_label_smooth =  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-667:\n",
      "Process Process-668:\n",
      "Process Process-665:\n",
      "Process Process-666:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 40, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/torchvision-0.1.9-py3.5.egg/torchvision/datasets/mnist.py\", line 72, in __getitem__\n",
      "    img = Image.fromarray(img.numpy(), mode='L')\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/PIL/Image.py\", line 2313, in fromarray\n",
      "    return frombuffer(mode, size, obj, \"raw\", rawmode, 0, 1)\n",
      "  File \"/home/gabriel/anaconda3/envs/py35/lib/python3.5/site-packages/PIL/Image.py\", line 2261, in frombuffer\n",
      "    core.map_buffer(data, size, decoder_name, None, 0, args)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-853919726c10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mreal_labelSmooth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnetG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputDir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_labelSmooth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-43-d5425b3d1ce2>\u001b[0m in \u001b[0;36mtrain_gan\u001b[0;34m(num_epochs, dataloader, netD, netG, outputDir, real_labelSmooth, epoch_interval, D_steps, G_steps)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0merrD_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mD_x\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0;31m#######################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "outputDir = 'outputdir_train_classifier_0d10'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))\n",
    "    \n",
    "num_epochs = 100\n",
    "real_labelSmooth = 0.10\n",
    "\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS error: [Errno 17] File exists: 'outputdir_train_classifier_decay_0d025_label_0d1'\n",
      "Lets train!\n",
      "In epoch =  0 real_label_smooth =  0.1\n",
      "epoch =  0\n",
      "[0/40] Loss_D: 299.6264 Loss_G: 3986.2494 D(x): 4684.5141 D(G(z)): 4462.2574 / 4436.1643 Elapsed 44.07 s\n",
      "In epoch =  1 real_label_smooth =  0.1\n",
      "epoch =  1\n",
      "[1/40] Loss_D: 17.6498 Loss_G: 4523.2620 D(x): 4342.3166 D(G(z)): 4626.4624 / 4612.3886 Elapsed 44.15 s\n",
      "In epoch =  2 real_label_smooth =  3.56755666949e-12\n",
      "epoch =  2\n",
      "[2/40] Loss_D: 1.6169 Loss_G: 5395.4594 D(x): 3517.9936 D(G(z)): 3330.3491 / 3322.5670 Elapsed 43.94 s\n",
      "In epoch =  3 real_label_smooth =  1.23625427814e-33\n",
      "epoch =  3\n",
      "[3/40] Loss_D: 0.8399 Loss_G: 6535.2582 D(x): 2754.9849 D(G(z)): 1918.5237 / 1910.1450 Elapsed 43.93 s\n",
      "In epoch =  4 real_label_smooth =  9.76301524616e-67\n",
      "epoch =  4\n",
      "[4/40] Loss_D: 0.5566 Loss_G: 6048.7730 D(x): 2248.0342 D(G(z)): 2086.4295 / 2079.0269 Elapsed 43.98 s\n",
      "In epoch =  5 real_label_smooth =  3.45770443308e-112\n",
      "epoch =  5\n",
      "[5/40] Loss_D: 0.2449 Loss_G: 6469.6992 D(x): 1877.5628 D(G(z)): 1129.3663 / 1123.9856 Elapsed 43.93 s\n",
      "In epoch =  6 real_label_smooth =  8.76032861174e-171\n",
      "epoch =  6\n",
      "[6/40] Loss_D: 0.1771 Loss_G: 7141.6656 D(x): 1550.1871 D(G(z)): 1777.2945 / 1772.4305 Elapsed 44.03 s\n",
      "In epoch =  7 real_label_smooth =  1.96562724946e-243\n",
      "epoch =  7\n",
      "[7/40] Loss_D: 0.1484 Loss_G: 6480.9819 D(x): 1485.6430 D(G(z)): 1988.4064 / 1975.6682 Elapsed 43.96 s\n",
      "In epoch =  8 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  8\n",
      "[8/40] Loss_D: 0.0591 Loss_G: 6851.9781 D(x): 1451.2835 D(G(z)): 786.9179 / 784.3248 Elapsed 43.86 s\n",
      "In epoch =  9 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  9\n",
      "[9/40] Loss_D: 0.0401 Loss_G: 7469.0433 D(x): 1322.5467 D(G(z)): 452.7343 / 451.6174 Elapsed 44.01 s\n",
      "In epoch =  10 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  10\n",
      "[10/40] Loss_D: 0.0308 Loss_G: 7758.1785 D(x): 1220.4099 D(G(z)): 392.1015 / 391.4477 Elapsed 44.02 s\n",
      "In epoch =  11 real_label_smooth =  0.0\n",
      "epoch =  11\n",
      "[11/40] Loss_D: 0.0256 Loss_G: 8116.6626 D(x): 1109.7536 D(G(z)): 403.0054 / 402.5517 Elapsed 44.02 s\n",
      "In epoch =  12 real_label_smooth =  0.0\n",
      "epoch =  12\n",
      "[12/40] Loss_D: 0.0207 Loss_G: 8442.3490 D(x): 987.8364 D(G(z)): 311.8724 / 311.4308 Elapsed 43.94 s\n",
      "In epoch =  13 real_label_smooth =  0.0\n",
      "epoch =  13\n",
      "[13/40] Loss_D: 0.0175 Loss_G: 8627.5118 D(x): 899.9534 D(G(z)): 7.2230 / 6.5990 Elapsed 43.89 s\n",
      "In epoch =  14 real_label_smooth =  0.0\n",
      "epoch =  14\n",
      "[14/40] Loss_D: 0.0137 Loss_G: 8791.6529 D(x): 816.8278 D(G(z)): -110.9021 / -111.6033 Elapsed 44.02 s\n",
      "In epoch =  15 real_label_smooth =  0.0\n",
      "epoch =  15\n",
      "[15/40] Loss_D: 0.0116 Loss_G: 8688.1247 D(x): 746.2785 D(G(z)): -99.0206 / -99.8978 Elapsed 44.16 s\n",
      "In epoch =  16 real_label_smooth =  0.0\n",
      "epoch =  16\n",
      "[16/40] Loss_D: 0.0094 Loss_G: 8620.9511 D(x): 655.6172 D(G(z)): -31.0945 / -32.3685 Elapsed 44.12 s\n",
      "In epoch =  17 real_label_smooth =  0.0\n",
      "epoch =  17\n",
      "[17/40] Loss_D: 0.0081 Loss_G: 8535.5732 D(x): 577.5503 D(G(z)): 1.8686 / 0.4328 Elapsed 43.93 s\n",
      "In epoch =  18 real_label_smooth =  0.0\n",
      "epoch =  18\n",
      "[18/40] Loss_D: 0.0062 Loss_G: 8548.5833 D(x): 493.5602 D(G(z)): -91.9530 / -93.2519 Elapsed 43.88 s\n",
      "In epoch =  19 real_label_smooth =  0.0\n",
      "epoch =  19\n",
      "[19/40] Loss_D: 0.0051 Loss_G: 8613.2924 D(x): 402.5187 D(G(z)): -170.6925 / -171.8656 Elapsed 44.27 s\n",
      "In epoch =  20 real_label_smooth =  0.0\n",
      "epoch =  20\n",
      "[20/40] Loss_D: 0.0042 Loss_G: 8708.0221 D(x): 297.8587 D(G(z)): -254.8648 / -255.7644 Elapsed 44.07 s\n",
      "In epoch =  21 real_label_smooth =  0.0\n",
      "epoch =  21\n",
      "[21/40] Loss_D: 0.0035 Loss_G: 8796.6124 D(x): 208.3974 D(G(z)): -370.4704 / -371.5899 Elapsed 44.02 s\n",
      "In epoch =  22 real_label_smooth =  -0.0\n",
      "epoch =  22\n",
      "[22/40] Loss_D: 0.0031 Loss_G: 8896.3812 D(x): 167.1734 D(G(z)): -480.6494 / -481.7839 Elapsed 43.99 s\n",
      "In epoch =  23 real_label_smooth =  0.0\n",
      "epoch =  23\n",
      "[23/40] Loss_D: 0.0023 Loss_G: 9029.9191 D(x): 98.8334 D(G(z)): -621.6203 / -622.6580 Elapsed 44.02 s\n",
      "In epoch =  24 real_label_smooth =  -0.0\n",
      "epoch =  24\n",
      "[24/40] Loss_D: 0.0018 Loss_G: 9193.1410 D(x): -67.8317 D(G(z)): -727.2048 / -727.8682 Elapsed 44.08 s\n",
      "In epoch =  25 real_label_smooth =  0.0\n",
      "epoch =  25\n",
      "[25/40] Loss_D: 0.0016 Loss_G: 9292.5756 D(x): -101.6631 D(G(z)): -825.1246 / -826.0307 Elapsed 44.02 s\n",
      "In epoch =  26 real_label_smooth =  0\n",
      "epoch =  26\n",
      "[26/40] Loss_D: 0.0013 Loss_G: 9431.6850 D(x): -160.8143 D(G(z)): -930.0736 / -931.1432 Elapsed 43.99 s\n",
      "In epoch =  27 real_label_smooth =  0\n",
      "epoch =  27\n",
      "[27/40] Loss_D: 0.0010 Loss_G: 9565.9101 D(x): -251.8549 D(G(z)): -1039.0587 / -1040.1826 Elapsed 44.08 s\n",
      "In epoch =  28 real_label_smooth =  0\n",
      "epoch =  28\n",
      "[28/40] Loss_D: 0.0008 Loss_G: 9718.4225 D(x): -312.5424 D(G(z)): -1142.3470 / -1143.0396 Elapsed 44.01 s\n",
      "In epoch =  29 real_label_smooth =  0\n",
      "epoch =  29\n",
      "[29/40] Loss_D: 0.0006 Loss_G: 9802.4248 D(x): -410.4253 D(G(z)): -1227.0709 / -1227.6941 Elapsed 43.97 s\n",
      "In epoch =  30 real_label_smooth =  0\n",
      "epoch =  30\n",
      "[30/40] Loss_D: 0.0005 Loss_G: 9815.9431 D(x): -507.2160 D(G(z)): -1290.4638 / -1291.4075 Elapsed 44.08 s\n",
      "In epoch =  31 real_label_smooth =  0\n",
      "epoch =  31\n",
      "[31/40] Loss_D: 0.0004 Loss_G: 9915.6579 D(x): -599.7771 D(G(z)): -1410.1178 / -1411.0052 Elapsed 44.06 s\n",
      "In epoch =  32 real_label_smooth =  0\n",
      "epoch =  32\n",
      "[32/40] Loss_D: 0.0003 Loss_G: 10010.9121 D(x): -672.9196 D(G(z)): -1536.3751 / -1537.1511 Elapsed 44.10 s\n",
      "In epoch =  33 real_label_smooth =  0\n",
      "epoch =  33\n",
      "[33/40] Loss_D: 0.0002 Loss_G: 10068.2500 D(x): -800.7328 D(G(z)): -1656.6601 / -1657.7962 Elapsed 43.96 s\n",
      "In epoch =  34 real_label_smooth =  0\n",
      "epoch =  34\n",
      "[34/40] Loss_D: 0.0002 Loss_G: 10110.3569 D(x): -910.4975 D(G(z)): -1714.5329 / -1716.1912 Elapsed 43.93 s\n",
      "In epoch =  35 real_label_smooth =  0\n",
      "epoch =  35\n",
      "[35/40] Loss_D: 0.0002 Loss_G: 10118.2311 D(x): -1029.2208 D(G(z)): -1741.1755 / -1742.9692 Elapsed 43.93 s\n",
      "In epoch =  36 real_label_smooth =  0\n",
      "epoch =  36\n",
      "[36/40] Loss_D: 0.0001 Loss_G: 10221.3768 D(x): -1177.5312 D(G(z)): -1856.2786 / -1858.2033 Elapsed 44.01 s\n",
      "In epoch =  37 real_label_smooth =  0\n",
      "epoch =  37\n",
      "[37/40] Loss_D: 0.0001 Loss_G: 10428.5349 D(x): -1320.0269 D(G(z)): -2098.0675 / -2100.1718 Elapsed 44.25 s\n",
      "In epoch =  38 real_label_smooth =  0\n",
      "epoch =  38\n",
      "[38/40] Loss_D: 9.5624 Loss_G: 9660.3090 D(x): 26.5949 D(G(z)): -509.6950 / -577.2580 Elapsed 44.04 s\n",
      "In epoch =  39 real_label_smooth =  0\n",
      "epoch =  39\n",
      "[39/40] Loss_D: 1.9172 Loss_G: 7639.9191 D(x): 1650.3707 D(G(z)): 1701.6152 / 1672.0122 Elapsed 44.11 s\n"
     ]
    }
   ],
   "source": [
    "outputDir = 'outputdir_train_classifier_decay_0d025_label_0d1'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))\n",
    "num_epochs = 40\n",
    "real_labelSmooth = 0.1\n",
    "decay = 0.025\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth, decay = decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets train!\n",
      "In epoch =  0 real_label_smooth =  0.15\n",
      "epoch =  0\n",
      "[0/40] Loss_D: 508.5954 Loss_G: 4500.6372 D(x): 5881.1898 D(G(z)): 5872.5133 / 5836.2248 Elapsed 44.28 s\n",
      "In epoch =  1 real_label_smooth =  0.15\n",
      "epoch =  1\n",
      "[1/40] Loss_D: 13.0091 Loss_G: 4565.4925 D(x): 5494.6438 D(G(z)): 5756.3354 / 5742.2552 Elapsed 43.97 s\n",
      "In epoch =  2 real_label_smooth =  5.35133500423e-12\n",
      "epoch =  2\n",
      "[2/40] Loss_D: 2.1132 Loss_G: 5154.6022 D(x): 4736.9500 D(G(z)): 4080.6326 / 4071.0461 Elapsed 43.98 s\n",
      "In epoch =  3 real_label_smooth =  1.85438141721e-33\n",
      "epoch =  3\n",
      "[3/40] Loss_D: 0.9438 Loss_G: 5502.7155 D(x): 4038.5562 D(G(z)): 3246.6930 / 3238.7257 Elapsed 44.10 s\n",
      "In epoch =  4 real_label_smooth =  1.46445228692e-66\n",
      "epoch =  4\n",
      "[4/40] Loss_D: 15.7246 Loss_G: 5726.9193 D(x): 3399.8026 D(G(z)): 3418.6800 / 3394.4242 Elapsed 43.93 s\n",
      "In epoch =  5 real_label_smooth =  5.18655664962e-112\n",
      "epoch =  5\n",
      "[5/40] Loss_D: 1.5668 Loss_G: 6275.4745 D(x): 2308.9835 D(G(z)): 1944.6503 / 1933.4710 Elapsed 44.10 s\n",
      "In epoch =  6 real_label_smooth =  1.31404929176e-170\n",
      "epoch =  6\n",
      "[6/40] Loss_D: 0.6997 Loss_G: 6641.9941 D(x): 1766.2199 D(G(z)): 2016.6839 / 2010.7416 Elapsed 44.02 s\n",
      "In epoch =  7 real_label_smooth =  2.94844087419e-243\n",
      "epoch =  7\n",
      "[7/40] Loss_D: 1.0625 Loss_G: 7215.7432 D(x): 1721.0583 D(G(z)): 1908.0416 / 1901.4002 Elapsed 44.06 s\n",
      "In epoch =  8 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  8\n",
      "[8/40] Loss_D: 1.4377 Loss_G: 7384.1542 D(x): 1421.2194 D(G(z)): 1225.3831 / 1217.6477 Elapsed 43.89 s\n",
      "In epoch =  9 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  9\n",
      "[9/40] Loss_D: 1.3620 Loss_G: 7974.6970 D(x): 1050.6839 D(G(z)): 1044.5434 / 1038.4358 Elapsed 43.92 s\n",
      "In epoch =  10 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  10\n",
      "[10/40] Loss_D: 0.6176 Loss_G: 8064.3963 D(x): 699.9276 D(G(z)): 573.7700 / 568.5085 Elapsed 43.84 s\n",
      "In epoch =  11 real_label_smooth =  0.0\n",
      "epoch =  11\n",
      "[11/40] Loss_D: 11.8359 Loss_G: 9165.2658 D(x): 1851.3587 D(G(z)): 1483.1286 / 1468.5829 Elapsed 44.06 s\n",
      "In epoch =  12 real_label_smooth =  0.0\n",
      "epoch =  12\n",
      "[12/40] Loss_D: 1.6358 Loss_G: 9187.0975 D(x): 1005.1180 D(G(z)): 771.6754 / 764.1039 Elapsed 43.93 s\n",
      "In epoch =  13 real_label_smooth =  0.0\n",
      "epoch =  13\n",
      "[13/40] Loss_D: 18.3318 Loss_G: 8265.0731 D(x): 1709.7539 D(G(z)): 1381.2119 / 1368.6763 Elapsed 44.10 s\n",
      "In epoch =  14 real_label_smooth =  0.0\n",
      "epoch =  14\n",
      "[14/40] Loss_D: 1.8661 Loss_G: 8640.9599 D(x): 1424.3468 D(G(z)): 1474.1029 / 1469.1308 Elapsed 44.10 s\n",
      "In epoch =  15 real_label_smooth =  0.0\n",
      "epoch =  15\n",
      "[15/40] Loss_D: 1.8161 Loss_G: 9775.6662 D(x): 1054.5030 D(G(z)): 654.9053 / 650.9296 Elapsed 43.88 s\n",
      "In epoch =  16 real_label_smooth =  0.0\n",
      "epoch =  16\n",
      "[16/40] Loss_D: 0.6477 Loss_G: 9598.8589 D(x): 869.7463 D(G(z)): 419.7277 / 416.9397 Elapsed 44.00 s\n",
      "In epoch =  17 real_label_smooth =  0.0\n",
      "epoch =  17\n",
      "[17/40] Loss_D: 0.6695 Loss_G: 10659.3624 D(x): 668.7145 D(G(z)): 84.6532 / 80.7251 Elapsed 44.09 s\n",
      "In epoch =  18 real_label_smooth =  0.0\n",
      "epoch =  18\n",
      "[18/40] Loss_D: 0.6771 Loss_G: 10709.9698 D(x): 564.5586 D(G(z)): -69.6973 / -72.0860 Elapsed 43.99 s\n",
      "In epoch =  19 real_label_smooth =  0.0\n",
      "epoch =  19\n",
      "[19/40] Loss_D: 1.0425 Loss_G: 10242.4841 D(x): 682.5499 D(G(z)): 489.0642 / 485.2915 Elapsed 44.11 s\n",
      "In epoch =  20 real_label_smooth =  0.0\n",
      "epoch =  20\n",
      "[20/40] Loss_D: 18.6595 Loss_G: 10206.4594 D(x): 744.7117 D(G(z)): 557.3284 / 546.6848 Elapsed 44.06 s\n",
      "In epoch =  21 real_label_smooth =  0.0\n",
      "epoch =  21\n",
      "[21/40] Loss_D: 4.5699 Loss_G: 9082.4441 D(x): 1366.9481 D(G(z)): 1115.9510 / 1106.7035 Elapsed 44.14 s\n",
      "In epoch =  22 real_label_smooth =  -0.0\n",
      "epoch =  22\n",
      "[22/40] Loss_D: 1.2745 Loss_G: 9653.7509 D(x): 767.1051 D(G(z)): 433.6175 / 429.0936 Elapsed 43.99 s\n",
      "In epoch =  23 real_label_smooth =  0.0\n",
      "epoch =  23\n",
      "[23/40] Loss_D: 0.8120 Loss_G: 9946.0610 D(x): 311.6419 D(G(z)): 132.3605 / 128.7671 Elapsed 44.05 s\n",
      "In epoch =  24 real_label_smooth =  -0.0\n",
      "epoch =  24\n",
      "[24/40] Loss_D: 0.7963 Loss_G: 10716.9171 D(x): 79.2046 D(G(z)): 196.6788 / 194.3488 Elapsed 44.05 s\n",
      "In epoch =  25 real_label_smooth =  0.0\n",
      "epoch =  25\n",
      "[25/40] Loss_D: 0.2072 Loss_G: 10275.1698 D(x): 59.8731 D(G(z)): -123.6266 / -125.5408 Elapsed 80.43 s\n",
      "In epoch =  26 real_label_smooth =  0\n",
      "epoch =  26\n",
      "[26/40] Loss_D: 0.5594 Loss_G: 10692.7830 D(x): 23.6901 D(G(z)): -420.7086 / -422.8415 Elapsed 53.32 s\n",
      "In epoch =  27 real_label_smooth =  0\n",
      "epoch =  27\n",
      "[27/40] Loss_D: 8.8110 Loss_G: 10930.4601 D(x): 1330.7964 D(G(z)): 819.2487 / 811.3924 Elapsed 49.18 s\n",
      "In epoch =  28 real_label_smooth =  0\n",
      "epoch =  28\n",
      "[28/40] Loss_D: 0.6475 Loss_G: 11079.0337 D(x): 911.0120 D(G(z)): 168.0517 / 164.7195 Elapsed 84.75 s\n",
      "In epoch =  29 real_label_smooth =  0\n",
      "epoch =  29\n",
      "[29/40] Loss_D: 0.7566 Loss_G: 10731.9881 D(x): 542.9032 D(G(z)): 770.9419 / 765.9670 Elapsed 44.10 s\n",
      "In epoch =  30 real_label_smooth =  0\n",
      "epoch =  30\n",
      "[30/40] Loss_D: 0.9548 Loss_G: 12393.6091 D(x): 206.5397 D(G(z)): -21.4036 / -25.3241 Elapsed 43.87 s\n",
      "In epoch =  31 real_label_smooth =  0\n",
      "epoch =  31\n",
      "[31/40] Loss_D: 4.8828 Loss_G: 12114.1020 D(x): 252.0280 D(G(z)): 44.0539 / 37.2052 Elapsed 44.19 s\n",
      "In epoch =  32 real_label_smooth =  0\n",
      "epoch =  32\n",
      "[32/40] Loss_D: 13.7438 Loss_G: 11943.1446 D(x): 491.7232 D(G(z)): 306.0364 / 292.1460 Elapsed 44.06 s\n",
      "In epoch =  33 real_label_smooth =  0\n",
      "epoch =  33\n",
      "[33/40] Loss_D: 1.3032 Loss_G: 10882.0680 D(x): 458.3043 D(G(z)): 4.7266 / -0.2477 Elapsed 44.00 s\n",
      "In epoch =  34 real_label_smooth =  0\n",
      "epoch =  34\n",
      "[34/40] Loss_D: 1.0355 Loss_G: 11472.8753 D(x): 299.9737 D(G(z)): -387.6387 / -391.8868 Elapsed 44.04 s\n",
      "In epoch =  35 real_label_smooth =  0\n",
      "epoch =  35\n",
      "[35/40] Loss_D: 1.5772 Loss_G: 11784.1656 D(x): 351.0903 D(G(z)): 540.6088 / 537.4276 Elapsed 43.93 s\n",
      "In epoch =  36 real_label_smooth =  0\n",
      "epoch =  36\n",
      "[36/40] Loss_D: 1.7587 Loss_G: 12566.8439 D(x): 415.6109 D(G(z)): 325.4101 / 321.7002 Elapsed 44.08 s\n",
      "In epoch =  37 real_label_smooth =  0\n",
      "epoch =  37\n",
      "[37/40] Loss_D: 1.2275 Loss_G: 12803.1988 D(x): 449.3252 D(G(z)): 123.5510 / 120.4821 Elapsed 61.06 s\n",
      "In epoch =  38 real_label_smooth =  0\n",
      "epoch =  38\n",
      "[38/40] Loss_D: 3.5430 Loss_G: 11318.5849 D(x): 331.2192 D(G(z)): -131.6862 / -141.6891 Elapsed 72.54 s\n",
      "In epoch =  39 real_label_smooth =  0\n",
      "epoch =  39\n",
      "[39/40] Loss_D: 0.4811 Loss_G: 10974.0509 D(x): -276.1298 D(G(z)): 605.8895 / 601.0415 Elapsed 44.24 s\n"
     ]
    }
   ],
   "source": [
    "outputDir = 'outputdir_train_classifier_decay_0d025_label_0d15'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))\n",
    "num_epochs = 40\n",
    "real_labelSmooth = 0.15\n",
    "decay = 0.025\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth, decay = decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets train!\n",
      "In epoch =  0 real_label_smooth =  0.2\n",
      "epoch =  0\n",
      "[0/40] Loss_D: 714.9876 Loss_G: 3808.0237 D(x): 7127.4171 D(G(z)): 6878.5448 / 6874.1314 Elapsed 44.11 s\n",
      "In epoch =  1 real_label_smooth =  0.2\n",
      "epoch =  1\n",
      "[1/40] Loss_D: 55.3161 Loss_G: 4500.3197 D(x): 6800.7863 D(G(z)): 6685.2322 / 6675.9286 Elapsed 53.31 s\n",
      "In epoch =  2 real_label_smooth =  7.13511333898e-12\n",
      "epoch =  2\n",
      "[2/40] Loss_D: 2.0881 Loss_G: 5857.2087 D(x): 5035.7761 D(G(z)): 5607.3286 / 5601.8534 Elapsed 80.18 s\n",
      "In epoch =  3 real_label_smooth =  2.47250855628e-33\n",
      "epoch =  3\n",
      "[3/40] Loss_D: 0.8350 Loss_G: 6580.7040 D(x): 3722.6656 D(G(z)): 4425.2984 / 4423.1513 Elapsed 44.00 s\n",
      "In epoch =  4 real_label_smooth =  1.95260304923e-66\n",
      "epoch =  4\n",
      "[4/40] Loss_D: 0.7148 Loss_G: 7119.6863 D(x): 3047.9679 D(G(z)): 3187.5652 / 3184.8675 Elapsed 52.48 s\n",
      "In epoch =  5 real_label_smooth =  6.91540886616e-112\n",
      "epoch =  5\n",
      "[5/40] Loss_D: 0.4383 Loss_G: 7197.2645 D(x): 2441.4306 D(G(z)): 2539.3882 / 2536.0665 Elapsed 81.66 s\n",
      "In epoch =  6 real_label_smooth =  1.75206572235e-170\n",
      "epoch =  6\n",
      "[6/40] Loss_D: 0.4344 Loss_G: 7865.9408 D(x): 1773.8945 D(G(z)): 2049.7841 / 2047.7796 Elapsed 44.15 s\n",
      "In epoch =  7 real_label_smooth =  3.93125449892e-243\n",
      "epoch =  7\n",
      "[7/40] Loss_D: 0.2345 Loss_G: 8096.9008 D(x): 1452.8142 D(G(z)): 1246.3820 / 1243.9939 Elapsed 43.91 s\n",
      "In epoch =  8 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  8\n",
      "[8/40] Loss_D: 66.0488 Loss_G: 8206.4694 D(x): 1398.1517 D(G(z)): 1287.7347 / 1276.4190 Elapsed 43.99 s\n",
      "In epoch =  9 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  9\n",
      "[9/40] Loss_D: 2.0073 Loss_G: 6659.2060 D(x): 2116.1212 D(G(z)): 331.5280 / 321.0712 Elapsed 43.98 s\n",
      "In epoch =  10 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  10\n",
      "[10/40] Loss_D: 0.2382 Loss_G: 7454.6750 D(x): 1705.2064 D(G(z)): -910.7521 / -916.8879 Elapsed 44.05 s\n",
      "In epoch =  11 real_label_smooth =  0.0\n",
      "epoch =  11\n",
      "[11/40] Loss_D: 0.1124 Loss_G: 8103.8762 D(x): 1630.1157 D(G(z)): -1415.2889 / -1419.4831 Elapsed 43.94 s\n",
      "In epoch =  12 real_label_smooth =  0.0\n",
      "epoch =  12\n",
      "[12/40] Loss_D: 0.0762 Loss_G: 8841.0914 D(x): 1562.0418 D(G(z)): -415.7904 / -418.7611 Elapsed 73.42 s\n",
      "In epoch =  13 real_label_smooth =  0.0\n",
      "epoch =  13\n",
      "[13/40] Loss_D: 0.1364 Loss_G: 8910.9145 D(x): 1473.8226 D(G(z)): -235.9565 / -238.3999 Elapsed 60.72 s\n",
      "In epoch =  14 real_label_smooth =  0.0\n",
      "epoch =  14\n",
      "[14/40] Loss_D: 0.9094 Loss_G: 8535.0749 D(x): 1210.9996 D(G(z)): 1780.7985 / 1777.0370 Elapsed 44.11 s\n",
      "In epoch =  15 real_label_smooth =  0.0\n",
      "epoch =  15\n",
      "[15/40] Loss_D: 0.1704 Loss_G: 8571.1518 D(x): 1417.9677 D(G(z)): 2367.6438 / 2366.0615 Elapsed 78.57 s\n",
      "In epoch =  16 real_label_smooth =  0.0\n",
      "epoch =  16\n",
      "[16/40] Loss_D: 0.6385 Loss_G: 8501.3461 D(x): 1085.2717 D(G(z)): 965.6186 / 962.3723 Elapsed 55.56 s\n",
      "In epoch =  17 real_label_smooth =  0.0\n",
      "epoch =  17\n",
      "[17/40] Loss_D: 2.6575 Loss_G: 9937.5469 D(x): 2206.6959 D(G(z)): 2195.9984 / 2192.0288 Elapsed 45.33 s\n",
      "In epoch =  18 real_label_smooth =  0.0\n",
      "epoch =  18\n",
      "[18/40] Loss_D: 24.7205 Loss_G: 10127.6447 D(x): 2480.6338 D(G(z)): 2224.8401 / 2213.7566 Elapsed 88.88 s\n",
      "In epoch =  19 real_label_smooth =  0.0\n",
      "epoch =  19\n",
      "[19/40] Loss_D: 2.2552 Loss_G: 8757.6180 D(x): 2994.0242 D(G(z)): 1080.8782 / 1071.8493 Elapsed 89.20 s\n",
      "In epoch =  20 real_label_smooth =  0.0\n",
      "epoch =  20\n",
      "[20/40] Loss_D: 0.6315 Loss_G: 8803.3619 D(x): 2558.5155 D(G(z)): 2745.7677 / 2743.0593 Elapsed 88.52 s\n",
      "In epoch =  21 real_label_smooth =  0.0\n",
      "epoch =  21\n",
      "[21/40] Loss_D: 0.6148 Loss_G: 9517.4864 D(x): 2106.1813 D(G(z)): 1727.5647 / 1725.0967 Elapsed 45.82 s\n",
      "In epoch =  22 real_label_smooth =  -0.0\n",
      "epoch =  22\n",
      "[22/40] Loss_D: 18.9748 Loss_G: 10274.2258 D(x): 1478.8467 D(G(z)): 1326.2508 / 1317.4982 Elapsed 44.00 s\n",
      "In epoch =  23 real_label_smooth =  0.0\n",
      "epoch =  23\n",
      "[23/40] Loss_D: 1.7677 Loss_G: 10041.1073 D(x): 1330.9378 D(G(z)): 1259.8241 / 1255.7319 Elapsed 44.07 s\n",
      "In epoch =  24 real_label_smooth =  -0.0\n",
      "epoch =  24\n",
      "[24/40] Loss_D: 0.9805 Loss_G: 11023.5693 D(x): 1224.4260 D(G(z)): 1134.3414 / 1132.2064 Elapsed 43.94 s\n",
      "In epoch =  25 real_label_smooth =  0.0\n",
      "epoch =  25\n",
      "[25/40] Loss_D: 0.5547 Loss_G: 10622.9484 D(x): 1163.7814 D(G(z)): 659.0005 / 657.0805 Elapsed 43.99 s\n",
      "In epoch =  26 real_label_smooth =  0\n",
      "epoch =  26\n",
      "[26/40] Loss_D: 0.5009 Loss_G: 11186.1994 D(x): 1092.7460 D(G(z)): 759.9413 / 759.0453 Elapsed 44.04 s\n",
      "In epoch =  27 real_label_smooth =  0\n",
      "epoch =  27\n",
      "[27/40] Loss_D: 7.2737 Loss_G: 11040.5963 D(x): 1011.9688 D(G(z)): 696.2369 / 694.3978 Elapsed 43.92 s\n",
      "In epoch =  28 real_label_smooth =  0\n",
      "epoch =  28\n",
      "[28/40] Loss_D: 5.6608 Loss_G: 10354.5890 D(x): 2113.0320 D(G(z)): 1750.2602 / 1741.9319 Elapsed 43.96 s\n",
      "In epoch =  29 real_label_smooth =  0\n",
      "epoch =  29\n",
      "[29/40] Loss_D: 0.6387 Loss_G: 10584.3443 D(x): 1710.7307 D(G(z)): 1548.1029 / 1545.3430 Elapsed 43.85 s\n",
      "In epoch =  30 real_label_smooth =  0\n",
      "epoch =  30\n",
      "[30/40] Loss_D: 0.5643 Loss_G: 11058.4768 D(x): 1448.3876 D(G(z)): 1148.5595 / 1147.0459 Elapsed 44.16 s\n",
      "In epoch =  31 real_label_smooth =  0\n",
      "epoch =  31\n",
      "[31/40] Loss_D: 1.7292 Loss_G: 11900.3574 D(x): 1265.2947 D(G(z)): 780.8357 / 778.5479 Elapsed 43.87 s\n",
      "In epoch =  32 real_label_smooth =  0\n",
      "epoch =  32\n",
      "[32/40] Loss_D: 0.6232 Loss_G: 11855.7878 D(x): 1254.8287 D(G(z)): 305.0655 / 302.0016 Elapsed 44.13 s\n",
      "In epoch =  33 real_label_smooth =  0\n",
      "epoch =  33\n",
      "[33/40] Loss_D: 1.9418 Loss_G: 12569.6495 D(x): 1171.3934 D(G(z)): 879.4306 / 876.0754 Elapsed 44.08 s\n",
      "In epoch =  34 real_label_smooth =  0\n",
      "epoch =  34\n",
      "[34/40] Loss_D: 1.8794 Loss_G: 12308.4178 D(x): 1180.9391 D(G(z)): 1194.2119 / 1190.8852 Elapsed 44.10 s\n",
      "In epoch =  35 real_label_smooth =  0\n",
      "epoch =  35\n",
      "[35/40] Loss_D: 1.2365 Loss_G: 11832.3407 D(x): 985.6011 D(G(z)): 1123.4323 / 1120.0005 Elapsed 44.04 s\n",
      "In epoch =  36 real_label_smooth =  0\n",
      "epoch =  36\n",
      "[36/40] Loss_D: 0.2542 Loss_G: 11473.7864 D(x): 740.2576 D(G(z)): 818.2848 / 815.9243 Elapsed 43.98 s\n",
      "In epoch =  37 real_label_smooth =  0\n",
      "epoch =  37\n",
      "[37/40] Loss_D: 0.4697 Loss_G: 12312.1262 D(x): 546.8212 D(G(z)): 382.6193 / 381.7923 Elapsed 44.02 s\n",
      "In epoch =  38 real_label_smooth =  0\n",
      "epoch =  38\n",
      "[38/40] Loss_D: 2.1092 Loss_G: 12326.3049 D(x): 682.4380 D(G(z)): 285.0019 / 281.1157 Elapsed 44.00 s\n",
      "In epoch =  39 real_label_smooth =  0\n",
      "epoch =  39\n",
      "[39/40] Loss_D: 7.9252 Loss_G: 12405.4802 D(x): 609.5948 D(G(z)): 241.5894 / 237.2217 Elapsed 44.02 s\n"
     ]
    }
   ],
   "source": [
    "outputDir = 'outputdir_train_classifier_decay_0d025_label_0d20'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))\n",
    "num_epochs = 40\n",
    "real_labelSmooth = 0.20\n",
    "decay = 0.025\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth, decay = decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets train!\n",
      "In epoch =  0 real_label_smooth =  0.25\n",
      "epoch =  0\n",
      "[0/40] Loss_D: 819.8724 Loss_G: 3617.0136 D(x): 7135.3925 D(G(z)): 7245.4033 / 7240.3889 Elapsed 44.21 s\n",
      "In epoch =  1 real_label_smooth =  0.25\n",
      "epoch =  1\n",
      "[1/40] Loss_D: 44.5112 Loss_G: 4426.5321 D(x): 6857.5648 D(G(z)): 6502.6205 / 6493.4633 Elapsed 44.05 s\n",
      "In epoch =  2 real_label_smooth =  8.91889167372e-12\n",
      "epoch =  2\n",
      "[2/40] Loss_D: 2.3197 Loss_G: 6005.3184 D(x): 5123.9166 D(G(z)): 5028.4857 / 5022.7162 Elapsed 43.92 s\n",
      "In epoch =  3 real_label_smooth =  3.09063569535e-33\n",
      "epoch =  3\n",
      "[3/40] Loss_D: 0.5356 Loss_G: 7082.0629 D(x): 3333.4222 D(G(z)): 3285.5788 / 3282.3544 Elapsed 44.05 s\n",
      "In epoch =  4 real_label_smooth =  2.44075381154e-66\n",
      "epoch =  4\n",
      "[4/40] Loss_D: 0.3983 Loss_G: 6864.5100 D(x): 2101.6130 D(G(z)): 3885.7073 / 3882.2587 Elapsed 44.04 s\n",
      "In epoch =  5 real_label_smooth =  8.6442610827e-112\n",
      "epoch =  5\n",
      "[5/40] Loss_D: 0.0863 Loss_G: 7002.1890 D(x): 2075.4041 D(G(z)): 4631.5733 / 4630.1305 Elapsed 44.05 s\n",
      "In epoch =  6 real_label_smooth =  2.19008215293e-170\n",
      "epoch =  6\n",
      "[6/40] Loss_D: 0.0491 Loss_G: 7690.1784 D(x): 2046.9844 D(G(z)): 2461.4047 / 2460.4467 Elapsed 44.04 s\n",
      "In epoch =  7 real_label_smooth =  4.91406812365e-243\n",
      "epoch =  7\n",
      "[7/40] Loss_D: 0.0314 Loss_G: 7944.1849 D(x): 2001.5983 D(G(z)): 914.6409 / 914.1342 Elapsed 43.99 s\n",
      "In epoch =  8 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  8\n",
      "[8/40] Loss_D: 0.0221 Loss_G: 8335.8290 D(x): 1881.7404 D(G(z)): 66.4699 / 65.8424 Elapsed 43.98 s\n",
      "In epoch =  9 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  9\n",
      "[9/40] Loss_D: 0.0152 Loss_G: 8527.7122 D(x): 1749.9427 D(G(z)): -351.8691 / -352.2379 Elapsed 44.00 s\n",
      "In epoch =  10 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  10\n",
      "[10/40] Loss_D: 0.0120 Loss_G: 8578.8054 D(x): 1705.6316 D(G(z)): -517.7962 / -518.0906 Elapsed 44.04 s\n",
      "In epoch =  11 real_label_smooth =  0.0\n",
      "epoch =  11\n",
      "[11/40] Loss_D: 0.0095 Loss_G: 8671.9358 D(x): 1616.1053 D(G(z)): -603.4187 / -603.7711 Elapsed 43.92 s\n",
      "In epoch =  12 real_label_smooth =  0.0\n",
      "epoch =  12\n",
      "[12/40] Loss_D: 0.0074 Loss_G: 8755.8818 D(x): 1575.2151 D(G(z)): -709.1023 / -709.4167 Elapsed 44.05 s\n",
      "In epoch =  13 real_label_smooth =  0.0\n",
      "epoch =  13\n",
      "[13/40] Loss_D: 0.0068 Loss_G: 8909.8351 D(x): 1511.2021 D(G(z)): -859.6639 / -859.9895 Elapsed 43.96 s\n",
      "In epoch =  14 real_label_smooth =  0.0\n",
      "epoch =  14\n",
      "[14/40] Loss_D: 0.0056 Loss_G: 9081.7553 D(x): 1440.6406 D(G(z)): -779.8283 / -780.1349 Elapsed 43.93 s\n",
      "In epoch =  15 real_label_smooth =  0.0\n",
      "epoch =  15\n",
      "[15/40] Loss_D: 0.0048 Loss_G: 9016.4860 D(x): 1394.2730 D(G(z)): -404.4468 / -404.7629 Elapsed 43.89 s\n",
      "In epoch =  16 real_label_smooth =  0.0\n",
      "epoch =  16\n",
      "[16/40] Loss_D: 0.0043 Loss_G: 8900.2583 D(x): 1301.7326 D(G(z)): 132.0774 / 131.6180 Elapsed 43.84 s\n",
      "In epoch =  17 real_label_smooth =  0.0\n",
      "epoch =  17\n",
      "[17/40] Loss_D: 0.0038 Loss_G: 8910.0019 D(x): 1240.8488 D(G(z)): 532.3189 / 531.6989 Elapsed 44.16 s\n",
      "In epoch =  18 real_label_smooth =  0.0\n",
      "epoch =  18\n",
      "[18/40] Loss_D: 0.0033 Loss_G: 8757.4165 D(x): 1254.0295 D(G(z)): 504.0908 / 503.4828 Elapsed 44.03 s\n",
      "In epoch =  19 real_label_smooth =  0.0\n",
      "epoch =  19\n",
      "[19/40] Loss_D: 0.0030 Loss_G: 8375.4984 D(x): 1169.0869 D(G(z)): 297.0055 / 296.4394 Elapsed 43.93 s\n",
      "In epoch =  20 real_label_smooth =  0.0\n",
      "epoch =  20\n",
      "[20/40] Loss_D: 0.0065 Loss_G: 7380.7467 D(x): 1007.9704 D(G(z)): 61.9676 / 60.9335 Elapsed 43.93 s\n",
      "In epoch =  21 real_label_smooth =  0.0\n",
      "epoch =  21\n",
      "[21/40] Loss_D: 0.0048 Loss_G: 7864.3723 D(x): 820.9856 D(G(z)): -181.0412 / -182.1259 Elapsed 43.97 s\n",
      "In epoch =  22 real_label_smooth =  -0.0\n",
      "epoch =  22\n",
      "[22/40] Loss_D: 0.0029 Loss_G: 8657.0019 D(x): 779.6313 D(G(z)): -459.2380 / -459.9829 Elapsed 44.05 s\n",
      "In epoch =  23 real_label_smooth =  0.0\n",
      "epoch =  23\n",
      "[23/40] Loss_D: 0.0019 Loss_G: 9263.4186 D(x): 654.1251 D(G(z)): -396.0054 / -396.5957 Elapsed 43.98 s\n",
      "In epoch =  24 real_label_smooth =  -0.0\n",
      "epoch =  24\n",
      "[24/40] Loss_D: 0.0014 Loss_G: 9251.5047 D(x): 567.7560 D(G(z)): -501.8812 / -502.3958 Elapsed 43.97 s\n",
      "In epoch =  25 real_label_smooth =  0.0\n",
      "epoch =  25\n",
      "[25/40] Loss_D: 0.0010 Loss_G: 9453.2857 D(x): 509.7490 D(G(z)): -595.3054 / -595.6879 Elapsed 44.15 s\n",
      "In epoch =  26 real_label_smooth =  0\n",
      "epoch =  26\n",
      "[26/40] Loss_D: 0.0009 Loss_G: 9581.6508 D(x): 441.1985 D(G(z)): -622.8206 / -623.2999 Elapsed 43.89 s\n",
      "In epoch =  27 real_label_smooth =  0\n",
      "epoch =  27\n",
      "[27/40] Loss_D: 0.0007 Loss_G: 9443.0998 D(x): 406.4551 D(G(z)): -630.5046 / -630.9722 Elapsed 44.02 s\n",
      "In epoch =  28 real_label_smooth =  0\n",
      "epoch =  28\n",
      "[28/40] Loss_D: 0.0006 Loss_G: 9696.3574 D(x): 331.8652 D(G(z)): -697.5037 / -697.9688 Elapsed 43.87 s\n",
      "In epoch =  29 real_label_smooth =  0\n",
      "epoch =  29\n",
      "[29/40] Loss_D: 0.0005 Loss_G: 9723.0943 D(x): 318.1294 D(G(z)): -833.2688 / -833.6790 Elapsed 44.05 s\n",
      "In epoch =  30 real_label_smooth =  0\n",
      "epoch =  30\n",
      "[30/40] Loss_D: 0.0003 Loss_G: 9589.8198 D(x): 241.4085 D(G(z)): -905.3950 / -905.6952 Elapsed 44.04 s\n",
      "In epoch =  31 real_label_smooth =  0\n",
      "epoch =  31\n",
      "[31/40] Loss_D: 0.0003 Loss_G: 9601.9124 D(x): 248.9576 D(G(z)): -980.8968 / -981.1863 Elapsed 43.93 s\n",
      "In epoch =  32 real_label_smooth =  0\n",
      "epoch =  32\n",
      "[32/40] Loss_D: 0.0002 Loss_G: 9745.0106 D(x): 156.8647 D(G(z)): -1058.9893 / -1059.3567 Elapsed 44.21 s\n",
      "In epoch =  33 real_label_smooth =  0\n",
      "epoch =  33\n",
      "[33/40] Loss_D: 0.0002 Loss_G: 9944.0072 D(x): 92.9669 D(G(z)): -1090.8621 / -1091.1260 Elapsed 86.48 s\n",
      "In epoch =  34 real_label_smooth =  0\n",
      "epoch =  34\n",
      "[34/40] Loss_D: 0.0001 Loss_G: 10011.6579 D(x): 36.0254 D(G(z)): -1082.7678 / -1082.9510 Elapsed 87.91 s\n",
      "In epoch =  35 real_label_smooth =  0\n",
      "epoch =  35\n",
      "[35/40] Loss_D: 0.0001 Loss_G: 10211.9695 D(x): -93.1287 D(G(z)): -1089.3459 / -1089.5648 Elapsed 88.72 s\n",
      "In epoch =  36 real_label_smooth =  0\n",
      "epoch =  36\n",
      "[36/40] Loss_D: 0.0001 Loss_G: 10290.1057 D(x): -225.5523 D(G(z)): -1146.7655 / -1147.0497 Elapsed 50.71 s\n",
      "In epoch =  37 real_label_smooth =  0\n",
      "epoch =  37\n",
      "[37/40] Loss_D: 13.9650 Loss_G: 9780.0943 D(x): 1358.9484 D(G(z)): 948.3117 / 924.6742 Elapsed 44.06 s\n",
      "In epoch =  38 real_label_smooth =  0\n",
      "epoch =  38\n",
      "[38/40] Loss_D: 1.3556 Loss_G: 9823.4888 D(x): 2150.4540 D(G(z)): 2802.3165 / 2795.5009 Elapsed 44.04 s\n",
      "In epoch =  39 real_label_smooth =  0\n",
      "epoch =  39\n",
      "[39/40] Loss_D: 0.4898 Loss_G: 9722.7266 D(x): 1950.8325 D(G(z)): 2168.3294 / 2166.4728 Elapsed 43.96 s\n"
     ]
    }
   ],
   "source": [
    "outputDir = 'outputdir_train_classifier_decay_0d025_label_0d25'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))\n",
    "num_epochs = 40\n",
    "real_labelSmooth = 0.25\n",
    "decay = 0.025\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth, decay = decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets train!\n",
      "In epoch =  0 real_label_smooth =  0.3\n",
      "epoch =  0\n",
      "[0/40] Loss_D: 781.7199 Loss_G: 3715.1845 D(x): 10748.5893 D(G(z)): 11206.2752 / 11218.2634 Elapsed 44.02 s\n",
      "In epoch =  1 real_label_smooth =  0.3\n",
      "epoch =  1\n",
      "[1/40] Loss_D: 49.6429 Loss_G: 4539.6461 D(x): 10675.3030 D(G(z)): 10760.4706 / 10755.2856 Elapsed 43.93 s\n",
      "In epoch =  2 real_label_smooth =  1.07026700085e-11\n",
      "epoch =  2\n",
      "[2/40] Loss_D: 2.7163 Loss_G: 5265.9083 D(x): 9479.4939 D(G(z)): 9948.6701 / 9944.2290 Elapsed 44.01 s\n",
      "In epoch =  3 real_label_smooth =  3.70876283442e-33\n",
      "epoch =  3\n",
      "[3/40] Loss_D: 0.8992 Loss_G: 6183.0167 D(x): 8002.1903 D(G(z)): 8749.0909 / 8744.7351 Elapsed 43.98 s\n",
      "In epoch =  4 real_label_smooth =  2.92890457385e-66\n",
      "epoch =  4\n",
      "[4/40] Loss_D: 0.6318 Loss_G: 7038.9538 D(x): 6699.0375 D(G(z)): 7950.7834 / 7947.7233 Elapsed 43.94 s\n",
      "In epoch =  5 real_label_smooth =  1.03731132992e-111\n",
      "epoch =  5\n",
      "[5/40] Loss_D: 32.3553 Loss_G: 6709.2191 D(x): 5080.7122 D(G(z)): 5468.9367 / 5454.8845 Elapsed 43.84 s\n",
      "In epoch =  6 real_label_smooth =  2.62809858352e-170\n",
      "epoch =  6\n",
      "[6/40] Loss_D: 1.4145 Loss_G: 6770.3478 D(x): 4001.0692 D(G(z)): 4897.8354 / 4897.2436 Elapsed 44.00 s\n",
      "In epoch =  7 real_label_smooth =  5.89688174838e-243\n",
      "epoch =  7\n",
      "[7/40] Loss_D: 0.7610 Loss_G: 7480.8044 D(x): 3524.3376 D(G(z)): 972.1126 / 969.3591 Elapsed 44.07 s\n",
      "In epoch =  8 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  8\n",
      "[8/40] Loss_D: 0.5382 Loss_G: 7716.3750 D(x): 3128.5382 D(G(z)): 2762.0102 / 2760.7286 Elapsed 44.05 s\n",
      "In epoch =  9 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  9\n",
      "[9/40] Loss_D: 1.7677 Loss_G: 8354.7325 D(x): 3302.2003 D(G(z)): 3508.5948 / 3508.0131 Elapsed 43.97 s\n",
      "In epoch =  10 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  10\n",
      "[10/40] Loss_D: 1.2182 Loss_G: 9151.2410 D(x): 3096.0177 D(G(z)): 3050.8814 / 3047.6260 Elapsed 43.93 s\n",
      "In epoch =  11 real_label_smooth =  0.0\n",
      "epoch =  11\n",
      "[11/40] Loss_D: 1.5301 Loss_G: 8908.4538 D(x): 3188.2186 D(G(z)): 2789.5130 / 2788.1116 Elapsed 43.99 s\n",
      "In epoch =  12 real_label_smooth =  0.0\n",
      "epoch =  12\n",
      "[12/40] Loss_D: 0.5111 Loss_G: 9276.8244 D(x): 3070.2426 D(G(z)): 2376.2945 / 2374.5671 Elapsed 43.90 s\n",
      "In epoch =  13 real_label_smooth =  0.0\n",
      "epoch =  13\n",
      "[13/40] Loss_D: 0.4204 Loss_G: 9336.9372 D(x): 2985.2110 D(G(z)): 2940.5235 / 2939.8223 Elapsed 44.08 s\n",
      "In epoch =  14 real_label_smooth =  0.0\n",
      "epoch =  14\n",
      "[14/40] Loss_D: 1.1168 Loss_G: 9546.0281 D(x): 3155.2722 D(G(z)): 3769.9125 / 3770.0267 Elapsed 44.13 s\n",
      "In epoch =  15 real_label_smooth =  0.0\n",
      "epoch =  15\n",
      "[15/40] Loss_D: 18.5429 Loss_G: 8245.2633 D(x): 4914.9813 D(G(z)): 4492.7989 / 4487.3229 Elapsed 43.97 s\n",
      "In epoch =  16 real_label_smooth =  0.0\n",
      "epoch =  16\n",
      "[16/40] Loss_D: 2.1841 Loss_G: 8930.5692 D(x): 3721.8884 D(G(z)): 4466.4837 / 4463.2429 Elapsed 43.94 s\n",
      "In epoch =  17 real_label_smooth =  0.0\n",
      "epoch =  17\n",
      "[17/40] Loss_D: 0.7413 Loss_G: 9449.7473 D(x): 3055.7078 D(G(z)): 2537.0092 / 2534.1159 Elapsed 43.95 s\n",
      "In epoch =  18 real_label_smooth =  0.0\n",
      "epoch =  18\n",
      "[18/40] Loss_D: 0.5278 Loss_G: 9912.8843 D(x): 2815.1518 D(G(z)): 3227.2701 / 3227.6108 Elapsed 44.10 s\n",
      "In epoch =  19 real_label_smooth =  0.0\n",
      "epoch =  19\n",
      "[19/40] Loss_D: 0.5832 Loss_G: 10400.6550 D(x): 2795.3297 D(G(z)): 2933.1358 / 2931.2625 Elapsed 43.94 s\n",
      "In epoch =  20 real_label_smooth =  0.0\n",
      "epoch =  20\n",
      "[20/40] Loss_D: 0.3413 Loss_G: 10402.3522 D(x): 2969.5067 D(G(z)): 2967.7654 / 2967.9302 Elapsed 43.99 s\n",
      "In epoch =  21 real_label_smooth =  0.0\n",
      "epoch =  21\n",
      "[21/40] Loss_D: 1.6476 Loss_G: 9834.1881 D(x): 3036.8262 D(G(z)): 2750.0709 / 2748.2277 Elapsed 44.14 s\n",
      "In epoch =  22 real_label_smooth =  -0.0\n",
      "epoch =  22\n",
      "[22/40] Loss_D: 6.2344 Loss_G: 11490.1125 D(x): 2885.1235 D(G(z)): 2787.7506 / 2781.9607 Elapsed 43.86 s\n",
      "In epoch =  23 real_label_smooth =  0.0\n",
      "epoch =  23\n",
      "[23/40] Loss_D: 1.3681 Loss_G: 11079.9513 D(x): 2628.2180 D(G(z)): 2637.7920 / 2636.0894 Elapsed 44.07 s\n",
      "In epoch =  24 real_label_smooth =  -0.0\n",
      "epoch =  24\n",
      "[24/40] Loss_D: 1.1517 Loss_G: 11102.0645 D(x): 2819.0994 D(G(z)): 2907.0784 / 2907.3021 Elapsed 43.90 s\n",
      "In epoch =  25 real_label_smooth =  0.0\n",
      "epoch =  25\n",
      "[25/40] Loss_D: 5.5603 Loss_G: 11573.6754 D(x): 3097.4300 D(G(z)): 3571.8019 / 3569.0727 Elapsed 44.12 s\n",
      "In epoch =  26 real_label_smooth =  0\n",
      "epoch =  26\n",
      "[26/40] Loss_D: 1.0868 Loss_G: 10785.0712 D(x): 3303.2031 D(G(z)): 3184.0161 / 3182.1798 Elapsed 43.82 s\n",
      "In epoch =  27 real_label_smooth =  0\n",
      "epoch =  27\n",
      "[27/40] Loss_D: 0.5656 Loss_G: 10905.3400 D(x): 2666.6005 D(G(z)): 2495.6230 / 2492.9367 Elapsed 44.12 s\n",
      "In epoch =  28 real_label_smooth =  0\n",
      "epoch =  28\n",
      "[28/40] Loss_D: 0.1027 Loss_G: 10191.6271 D(x): 2327.8183 D(G(z)): 2147.4215 / 2145.4153 Elapsed 44.11 s\n",
      "In epoch =  29 real_label_smooth =  0\n",
      "epoch =  29\n",
      "[29/40] Loss_D: 0.0538 Loss_G: 10163.4149 D(x): 1883.6957 D(G(z)): 1922.6175 / 1921.9833 Elapsed 44.06 s\n",
      "In epoch =  30 real_label_smooth =  0\n",
      "epoch =  30\n",
      "[30/40] Loss_D: 0.0183 Loss_G: 10792.9048 D(x): 1724.1179 D(G(z)): 1756.5615 / 1755.5985 Elapsed 43.96 s\n",
      "In epoch =  31 real_label_smooth =  0\n",
      "epoch =  31\n",
      "[31/40] Loss_D: 0.0305 Loss_G: 11250.8326 D(x): 1461.3673 D(G(z)): 1463.0806 / 1462.1473 Elapsed 43.98 s\n",
      "In epoch =  32 real_label_smooth =  0\n",
      "epoch =  32\n",
      "[32/40] Loss_D: 0.0251 Loss_G: 11214.1763 D(x): 1306.6242 D(G(z)): 1546.3008 / 1545.5374 Elapsed 44.02 s\n",
      "In epoch =  33 real_label_smooth =  0\n",
      "epoch =  33\n",
      "[33/40] Loss_D: 7.5489 Loss_G: 11604.0669 D(x): 2020.6077 D(G(z)): 2431.3556 / 2433.1825 Elapsed 44.26 s\n",
      "In epoch =  34 real_label_smooth =  0\n",
      "epoch =  34\n",
      "[34/40] Loss_D: 2.7680 Loss_G: 12463.3377 D(x): 2965.7078 D(G(z)): 2562.4112 / 2559.3600 Elapsed 43.97 s\n",
      "In epoch =  35 real_label_smooth =  0\n",
      "epoch =  35\n",
      "[35/40] Loss_D: 0.4457 Loss_G: 11251.8187 D(x): 2711.1252 D(G(z)): 2115.0216 / 2113.3399 Elapsed 44.19 s\n",
      "In epoch =  36 real_label_smooth =  0\n",
      "epoch =  36\n",
      "[36/40] Loss_D: 0.1121 Loss_G: 10430.1108 D(x): 1964.8933 D(G(z)): 1901.6065 / 1899.9066 Elapsed 44.03 s\n",
      "In epoch =  37 real_label_smooth =  0\n",
      "epoch =  37\n",
      "[37/40] Loss_D: 0.3457 Loss_G: 11520.0292 D(x): 1973.1848 D(G(z)): 1507.9093 / 1506.6412 Elapsed 44.02 s\n",
      "In epoch =  38 real_label_smooth =  0\n",
      "epoch =  38\n",
      "[38/40] Loss_D: 10.2589 Loss_G: 11824.9409 D(x): 2157.7773 D(G(z)): 2348.2501 / 2347.5477 Elapsed 43.91 s\n",
      "In epoch =  39 real_label_smooth =  0\n",
      "epoch =  39\n",
      "[39/40] Loss_D: 1.4004 Loss_G: 11412.0861 D(x): 3036.4128 D(G(z)): 2838.3106 / 2835.8340 Elapsed 44.01 s\n"
     ]
    }
   ],
   "source": [
    "outputDir = 'outputdir_train_classifier_decay_0d025_label_0d30'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))\n",
    "num_epochs = 40\n",
    "real_labelSmooth = 0.30\n",
    "decay = 0.025\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth, decay = decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS error: [Errno 17] File exists: 'outputdir_train_classifier_decay_0d025_label_0d15'\n",
      "Lets train!\n",
      "In epoch =  0 real_label_smooth =  0.15\n",
      "epoch =  0\n",
      "[0/40] Loss_D: 549.7038 Loss_G: 3797.2124 D(x): 12137.1745 D(G(z)): 12496.9786 / 12504.5495 Elapsed 43.18 s\n",
      "In epoch =  1 real_label_smooth =  0.15\n",
      "epoch =  1\n",
      "[1/40] Loss_D: 17.5712 Loss_G: 4774.6924 D(x): 11105.6962 D(G(z)): 11200.3752 / 11193.0390 Elapsed 44.03 s\n",
      "In epoch =  2 real_label_smooth =  5.35133500423e-12\n",
      "epoch =  2\n",
      "[2/40] Loss_D: 1.6773 Loss_G: 6349.0323 D(x): 8425.8559 D(G(z)): 9316.0792 / 9309.6890 Elapsed 43.85 s\n",
      "In epoch =  3 real_label_smooth =  1.85438141721e-33\n",
      "epoch =  3\n",
      "[3/40] Loss_D: 0.6435 Loss_G: 8157.9107 D(x): 6153.2338 D(G(z)): 7238.1553 / 7235.1724 Elapsed 44.05 s\n",
      "In epoch =  4 real_label_smooth =  1.46445228692e-66\n",
      "epoch =  4\n",
      "[4/40] Loss_D: 0.3276 Loss_G: 8864.2031 D(x): 5123.3387 D(G(z)): 6122.1273 / 6120.8418 Elapsed 44.41 s\n",
      "In epoch =  5 real_label_smooth =  5.18655664962e-112\n",
      "epoch =  5\n",
      "[5/40] Loss_D: 0.4415 Loss_G: 9474.6161 D(x): 4668.3166 D(G(z)): 5138.8393 / 5137.3810 Elapsed 44.71 s\n",
      "In epoch =  6 real_label_smooth =  1.31404929176e-170\n",
      "epoch =  6\n",
      "[6/40] Loss_D: 0.5380 Loss_G: 9468.4576 D(x): 4248.9608 D(G(z)): 4657.1499 / 4654.5937 Elapsed 44.85 s\n",
      "In epoch =  7 real_label_smooth =  2.94844087419e-243\n",
      "epoch =  7\n",
      "[7/40] Loss_D: 0.3838 Loss_G: 8883.3702 D(x): 3871.3440 D(G(z)): 4175.0581 / 4174.9624 Elapsed 44.90 s\n",
      "In epoch =  8 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  8\n",
      "[8/40] Loss_D: 1.0691 Loss_G: 9172.2626 D(x): 4565.1625 D(G(z)): 4660.3184 / 4664.0722 Elapsed 45.01 s\n",
      "In epoch =  9 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  9\n",
      "[9/40] Loss_D: 4.6651 Loss_G: 9881.2629 D(x): 5572.9894 D(G(z)): 5679.1022 / 5678.4848 Elapsed 45.02 s\n",
      "In epoch =  10 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  10\n",
      "[10/40] Loss_D: 1.3309 Loss_G: 9450.0733 D(x): 5424.9744 D(G(z)): 5896.8261 / 5895.2786 Elapsed 45.22 s\n",
      "In epoch =  11 real_label_smooth =  0.0\n",
      "epoch =  11\n",
      "[11/40] Loss_D: 0.2851 Loss_G: 9817.9722 D(x): 4385.6116 D(G(z)): 4851.5626 / 4849.4486 Elapsed 45.15 s\n",
      "In epoch =  12 real_label_smooth =  0.0\n",
      "epoch =  12\n",
      "[12/40] Loss_D: 2.2015 Loss_G: 10425.8397 D(x): 3887.6831 D(G(z)): 3936.7471 / 3935.8147 Elapsed 45.04 s\n",
      "In epoch =  13 real_label_smooth =  0.0\n",
      "epoch =  13\n",
      "[13/40] Loss_D: 0.9340 Loss_G: 10507.6688 D(x): 4307.3954 D(G(z)): 4245.4301 / 4244.6130 Elapsed 45.20 s\n",
      "In epoch =  14 real_label_smooth =  0.0\n",
      "epoch =  14\n",
      "[14/40] Loss_D: 0.6124 Loss_G: 10947.3856 D(x): 4557.2185 D(G(z)): 4849.6223 / 4849.7045 Elapsed 45.45 s\n",
      "In epoch =  15 real_label_smooth =  0.0\n",
      "epoch =  15\n",
      "[15/40] Loss_D: 9.0097 Loss_G: 10995.3543 D(x): 4357.0888 D(G(z)): 4411.6546 / 4410.5724 Elapsed 45.19 s\n",
      "In epoch =  16 real_label_smooth =  0.0\n",
      "epoch =  16\n",
      "[16/40] Loss_D: 1.2358 Loss_G: 9768.4135 D(x): 4626.4372 D(G(z)): 4288.4533 / 4285.7566 Elapsed 45.31 s\n",
      "In epoch =  17 real_label_smooth =  0.0\n",
      "epoch =  17\n",
      "[17/40] Loss_D: 0.7396 Loss_G: 10065.0024 D(x): 4354.8112 D(G(z)): 4383.0431 / 4382.8786 Elapsed 45.14 s\n",
      "In epoch =  18 real_label_smooth =  0.0\n",
      "epoch =  18\n",
      "[18/40] Loss_D: 1.1960 Loss_G: 10952.1608 D(x): 3695.7327 D(G(z)): 4124.8488 / 4123.3399 Elapsed 45.26 s\n",
      "In epoch =  19 real_label_smooth =  0.0\n",
      "epoch =  19\n",
      "[19/40] Loss_D: 0.5782 Loss_G: 10817.5292 D(x): 3426.6793 D(G(z)): 3930.1076 / 3930.3879 Elapsed 45.29 s\n",
      "In epoch =  20 real_label_smooth =  0.0\n",
      "epoch =  20\n",
      "[20/40] Loss_D: 3.1037 Loss_G: 11896.9145 D(x): 3645.5462 D(G(z)): 3933.6823 / 3934.0343 Elapsed 45.40 s\n",
      "In epoch =  21 real_label_smooth =  0.0\n",
      "epoch =  21\n",
      "[21/40] Loss_D: 1.1641 Loss_G: 11322.6903 D(x): 3890.8624 D(G(z)): 3393.1438 / 3394.1584 Elapsed 45.30 s\n",
      "In epoch =  22 real_label_smooth =  -0.0\n",
      "epoch =  22\n",
      "[22/40] Loss_D: 0.9091 Loss_G: 13019.7758 D(x): 4054.2085 D(G(z)): 3643.8713 / 3641.9910 Elapsed 45.19 s\n",
      "In epoch =  23 real_label_smooth =  0.0\n",
      "epoch =  23\n",
      "[23/40] Loss_D: 0.7420 Loss_G: 13677.8582 D(x): 3510.5228 D(G(z)): 3561.1047 / 3558.9888 Elapsed 45.48 s\n",
      "In epoch =  24 real_label_smooth =  -0.0\n",
      "epoch =  24\n",
      "[24/40] Loss_D: 0.3273 Loss_G: 12324.8078 D(x): 3107.8987 D(G(z)): 3634.8186 / 3636.0525 Elapsed 45.34 s\n",
      "In epoch =  25 real_label_smooth =  0.0\n",
      "epoch =  25\n",
      "[25/40] Loss_D: 7.8788 Loss_G: 12249.4808 D(x): 2807.7928 D(G(z)): 3835.9388 / 3829.0297 Elapsed 45.34 s\n",
      "In epoch =  26 real_label_smooth =  0\n",
      "epoch =  26\n",
      "[26/40] Loss_D: 0.9155 Loss_G: 10944.7702 D(x): 2696.4021 D(G(z)): 2436.4699 / 2434.5725 Elapsed 45.44 s\n",
      "In epoch =  27 real_label_smooth =  0\n",
      "epoch =  27\n",
      "[27/40] Loss_D: 0.2904 Loss_G: 10708.3078 D(x): 2598.2102 D(G(z)): 2173.0803 / 2171.0944 Elapsed 45.39 s\n",
      "In epoch =  28 real_label_smooth =  0\n",
      "epoch =  28\n",
      "[28/40] Loss_D: 0.2372 Loss_G: 11572.8801 D(x): 2272.9064 D(G(z)): 1873.4190 / 1872.6335 Elapsed 45.37 s\n",
      "In epoch =  29 real_label_smooth =  0\n",
      "epoch =  29\n",
      "[29/40] Loss_D: 1.7899 Loss_G: 13367.5097 D(x): 2395.2891 D(G(z)): 1966.7154 / 1964.4302 Elapsed 45.85 s\n",
      "In epoch =  30 real_label_smooth =  0\n",
      "epoch =  30\n",
      "[30/40] Loss_D: 7.0482 Loss_G: 13438.3271 D(x): 3146.9171 D(G(z)): 3007.5999 / 3008.4771 Elapsed 45.29 s\n",
      "In epoch =  31 real_label_smooth =  0\n",
      "epoch =  31\n",
      "[31/40] Loss_D: 0.6011 Loss_G: 11758.4781 D(x): 3531.7817 D(G(z)): 2909.4980 / 2907.8747 Elapsed 45.67 s\n",
      "In epoch =  32 real_label_smooth =  0\n",
      "epoch =  32\n",
      "[32/40] Loss_D: 0.1503 Loss_G: 11818.1101 D(x): 3196.0618 D(G(z)): 2730.8013 / 2729.7968 Elapsed 45.45 s\n",
      "In epoch =  33 real_label_smooth =  0\n",
      "epoch =  33\n",
      "[33/40] Loss_D: 0.1490 Loss_G: 12092.6208 D(x): 2767.3200 D(G(z)): 1939.8691 / 1938.5684 Elapsed 45.41 s\n",
      "In epoch =  34 real_label_smooth =  0\n",
      "epoch =  34\n",
      "[34/40] Loss_D: 0.1632 Loss_G: 12218.1587 D(x): 2897.4644 D(G(z)): 1685.8778 / 1686.0580 Elapsed 45.50 s\n",
      "In epoch =  35 real_label_smooth =  0\n",
      "epoch =  35\n",
      "[35/40] Loss_D: 4.3740 Loss_G: 12995.7917 D(x): 3242.8487 D(G(z)): 2563.2772 / 2562.9648 Elapsed 45.37 s\n",
      "In epoch =  36 real_label_smooth =  0\n",
      "epoch =  36\n",
      "[36/40] Loss_D: 1.0810 Loss_G: 11461.5736 D(x): 3764.2501 D(G(z)): 4259.6811 / 4254.3184 Elapsed 45.46 s\n",
      "In epoch =  37 real_label_smooth =  0\n",
      "epoch =  37\n",
      "[37/40] Loss_D: 3.7018 Loss_G: 13041.6470 D(x): 3302.5358 D(G(z)): 3732.9371 / 3733.2466 Elapsed 45.89 s\n",
      "In epoch =  38 real_label_smooth =  0\n",
      "epoch =  38\n",
      "[38/40] Loss_D: 0.7740 Loss_G: 12741.7503 D(x): 3133.4147 D(G(z)): 3607.6534 / 3602.9444 Elapsed 45.32 s\n",
      "In epoch =  39 real_label_smooth =  0\n",
      "epoch =  39\n",
      "[39/40] Loss_D: 0.4576 Loss_G: 13157.3612 D(x): 2841.9535 D(G(z)): 2881.4308 / 2881.3632 Elapsed 45.38 s\n"
     ]
    }
   ],
   "source": [
    "outputDir = 'outputdir_train_classifier_decay_0d025_label_0d15'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))\n",
    "num_epochs = 40\n",
    "real_labelSmooth = 0.15\n",
    "decay = 0.025\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth, decay = decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets train!\n",
      "In epoch =  0 real_label_smooth =  0.1\n",
      "epoch =  0\n",
      "[0/40] Loss_D: 507.7420 Loss_G: 3972.4226 D(x): 12859.3070 D(G(z)): 13087.5091 / 13103.0339 Elapsed 45.55 s\n",
      "In epoch =  1 real_label_smooth =  0.1\n",
      "epoch =  1\n",
      "[1/40] Loss_D: 29.4912 Loss_G: 4546.8625 D(x): 12531.2498 D(G(z)): 12373.2577 / 12368.0497 Elapsed 45.32 s\n",
      "In epoch =  2 real_label_smooth =  3.56755666949e-12\n",
      "epoch =  2\n",
      "[2/40] Loss_D: 2.5138 Loss_G: 5855.9885 D(x): 11256.2571 D(G(z)): 10987.5664 / 10984.3815 Elapsed 45.64 s\n",
      "In epoch =  3 real_label_smooth =  1.23625427814e-33\n",
      "epoch =  3\n",
      "[3/40] Loss_D: 1.2730 Loss_G: 6718.6383 D(x): 9944.6017 D(G(z)): 9359.6083 / 9356.5230 Elapsed 45.50 s\n",
      "In epoch =  4 real_label_smooth =  9.76301524616e-67\n",
      "epoch =  4\n",
      "[4/40] Loss_D: 0.4384 Loss_G: 7332.0316 D(x): 8878.8635 D(G(z)): 8392.9286 / 8390.6383 Elapsed 45.48 s\n",
      "In epoch =  5 real_label_smooth =  3.45770443308e-112\n",
      "epoch =  5\n",
      "[5/40] Loss_D: 0.2238 Loss_G: 7362.7106 D(x): 7910.5741 D(G(z)): 8187.9386 / 8185.6142 Elapsed 45.41 s\n",
      "In epoch =  6 real_label_smooth =  8.76032861174e-171\n",
      "epoch =  6\n",
      "[6/40] Loss_D: 0.1717 Loss_G: 6768.6237 D(x): 6918.8583 D(G(z)): 10789.2763 / 10786.5369 Elapsed 45.46 s\n",
      "In epoch =  7 real_label_smooth =  1.96562724946e-243\n",
      "epoch =  7\n",
      "[7/40] Loss_D: 0.1288 Loss_G: 7153.0117 D(x): 6146.9288 D(G(z)): 7900.1802 / 7898.0891 Elapsed 45.38 s\n",
      "In epoch =  8 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  8\n",
      "[8/40] Loss_D: 0.0383 Loss_G: 7412.0204 D(x): 5553.5211 D(G(z)): 8053.1009 / 8052.2043 Elapsed 45.51 s\n",
      "In epoch =  9 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  9\n",
      "[9/40] Loss_D: 0.0190 Loss_G: 7786.7391 D(x): 5249.4077 D(G(z)): 7852.8976 / 7852.4126 Elapsed 45.55 s\n",
      "In epoch =  10 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  10\n",
      "[10/40] Loss_D: 0.0126 Loss_G: 8166.9141 D(x): 5001.9581 D(G(z)): 7552.6070 / 7552.2312 Elapsed 45.57 s\n",
      "In epoch =  11 real_label_smooth =  0.0\n",
      "epoch =  11\n",
      "[11/40] Loss_D: 0.0082 Loss_G: 8417.1343 D(x): 4834.8662 D(G(z)): 7121.3239 / 7121.0072 Elapsed 45.54 s\n",
      "In epoch =  12 real_label_smooth =  0.0\n",
      "epoch =  12\n",
      "[12/40] Loss_D: 0.0073 Loss_G: 8647.3055 D(x): 4730.4326 D(G(z)): 6744.6923 / 6744.2981 Elapsed 45.50 s\n",
      "In epoch =  13 real_label_smooth =  0.0\n",
      "epoch =  13\n",
      "[13/40] Loss_D: 0.0061 Loss_G: 8939.6018 D(x): 4484.6854 D(G(z)): 6588.6121 / 6588.2526 Elapsed 45.51 s\n",
      "In epoch =  14 real_label_smooth =  0.0\n",
      "epoch =  14\n",
      "[14/40] Loss_D: 0.0046 Loss_G: 9210.1911 D(x): 4308.9089 D(G(z)): 5994.0237 / 5993.7602 Elapsed 45.74 s\n",
      "In epoch =  15 real_label_smooth =  0.0\n",
      "epoch =  15\n",
      "[15/40] Loss_D: 0.0035 Loss_G: 9343.4210 D(x): 4193.5196 D(G(z)): 5459.9632 / 5459.6820 Elapsed 45.47 s\n",
      "In epoch =  16 real_label_smooth =  0.0\n",
      "epoch =  16\n",
      "[16/40] Loss_D: 0.0027 Loss_G: 9470.8748 D(x): 4062.3244 D(G(z)): 4730.4519 / 4730.1032 Elapsed 45.58 s\n",
      "In epoch =  17 real_label_smooth =  0.0\n",
      "epoch =  17\n",
      "[17/40] Loss_D: 0.0024 Loss_G: 9586.8124 D(x): 3863.3540 D(G(z)): 3997.3724 / 3996.9429 Elapsed 45.78 s\n",
      "In epoch =  18 real_label_smooth =  0.0\n",
      "epoch =  18\n",
      "[18/40] Loss_D: 0.0024 Loss_G: 9843.3214 D(x): 3618.7771 D(G(z)): 3477.1776 / 3476.3960 Elapsed 45.56 s\n",
      "In epoch =  19 real_label_smooth =  0.0\n",
      "epoch =  19\n",
      "[19/40] Loss_D: 25.5670 Loss_G: 9318.8254 D(x): 5232.3502 D(G(z)): 4235.3974 / 4241.9365 Elapsed 45.67 s\n",
      "In epoch =  20 real_label_smooth =  0.0\n",
      "epoch =  20\n",
      "[20/40] Loss_D: 1.9183 Loss_G: 7817.7936 D(x): 8116.5756 D(G(z)): 7083.4992 / 7078.5090 Elapsed 45.51 s\n",
      "In epoch =  21 real_label_smooth =  0.0\n",
      "epoch =  21\n",
      "[21/40] Loss_D: 1.0313 Loss_G: 8667.0793 D(x): 7270.2038 D(G(z)): 7356.0808 / 7353.7278 Elapsed 45.52 s\n",
      "In epoch =  22 real_label_smooth =  -0.0\n",
      "epoch =  22\n",
      "[22/40] Loss_D: 0.5113 Loss_G: 8978.8401 D(x): 6934.6063 D(G(z)): 6640.9386 / 6639.9873 Elapsed 45.61 s\n",
      "In epoch =  23 real_label_smooth =  0.0\n",
      "epoch =  23\n",
      "[23/40] Loss_D: 0.6329 Loss_G: 9993.9813 D(x): 6221.3130 D(G(z)): 6294.0320 / 6292.7435 Elapsed 45.57 s\n",
      "In epoch =  24 real_label_smooth =  -0.0\n",
      "epoch =  24\n",
      "[24/40] Loss_D: 9.7337 Loss_G: 10624.4083 D(x): 5454.3523 D(G(z)): 6443.4388 / 6442.2727 Elapsed 45.53 s\n",
      "In epoch =  25 real_label_smooth =  0.0\n",
      "epoch =  25\n",
      "[25/40] Loss_D: 0.8711 Loss_G: 11016.2885 D(x): 5523.8466 D(G(z)): 5794.5978 / 5794.0234 Elapsed 45.57 s\n",
      "In epoch =  26 real_label_smooth =  0\n",
      "epoch =  26\n",
      "[26/40] Loss_D: 0.2909 Loss_G: 10887.2591 D(x): 5365.9474 D(G(z)): 5759.4735 / 5759.0244 Elapsed 45.52 s\n",
      "In epoch =  27 real_label_smooth =  0\n",
      "epoch =  27\n",
      "[27/40] Loss_D: 0.1289 Loss_G: 10472.1197 D(x): 5109.0045 D(G(z)): 5357.5993 / 5357.4263 Elapsed 45.55 s\n",
      "In epoch =  28 real_label_smooth =  0\n",
      "epoch =  28\n",
      "[28/40] Loss_D: 0.3133 Loss_G: 10335.2236 D(x): 4846.4574 D(G(z)): 5031.6335 / 5031.1493 Elapsed 45.57 s\n",
      "In epoch =  29 real_label_smooth =  0\n",
      "epoch =  29\n",
      "[29/40] Loss_D: 0.0830 Loss_G: 11400.2042 D(x): 4845.2803 D(G(z)): 4695.3150 / 4694.7399 Elapsed 45.57 s\n",
      "In epoch =  30 real_label_smooth =  0\n",
      "epoch =  30\n",
      "[30/40] Loss_D: 0.1375 Loss_G: 11476.2219 D(x): 4316.8040 D(G(z)): 4207.6081 / 4206.9526 Elapsed 45.54 s\n",
      "In epoch =  31 real_label_smooth =  0\n",
      "epoch =  31\n",
      "[31/40] Loss_D: 1.0359 Loss_G: 11871.1981 D(x): 4195.3595 D(G(z)): 4292.3107 / 4292.2705 Elapsed 45.61 s\n",
      "In epoch =  32 real_label_smooth =  0\n",
      "epoch =  32\n",
      "[32/40] Loss_D: 2.8832 Loss_G: 12558.6388 D(x): 4158.9545 D(G(z)): 4246.2021 / 4250.0172 Elapsed 45.61 s\n",
      "In epoch =  33 real_label_smooth =  0\n",
      "epoch =  33\n",
      "[33/40] Loss_D: 1.0475 Loss_G: 11556.1651 D(x): 4633.5344 D(G(z)): 5123.8061 / 5119.8591 Elapsed 45.46 s\n",
      "In epoch =  34 real_label_smooth =  0\n",
      "epoch =  34\n",
      "[34/40] Loss_D: 0.5310 Loss_G: 12757.9666 D(x): 3484.5553 D(G(z)): 3878.5210 / 3877.5560 Elapsed 45.56 s\n",
      "In epoch =  35 real_label_smooth =  0\n",
      "epoch =  35\n",
      "[35/40] Loss_D: 1.0529 Loss_G: 13409.6952 D(x): 3808.9945 D(G(z)): 3833.8244 / 3837.0007 Elapsed 45.68 s\n",
      "In epoch =  36 real_label_smooth =  0\n",
      "epoch =  36\n",
      "[36/40] Loss_D: 1.6653 Loss_G: 13028.0697 D(x): 4140.7612 D(G(z)): 3759.9199 / 3757.4089 Elapsed 45.87 s\n",
      "In epoch =  37 real_label_smooth =  0\n",
      "epoch =  37\n",
      "[37/40] Loss_D: 1.4121 Loss_G: 12570.4700 D(x): 4082.8945 D(G(z)): 4471.5641 / 4473.3902 Elapsed 45.46 s\n",
      "In epoch =  38 real_label_smooth =  0\n",
      "epoch =  38\n",
      "[38/40] Loss_D: 0.6421 Loss_G: 12872.9779 D(x): 3931.6219 D(G(z)): 4144.9456 / 4144.3303 Elapsed 45.89 s\n",
      "In epoch =  39 real_label_smooth =  0\n",
      "epoch =  39\n",
      "[39/40] Loss_D: 2.4832 Loss_G: 13211.3382 D(x): 3802.8840 D(G(z)): 4403.1476 / 4404.0681 Elapsed 45.60 s\n"
     ]
    }
   ],
   "source": [
    "outputDir = 'outputdir_train_classifier_decay_0d025_label_0d10'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))\n",
    "num_epochs = 40\n",
    "real_labelSmooth = 0.10\n",
    "decay = 0.025\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth, decay = decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets train!\n",
      "In epoch =  0 real_label_smooth =  0.1\n",
      "epoch =  0\n",
      "[0/40] Loss_D: 375.8008 Loss_G: 4548.2325 D(x): 12897.6643 D(G(z)): 13016.5312 / 13031.5164 Elapsed 43.58 s\n",
      "In epoch =  1 real_label_smooth =  0.1\n",
      "epoch =  1\n",
      "[1/40] Loss_D: 17.1547 Loss_G: 4886.9106 D(x): 12959.3268 D(G(z)): 12558.4153 / 12555.0399 Elapsed 43.77 s\n",
      "In epoch =  2 real_label_smooth =  3.56755666949e-12\n",
      "epoch =  2\n",
      "[2/40] Loss_D: 1.9574 Loss_G: 5766.4303 D(x): 12290.9605 D(G(z)): 12137.2978 / 12135.5654 Elapsed 43.93 s\n",
      "In epoch =  3 real_label_smooth =  1.23625427814e-33\n",
      "epoch =  3\n",
      "[3/40] Loss_D: 1.0432 Loss_G: 6312.5672 D(x): 11584.6274 D(G(z)): 11173.1914 / 11171.2680 Elapsed 44.29 s\n",
      "In epoch =  4 real_label_smooth =  9.76301524616e-67\n",
      "epoch =  4\n",
      "[4/40] Loss_D: 0.7644 Loss_G: 6926.1553 D(x): 10837.1461 D(G(z)): 10399.9942 / 10398.4188 Elapsed 44.67 s\n",
      "In epoch =  5 real_label_smooth =  3.45770443308e-112\n",
      "epoch =  5\n",
      "[5/40] Loss_D: 0.4421 Loss_G: 7380.4011 D(x): 10066.3445 D(G(z)): 9456.5590 / 9454.4426 Elapsed 44.94 s\n",
      "In epoch =  6 real_label_smooth =  8.76032861174e-171\n",
      "epoch =  6\n",
      "[6/40] Loss_D: 0.2256 Loss_G: 8004.2546 D(x): 9281.5595 D(G(z)): 9142.2048 / 9140.4761 Elapsed 44.91 s\n",
      "In epoch =  7 real_label_smooth =  1.96562724946e-243\n",
      "epoch =  7\n",
      "[7/40] Loss_D: 0.1378 Loss_G: 8383.3335 D(x): 8583.8106 D(G(z)): 8701.1857 / 8699.5143 Elapsed 44.93 s\n",
      "In epoch =  8 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  8\n",
      "[8/40] Loss_D: 7.1618 Loss_G: 8812.6176 D(x): 5437.3718 D(G(z)): 7294.8485 / 7280.5466 Elapsed 44.99 s\n",
      "In epoch =  9 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  9\n",
      "[9/40] Loss_D: 0.5562 Loss_G: 9162.3033 D(x): 4194.4932 D(G(z)): 6916.5140 / 6916.4186 Elapsed 45.32 s\n",
      "In epoch =  10 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  10\n",
      "[10/40] Loss_D: 0.7798 Loss_G: 10593.9871 D(x): 4063.2874 D(G(z)): 4311.0965 / 4311.6954 Elapsed 45.18 s\n",
      "In epoch =  11 real_label_smooth =  0.0\n",
      "epoch =  11\n",
      "[11/40] Loss_D: 0.5795 Loss_G: 10994.4529 D(x): 4522.9403 D(G(z)): 5221.7510 / 5221.7747 Elapsed 45.13 s\n",
      "In epoch =  12 real_label_smooth =  0.0\n",
      "epoch =  12\n",
      "[12/40] Loss_D: 3.9287 Loss_G: 10639.6243 D(x): 4497.1727 D(G(z)): 4589.2343 / 4588.3437 Elapsed 45.19 s\n",
      "In epoch =  13 real_label_smooth =  0.0\n",
      "epoch =  13\n",
      "[13/40] Loss_D: 0.8913 Loss_G: 10542.4176 D(x): 4858.2325 D(G(z)): 4445.4142 / 4444.3644 Elapsed 45.30 s\n",
      "In epoch =  14 real_label_smooth =  0.0\n",
      "epoch =  14\n",
      "[14/40] Loss_D: 0.3586 Loss_G: 10812.0341 D(x): 4714.3478 D(G(z)): 4975.1438 / 4974.3649 Elapsed 45.35 s\n",
      "In epoch =  15 real_label_smooth =  0.0\n",
      "epoch =  15\n",
      "[15/40] Loss_D: 1.5187 Loss_G: 11104.1754 D(x): 4493.9976 D(G(z)): 4839.7263 / 4838.8740 Elapsed 45.24 s\n",
      "In epoch =  16 real_label_smooth =  0.0\n",
      "epoch =  16\n",
      "[16/40] Loss_D: 0.7064 Loss_G: 11811.3725 D(x): 4311.5857 D(G(z)): 4553.8721 / 4553.2861 Elapsed 45.40 s\n",
      "In epoch =  17 real_label_smooth =  0.0\n",
      "epoch =  17\n",
      "[17/40] Loss_D: 0.2467 Loss_G: 12002.0435 D(x): 4004.5888 D(G(z)): 4012.0076 / 4010.2252 Elapsed 45.30 s\n",
      "In epoch =  18 real_label_smooth =  0.0\n",
      "epoch =  18\n",
      "[18/40] Loss_D: 6.0378 Loss_G: 12102.1973 D(x): 5031.4269 D(G(z)): 5230.8043 / 5236.7251 Elapsed 45.24 s\n",
      "In epoch =  19 real_label_smooth =  0.0\n",
      "epoch =  19\n",
      "[19/40] Loss_D: 2.6235 Loss_G: 11528.0135 D(x): 5307.4086 D(G(z)): 5344.3516 / 5340.0809 Elapsed 45.31 s\n",
      "In epoch =  20 real_label_smooth =  0.0\n",
      "epoch =  20\n",
      "[20/40] Loss_D: 0.5960 Loss_G: 11476.3868 D(x): 3829.5233 D(G(z)): 4208.4917 / 4207.1059 Elapsed 45.36 s\n",
      "In epoch =  21 real_label_smooth =  0.0\n",
      "epoch =  21\n",
      "[21/40] Loss_D: 0.3657 Loss_G: 11823.0850 D(x): 3444.1542 D(G(z)): 3206.1709 / 3205.0285 Elapsed 45.43 s\n",
      "In epoch =  22 real_label_smooth =  -0.0\n",
      "epoch =  22\n",
      "[22/40] Loss_D: 0.3283 Loss_G: 11820.5030 D(x): 3792.4894 D(G(z)): 2924.6316 / 2923.1699 Elapsed 45.39 s\n",
      "In epoch =  23 real_label_smooth =  0.0\n",
      "epoch =  23\n",
      "[23/40] Loss_D: 0.1134 Loss_G: 12142.2292 D(x): 3178.5685 D(G(z)): 2310.5680 / 2309.3029 Elapsed 45.50 s\n",
      "In epoch =  24 real_label_smooth =  -0.0\n",
      "epoch =  24\n",
      "[24/40] Loss_D: 1.9651 Loss_G: 11385.6158 D(x): 3565.6213 D(G(z)): 3674.2127 / 3672.6146 Elapsed 45.52 s\n",
      "In epoch =  25 real_label_smooth =  0.0\n",
      "epoch =  25\n",
      "[25/40] Loss_D: 0.2907 Loss_G: 11639.5047 D(x): 3389.4557 D(G(z)): 3967.8692 / 3968.8780 Elapsed 45.47 s\n",
      "In epoch =  26 real_label_smooth =  0\n",
      "epoch =  26\n",
      "[26/40] Loss_D: 0.3859 Loss_G: 11688.3304 D(x): 3953.3962 D(G(z)): 4109.9102 / 4110.1471 Elapsed 45.47 s\n",
      "In epoch =  27 real_label_smooth =  0\n",
      "epoch =  27\n",
      "[27/40] Loss_D: 0.2127 Loss_G: 12101.0789 D(x): 3473.9471 D(G(z)): 3866.3738 / 3866.4022 Elapsed 45.54 s\n",
      "In epoch =  28 real_label_smooth =  0\n",
      "epoch =  28\n",
      "[28/40] Loss_D: 3.7575 Loss_G: 12506.0647 D(x): 4708.4222 D(G(z)): 4390.3505 / 4388.1472 Elapsed 45.46 s\n",
      "In epoch =  29 real_label_smooth =  0\n",
      "epoch =  29\n",
      "[29/40] Loss_D: 1.6455 Loss_G: 13109.7191 D(x): 3708.9156 D(G(z)): 3907.5252 / 3905.7278 Elapsed 45.43 s\n",
      "In epoch =  30 real_label_smooth =  0\n",
      "epoch =  30\n",
      "[30/40] Loss_D: 0.5080 Loss_G: 13303.6339 D(x): 3516.0181 D(G(z)): 3947.3624 / 3945.5936 Elapsed 45.46 s\n",
      "In epoch =  31 real_label_smooth =  0\n",
      "epoch =  31\n",
      "[31/40] Loss_D: 0.3195 Loss_G: 13882.2068 D(x): 3378.0934 D(G(z)): 3780.2696 / 3778.9352 Elapsed 45.51 s\n",
      "In epoch =  32 real_label_smooth =  0\n",
      "epoch =  32\n",
      "[32/40] Loss_D: 0.5841 Loss_G: 14235.7087 D(x): 2984.3365 D(G(z)): 3537.1537 / 3536.4916 Elapsed 45.46 s\n",
      "In epoch =  33 real_label_smooth =  0\n"
     ]
    }
   ],
   "source": [
    "outputDir = 'outputdir_train_classifier_decay_0d018_label_0d10'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))\n",
    "num_epochs = 40\n",
    "real_labelSmooth = 0.10\n",
    "decay = 0.018\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth, decay = decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS error: [Errno 17] File exists: 'outputdir_train_classifier_decay_0d025_label_0d15'\n",
      "Lets train!\n",
      "In epoch =  0 real_label_smooth =  0.1\n",
      "epoch =  0\n",
      "[0/40] Loss_D: 586.5647 Loss_G: 3512.8855 D(x): -310.1243 D(G(z)): -371.3154 / -378.8754 Elapsed 43.00 s\n",
      "In epoch =  1 real_label_smooth =  0.1\n",
      "epoch =  1\n",
      "[1/40] Loss_D: 196.4603 Loss_G: 3993.8315 D(x): -532.8350 D(G(z)): -568.7550 / -571.3881 Elapsed 43.42 s\n",
      "In epoch =  2 real_label_smooth =  3.56755666949e-12\n",
      "epoch =  2\n",
      "[2/40] Loss_D: 122.9132 Loss_G: 4885.0473 D(x): -727.9536 D(G(z)): -771.0179 / -773.6365 Elapsed 43.39 s\n",
      "In epoch =  3 real_label_smooth =  1.23625427814e-33\n",
      "epoch =  3\n",
      "[3/40] Loss_D: 136.9712 Loss_G: 5337.2350 D(x): -916.5261 D(G(z)): -954.3983 / -956.4158 Elapsed 43.60 s\n",
      "In epoch =  4 real_label_smooth =  9.76301524616e-67\n",
      "epoch =  4\n",
      "[4/40] Loss_D: 110.3570 Loss_G: 5728.3650 D(x): -1082.2183 D(G(z)): -1130.1459 / -1134.7157 Elapsed 43.90 s\n",
      "In epoch =  5 real_label_smooth =  3.45770443308e-112\n",
      "epoch =  5\n",
      "[5/40] Loss_D: 125.1698 Loss_G: 5939.2131 D(x): -1201.8153 D(G(z)): -1259.9647 / -1265.2543 Elapsed 44.31 s\n",
      "In epoch =  6 real_label_smooth =  8.76032861174e-171\n",
      "epoch =  6\n",
      "[6/40] Loss_D: 88.2714 Loss_G: 6069.2053 D(x): -1347.3498 D(G(z)): -1412.6525 / -1416.9608 Elapsed 44.36 s\n",
      "In epoch =  7 real_label_smooth =  1.96562724946e-243\n",
      "epoch =  7\n",
      "[7/40] Loss_D: 134.5120 Loss_G: 6146.0638 D(x): -1361.2984 D(G(z)): -1422.9833 / -1428.3857 Elapsed 44.32 s\n",
      "In epoch =  8 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  8\n",
      "[8/40] Loss_D: 58.8408 Loss_G: 6601.6934 D(x): -1585.1063 D(G(z)): -1650.3402 / -1654.9950 Elapsed 44.43 s\n",
      "In epoch =  9 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  9\n",
      "[9/40] Loss_D: 106.2382 Loss_G: 6522.3033 D(x): -1591.7478 D(G(z)): -1661.2633 / -1665.8443 Elapsed 44.67 s\n",
      "In epoch =  10 real_label_smooth =  4.94065645841e-324\n",
      "epoch =  10\n",
      "[10/40] Loss_D: 90.8814 Loss_G: 6755.5909 D(x): -1746.1074 D(G(z)): -1815.6877 / -1821.0005 Elapsed 44.60 s\n",
      "In epoch =  11 real_label_smooth =  0.0\n",
      "epoch =  11\n",
      "[11/40] Loss_D: 71.1060 Loss_G: 6888.0696 D(x): -1831.8904 D(G(z)): -1926.3329 / -1931.7492 Elapsed 44.62 s\n",
      "In epoch =  12 real_label_smooth =  0.0\n",
      "epoch =  12\n",
      "[12/40] Loss_D: 98.7374 Loss_G: 6941.4959 D(x): -1940.4657 D(G(z)): -2018.1844 / -2024.4132 Elapsed 44.62 s\n",
      "In epoch =  13 real_label_smooth =  0.0\n",
      "epoch =  13\n",
      "[13/40] Loss_D: 54.5306 Loss_G: 7238.2937 D(x): -2045.0891 D(G(z)): -2160.4550 / -2166.9153 Elapsed 44.62 s\n",
      "In epoch =  14 real_label_smooth =  0.0\n",
      "epoch =  14\n",
      "[14/40] Loss_D: 88.9819 Loss_G: 7261.9799 D(x): -2103.6304 D(G(z)): -2206.1246 / -2211.6366 Elapsed 44.68 s\n",
      "In epoch =  15 real_label_smooth =  0.0\n",
      "epoch =  15\n",
      "[15/40] Loss_D: 78.0146 Loss_G: 7398.3988 D(x): -2205.5006 D(G(z)): -2302.4281 / -2310.2450 Elapsed 44.83 s\n",
      "In epoch =  16 real_label_smooth =  0.0\n",
      "epoch =  16\n",
      "[16/40] Loss_D: 80.5392 Loss_G: 7293.4562 D(x): -2366.2820 D(G(z)): -2447.3179 / -2453.3268 Elapsed 44.74 s\n",
      "In epoch =  17 real_label_smooth =  0.0\n",
      "epoch =  17\n",
      "[17/40] Loss_D: 112.7932 Loss_G: 7167.4797 D(x): -2221.7665 D(G(z)): -2278.1868 / -2282.0542 Elapsed 44.84 s\n",
      "In epoch =  18 real_label_smooth =  0.0\n",
      "epoch =  18\n",
      "[18/40] Loss_D: 63.5520 Loss_G: 7628.9634 D(x): -2411.5054 D(G(z)): -2506.4592 / -2511.8397 Elapsed 44.78 s\n",
      "In epoch =  19 real_label_smooth =  0.0\n",
      "epoch =  19\n",
      "[19/40] Loss_D: 11.7605 Loss_G: 8141.1083 D(x): -2483.2361 D(G(z)): -2707.5737 / -2713.3972 Elapsed 44.45 s\n",
      "In epoch =  20 real_label_smooth =  0.0\n",
      "epoch =  20\n",
      "[20/40] Loss_D: 98.0910 Loss_G: 7715.5528 D(x): -2366.8724 D(G(z)): -2493.5619 / -2500.1436 Elapsed 44.44 s\n",
      "In epoch =  21 real_label_smooth =  0.0\n",
      "epoch =  21\n",
      "[21/40] Loss_D: 51.7218 Loss_G: 8095.5319 D(x): -2473.8166 D(G(z)): -2640.3429 / -2649.2039 Elapsed 44.52 s\n",
      "In epoch =  22 real_label_smooth =  -0.0\n",
      "epoch =  22\n",
      "[22/40] Loss_D: 47.3724 Loss_G: 8286.2910 D(x): -2480.5654 D(G(z)): -2699.2214 / -2707.3296 Elapsed 44.52 s\n",
      "In epoch =  23 real_label_smooth =  0.0\n",
      "epoch =  23\n",
      "[23/40] Loss_D: 86.5371 Loss_G: 8041.9487 D(x): -2464.4796 D(G(z)): -2595.3120 / -2603.5816 Elapsed 44.44 s\n",
      "In epoch =  24 real_label_smooth =  -0.0\n",
      "epoch =  24\n",
      "[24/40] Loss_D: 54.4918 Loss_G: 8476.5735 D(x): -2505.9001 D(G(z)): -2756.4145 / -2763.5715 Elapsed 44.55 s\n",
      "In epoch =  25 real_label_smooth =  0.0\n",
      "epoch =  25\n",
      "[25/40] Loss_D: 69.6606 Loss_G: 7932.9789 D(x): -2563.5455 D(G(z)): -2653.7819 / -2661.4029 Elapsed 44.39 s\n",
      "In epoch =  26 real_label_smooth =  0\n",
      "epoch =  26\n",
      "[26/40] Loss_D: 53.4361 Loss_G: 8262.2774 D(x): -2604.7687 D(G(z)): -2792.9614 / -2801.6330 Elapsed 44.52 s\n",
      "In epoch =  27 real_label_smooth =  0\n",
      "epoch =  27\n",
      "[27/40] Loss_D: 59.4613 Loss_G: 8523.4715 D(x): -2567.4582 D(G(z)): -2808.3933 / -2815.9950 Elapsed 44.23 s\n",
      "In epoch =  28 real_label_smooth =  0\n",
      "epoch =  28\n",
      "[28/40] Loss_D: 52.6690 Loss_G: 8245.3193 D(x): -2657.2409 D(G(z)): -2791.2481 / -2799.1038 Elapsed 44.49 s\n",
      "In epoch =  29 real_label_smooth =  0\n",
      "epoch =  29\n",
      "[29/40] Loss_D: 46.1137 Loss_G: 8582.1128 D(x): -2703.8978 D(G(z)): -2915.8334 / -2926.6102 Elapsed 44.33 s\n",
      "In epoch =  30 real_label_smooth =  0\n",
      "epoch =  30\n",
      "[30/40] Loss_D: 43.0683 Loss_G: 9064.7502 D(x): -2699.5661 D(G(z)): -3052.2786 / -3059.9604 Elapsed 44.35 s\n",
      "In epoch =  31 real_label_smooth =  0\n",
      "epoch =  31\n",
      "[31/40] Loss_D: 73.1661 Loss_G: 8412.3502 D(x): -2734.6109 D(G(z)): -2902.1495 / -2912.0228 Elapsed 44.38 s\n",
      "In epoch =  32 real_label_smooth =  0\n",
      "epoch =  32\n",
      "[32/40] Loss_D: 58.0667 Loss_G: 8390.7779 D(x): -2820.6913 D(G(z)): -2958.2698 / -2967.4186 Elapsed 44.43 s\n",
      "In epoch =  33 real_label_smooth =  0\n",
      "epoch =  33\n",
      "[33/40] Loss_D: 52.3438 Loss_G: 8532.0152 D(x): -2856.9064 D(G(z)): -3041.3936 / -3049.1116 Elapsed 44.32 s\n",
      "In epoch =  34 real_label_smooth =  0\n",
      "epoch =  34\n",
      "[34/40] Loss_D: 48.7890 Loss_G: 8999.5040 D(x): -2858.1172 D(G(z)): -3180.1483 / -3189.2696 Elapsed 44.46 s\n",
      "In epoch =  35 real_label_smooth =  0\n",
      "epoch =  35\n",
      "[35/40] Loss_D: 47.8028 Loss_G: 8451.5377 D(x): -2856.7254 D(G(z)): -2964.1074 / -2971.6349 Elapsed 44.42 s\n",
      "In epoch =  36 real_label_smooth =  0\n",
      "epoch =  36\n",
      "[36/40] Loss_D: 38.9229 Loss_G: 9084.2285 D(x): -2911.9512 D(G(z)): -3184.1425 / -3192.6870 Elapsed 44.52 s\n",
      "In epoch =  37 real_label_smooth =  0\n",
      "epoch =  37\n",
      "[37/40] Loss_D: 45.8599 Loss_G: 8969.0476 D(x): -2960.4210 D(G(z)): -3173.6342 / -3184.0662 Elapsed 44.42 s\n",
      "In epoch =  38 real_label_smooth =  0\n",
      "epoch =  38\n",
      "[38/40] Loss_D: 30.4739 Loss_G: 9241.8185 D(x): -2932.1631 D(G(z)): -3234.0255 / -3241.9304 Elapsed 44.58 s\n",
      "In epoch =  39 real_label_smooth =  0\n"
     ]
    }
   ],
   "source": [
    "outputDir = 'outputdir_train_classifier_decay_0d025_label_0d15'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))\n",
    "num_epochs = 40\n",
    "real_labelSmooth = 0.10\n",
    "decay = 0.018\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth, decay = decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
