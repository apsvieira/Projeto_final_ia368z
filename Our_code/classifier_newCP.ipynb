{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "import gc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch as tc\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#get_ipython().magic('matplotlib inline')\n",
    "from PIL import Image\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System properties and libs currently in use\n",
    "- We have developed using python 3.5.x, pytorch 0.2.1\n",
    "- No significant attention was given to backwards compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__Python VERSION: 3.5.4 |Continuum Analytics, Inc.| (default, Aug 14 2017, 13:41:13) [MSC v.1900 64 bit (AMD64)]\n",
      "__pyTorch VERSION: 0.2.1+a4fc05a\n",
      "__CUDA VERSION\n",
      "__CUDNN VERSION: None\n",
      "__Number CUDA Devices: 1\n",
      "__Devices\n",
      "Active CUDA Device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "#from subprocess import call\n",
    "#call([\"nvcc\", \"--version\"])\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "#call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
    "print('Active CUDA Device: GPU', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities\n",
    "- Saving images and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_images(netG, noise, outputDir,epoch):\n",
    "   # the first 64 samples from the mini-batch are saved.\n",
    "   fake,_ = netG(fixed_noise)\n",
    "   vutils.save_image(fake.data[0:64,:,:,:],'%s/fake_samples_epoch_%03d.png' % (outputDir, epoch), nrow=8)\n",
    "\n",
    "def save_models(netG, netD, outputDir, epoch):\n",
    "   torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (outputDir, epoch))\n",
    "   torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (outputDir, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using CUDA. If it is not what you want, manually set this as False!\n"
     ]
    }
   ],
   "source": [
    "cudnn.benchmark = True\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "#use_gpu = False\n",
    "if use_gpu:\n",
    "    print(\"You are using CUDA. If it is not what you want, manually set this as False!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Directory\n",
    "- This is where images will be saved to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS error: [WinError 183] Não é possível criar um arquivo já existente: 'outputdir_train_classifier'\n"
     ]
    }
   ],
   "source": [
    "outputDir = 'outputdir_train_classifier'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset definition and hyperparameter setting\n",
    "- Changing dataset name alters network architecture parameters\n",
    "- Currently supporting few datasets\n",
    "- Hyperparameters defined according to Radford et al. (2015)\n",
    "\n",
    "Valores típicos são\n",
    "\n",
    "nc = 3,\n",
    "ngpu = 1,\n",
    "nz = 100,\n",
    "ngf = 64,\n",
    "ndf = 64,\n",
    "n_extra_d = 0,\n",
    "n_extra_g = 1,\n",
    "imageSize = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "\n",
    "# This should, in the future, be set in CLI\n",
    "chosen_dataset = 'CIFAR10'\n",
    "\n",
    "datasets = {\n",
    "    'MNIST': torchvision.datasets.MNIST,\n",
    "    'CIFAR10': torchvision.datasets.CIFAR10,\n",
    "    'ANIME': '/home/gabriel/Redes Neurais/Projeto_Final_GANS/Tutorial_2/dataset/min_anime-faces',\n",
    "}\n",
    "\n",
    "dataset = datasets[chosen_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "possible_parameters = {\n",
    "    'MNIST': {\n",
    "        'ndf': 64,\n",
    "        'ngf': 64,\n",
    "        'nz': 50,\n",
    "        'nc': 1,\n",
    "        'n_classes' : 10,\n",
    "    },\n",
    "    'CIFAR10': {\n",
    "        'ndf': 64,\n",
    "        'ngf': 64,\n",
    "        'nz': 100,\n",
    "        'nc': 3,\n",
    "        'n_extra_d' : 0,\n",
    "        'n_extra_g' : 0, # Aqui a jogada é que o gerador deve ser mais poderoso q o detetive\n",
    "        'imageSize' : 32,\n",
    "        'n_classes' : 10,\n",
    "        'ngpu' : 1,\n",
    "    },\n",
    "    'ANIME': {\n",
    "        'nc' : 3,\n",
    "        'ngpu' : 1,\n",
    "        'nz' : 100,\n",
    "        'ngf' : 64,\n",
    "        'ndf' : 64,\n",
    "        'n_extra_d' : 0,\n",
    "        'n_extra_g' : 0, # Aqui a jogada é que o gerador deve ser mais poderoso q o detetive\n",
    "        'imageSize' : 64,\n",
    "        'n_classes' : 1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngf = possible_parameters[chosen_dataset]['ngf']\n",
    "ndf = possible_parameters[chosen_dataset]['ndf']\n",
    "nz = possible_parameters[chosen_dataset]['nz']\n",
    "nc = possible_parameters[chosen_dataset]['nc']\n",
    "imageSize = possible_parameters[chosen_dataset]['imageSize']\n",
    "n_classes = possible_parameters[chosen_dataset]['n_classes']\n",
    "ngpu = possible_parameters[chosen_dataset]['ngpu']\n",
    "n_extra_d = possible_parameters[chosen_dataset]['n_extra_d']\n",
    "n_extra_g = possible_parameters[chosen_dataset]['n_extra_g']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "if dataset == 'ANIME':\n",
    "    dataset = dset.ImageFolder(\n",
    "        root='/home/gabriel/Redes Neurais/Projeto_Final_GANS/Tutorial_2/dataset/min_anime-faces',\n",
    "        transform=transforms.Compose([\n",
    "                transforms.Scale((imageSize, imageSize)),\n",
    "                # transforms.CenterCrop(opt.imageSize),\n",
    "                transforms.ToTensor(),\n",
    "                #transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)), # bring images to (-1,1)\n",
    "            ])\n",
    "    )\n",
    "else:\n",
    "    transform = transforms.Compose([\n",
    "                    transforms.Scale((imageSize, imageSize)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)), # bring images to (-1,1)\n",
    "                ]) \n",
    "    dataset_done = dataset('./datasets', train=True, download=True, transform=transform)\n",
    "    dataloader = tc.utils.data.DataLoader(dataset_done, batch_size=batch_size, shuffle=True, num_workers=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição dos modelos\n",
    "- Model is a DCGAN\n",
    "- Images are sized (nc, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netD_1(nn.Module):\n",
    "    def __init__(self, ngpu, nz, nc, ndf,  n_extra_layers_d, n_classes):\n",
    "        super(_netD_1, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.conv1 = nn.Conv2d(in_channels = nc, out_channels = ndf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(in_channels = ndf, out_channels = ndf*2, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch2 = nn.BatchNorm2d(ndf * 2)\n",
    "        self.conv3 = nn.Conv2d(in_channels = ndf*2, out_channels = ndf*4, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch3 = nn.BatchNorm2d(ndf * 4)\n",
    "        self.conv4 = nn.Conv2d(in_channels = ndf*4, out_channels = ndf*8, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch4 = nn.BatchNorm2d(ndf * 8)\n",
    "        \n",
    "        self.final_conv = nn.Conv2d(in_channels=ndf*8, out_channels=n_classes+1,kernel_size=2,stride=1,padding=0,bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x),0.2,inplace=True)\n",
    "        x = F.leaky_relu(self.batch2(self.conv2(x)),0.2,inplace=True)\n",
    "        x = F.leaky_relu(self.batch3(self.conv3(x)),0.2,inplace=True)\n",
    "        x = F.leaky_relu(self.batch4(self.conv4(x)),0.2,inplace=True)\n",
    "        x = self.final_conv(x)\n",
    "        \n",
    "        x = F.sigmoid(x)\n",
    "\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netG_1(nn.Module):\n",
    "    def __init__(self, ngpu, nz, nc , ngf, n_extra_layers_g):\n",
    "        super(_netG_1, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.z = None\n",
    "        self.convt1 = nn.ConvTranspose2d(in_channels=nz, out_channels=ngf * 8, kernel_size=4, stride=2, padding=0, bias=False)\n",
    "        self.batch1 = nn.BatchNorm2d(ngf*8)\n",
    "        self.convt2 = nn.ConvTranspose2d(in_channels=ngf * 8, out_channels=ngf * 4, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch2 = nn.BatchNorm2d(ngf*4)\n",
    "        self.convt3 = nn.ConvTranspose2d(in_channels=ngf * 4, out_channels=ngf * 2, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch3 = nn.BatchNorm2d(ngf*2)\n",
    "        self.convt4 = nn.ConvTranspose2d(in_channels=ngf*2, out_channels=ngf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch4 = nn.BatchNorm2d(ngf)\n",
    "        \n",
    "        self.final_conv = nn.ConvTranspose2d(in_channels=ngf, out_channels=nc, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.batch1(self.convt1(x)))\n",
    "        x = F.relu(self.batch2(self.convt2(x)))\n",
    "        x = F.relu(self.batch3(self.convt3(x)))\n",
    "        x = F.relu(self.batch4(self.convt4(x)))\n",
    "        x = self.final_conv(x)\n",
    "        x = F.tanh(x)\n",
    "        \n",
    "        return (x),self.z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 100 3 64 0\n",
      "1 100 3 64 0 10\n"
     ]
    }
   ],
   "source": [
    "print(ngpu, nz, nc, ngf, n_extra_g)\n",
    "netG = _netG_1(ngpu, nz, nc, ngf, n_extra_g)\n",
    "#netG_parallel = torch.nn.DataParallel(_netG_1(ngpu, nz, nc, ngf, n_extra_g))\n",
    "print(ngpu, nz, nc, ndf, n_extra_d,n_classes)\n",
    "netD = _netD_1(ngpu, nz, nc, ndf, n_extra_d,n_classes)\n",
    "#netD_parallel = torch.nn.DataParallel(_netD_1(ngpu, nz, nc, ndf, n_extra_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializador de pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_netG_1 (\n",
      "  (convt1): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(2, 2), bias=False)\n",
      "  (batch1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (convt2): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (convt3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (convt4): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (final_conv): ConvTranspose2d(64, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      ") \n",
      " _netD_1 (\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (conv3): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (conv4): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (final_conv): Conv2d(512, 11, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)\n",
    "print(netG, '\\n', netD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses\n",
    "- Binary Cross-Entropy is used to differentiate real and fake images\n",
    "- Class loss should be Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "criterion_MSE = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sizes of the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 100, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "input = torch.FloatTensor(batch_size, 3, imageSize, imageSize)\n",
    "print(input.size())\n",
    "noise = torch.FloatTensor(batch_size, nz, 1, 1)\n",
    "print(noise.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary=False\n",
    "#Ele testa pergunta se vc quer que o seu Z venha da distribuição bernoulli\n",
    "if binary:\n",
    "    bernoulli_prob = torch.FloatTensor(batch_size, nz, 1, 1).fill_(0.5)\n",
    "    fixed_noise = torch.bernoulli(bernoulli_prob)\n",
    "else:\n",
    "    fixed_noise = torch.FloatTensor(batch_size, nz, 1, 1).normal_(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label size: torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "label = torch.FloatTensor(batch_size,n_classes)\n",
    "print('Label size:', label.size())\n",
    "real_label = 1\n",
    "fake_label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_hot = torch.LongTensor(64, n_classes+1).zero_()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcast to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    netD.cuda()\n",
    "    netG.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    criterion_MSE = criterion_MSE.cuda()\n",
    "    input,label = input.cuda(), label.cuda()\n",
    "    noise, fixed_noise = noise.cuda(), fixed_noise.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Variables\n",
    "- Convert frequently used tensors to Variables, avoids broadcasting things to GPU and definition overheads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = Variable(input)\n",
    "label = Variable(label)\n",
    "noise = Variable(noise)\n",
    "fixed_noise = Variable(fixed_noise)\n",
    "one_hot = Variable(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer Parameters\n",
    "- Following the lead of Radford et al., 2015:\n",
    "\n",
    "    <b>\n",
    "    1. beta1 = 0.5\n",
    "    2. lr = 0.0002\n",
    "    </b>\n",
    "    \n",
    "- For WGAN, parameters follow Arjovsky et al., 2017:\n",
    "\n",
    "    <b>\n",
    "    1. clamp_lower = clamp_upper = 0.1\n",
    "    2. Optimizer: Adam(lr=1e-5, beta1=0.5, beta2=0.999)\n",
    "    </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta1, beta2 = 0.5, 0.999\n",
    "lr = 2.0e-4\n",
    "lr_wgan = 5.0e-5\n",
    "optimizerD = optim.Adam(netD.parameters(), lr = lr, betas = (beta1, beta2))\n",
    "#optimizerD = optim.Adam(netD_parallel.parameters(), lr = lr, betas = (beta1, beta2))\n",
    "\n",
    "optimizerG = optim.Adam(netG.parameters(), lr = lr, betas = (beta1, beta2))\n",
    "#optimizerG = optim.Adam(netG_parallel.parameters(), lr = lr, betas = (beta1, beta2))\n",
    "\n",
    "optimizerD_wgan = optim.RMSprop(netD.parameters(), lr = lr_wgan)\n",
    "optimizerG_wgan = optim.RMSprop(netG.parameters(), lr = lr_wgan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator output size: torch.Size([64, 3, 32, 32])\n",
      "Discriminator output size: torch.Size([64, 11, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "test_input_G = tc.randn(64, 100, 1, 1)\n",
    "test_input_G = Variable(test_input_G)\n",
    "test_output_G,_ = netG(test_input_G.cuda())\n",
    "\n",
    "test_output_D = netD(test_output_G)\n",
    "\n",
    "print('Generator output size:', test_output_G.size())\n",
    "print('Discriminator output size:', test_output_D.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Treinamento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_gan(num_epochs, dataloader, netD, netG, d_labelSmooth, outputDir,\n",
    "              model_option=1, binary=False, epoch_interval=100,\n",
    "              D_steps=1, G_steps=1):\n",
    "    # This validation is subjective. WGAN-GP uses 100 D_steps...\n",
    "    assert D_steps < 5, \"Keep it low, D_steps is too high.\"\n",
    "    assert G_steps < 3, \"Keep it low, G_steps is too high.\"\n",
    "    #assert batch_size % D_steps == 0, \"Use batch_size multiple of D_steps.\"\n",
    "    \n",
    "    print('Lets train!')\n",
    "    for epoch in range(num_epochs):\n",
    "        start_iter = time.time()  \n",
    "        D_x = 0\n",
    "        D_G_z1 = 0\n",
    "        D_G_z2 = 0\n",
    "        errD_acum = 0\n",
    "        errG_acum = 0\n",
    "\n",
    "        for batch, data in enumerate(dataloader, 0):\n",
    "            for step in range(D_steps):\n",
    "                #############################################################\n",
    "                # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "                # 1A - Train the detective network in the Real Dataset\n",
    "                #############################################################\n",
    "                \n",
    "                netD.zero_grad()\n",
    "                one_hot.data.fill_(0)\n",
    "                #real_cpu, _ = data\n",
    "                start = step*(int(data[0].size()[0]/D_steps))\n",
    "                end = (step+1)*int(data[0].size()[0]/D_steps)\n",
    "                #real_cpu = data[0][step*(int(data[0].size()[0]/D_steps)):(step+1)*int(data[0].size()[0]/D_steps)]\n",
    "                inp, target = data\n",
    "\n",
    "                #Aqui começa um one-hot-encoding\n",
    "                target_ = tc.unsqueeze(target,1)\n",
    "                one_hot.data.resize_(target_.size()[0],one_hot.size()[1])\n",
    "                one_hot.scatter_(1, target_, 1)\n",
    "                real_cpu = data[0][start:end]\n",
    "                real_cpu = real_cpu.cuda()\n",
    "                if (epoch == 0 and step == 0):\n",
    "                    vutils.save_image(real_cpu[0:64,:,:,:], '%s/real_samples.png' % outputDir, nrow=8)\n",
    "\n",
    "                batch_size = real_cpu.size(0)\n",
    "                input.data.resize_(real_cpu.size()).copy_(real_cpu)\n",
    "                ones_ = Variable(tc.ones(inp.size(0),1)).cuda()\n",
    "                label.data.resize_(inp.size(0),label.size(1))\n",
    "                label2 = Variable(tc.cat((label.data,ones_.data),1))\n",
    "\n",
    "                label2.data.resize_(batch_size,one_hot.size(1)).copy_(one_hot.data) # use smooth label for discriminator\n",
    "\n",
    "                output = netD(input)\n",
    "                errD_real = criterion(output.squeeze(),label2)\n",
    "                errD_real.backward()\n",
    "                \n",
    "                D_x += output.data.mean()\n",
    "                \n",
    "                #######################################################\n",
    "                # 1B - Train the detective network in the False Dataset\n",
    "                #######################################################\n",
    "                \n",
    "                noise.data.resize_(batch_size, nz, 1, 1)\n",
    "                if binary:\n",
    "                    bernoulli_prob.resize_(noise.data.size())\n",
    "                    noise.data.copy_(2*(torch.bernoulli(bernoulli_prob)-0.5))\n",
    "                else:\n",
    "                    noise.data.normal_(0, 1)\n",
    "                fake,_ = netG(noise)\n",
    "                label.data.fill_(fake_label)\n",
    "                output = netD(fake.detach()) # add \".detach()\" to avoid backprop through G\n",
    "                label3 = Variable(tc.cat((label.data,tc.zeros(inp.size(0),1).cuda()),1))\n",
    "                errD_fake = criterion(output.squeeze(), label3)\n",
    "                errD_fake.backward() # gradients for fake/real will be accumulated\n",
    "                \n",
    "                D_G_z1 += output.data.mean()\n",
    "\n",
    "                errD_acum += errD_real.data[0] + errD_fake.data[0]\n",
    "\n",
    "                optimizerD.step() # .step() can be called once the gradients are computed\n",
    "\n",
    "            for step in range(G_steps):\n",
    "                ####################################################################################\n",
    "                # (2) Update G network: maximize log(D(G(z)))\n",
    "                # Train the faker with de output from the Detective (but don't train the Detective)\n",
    "                ####################################################################################\n",
    "                \n",
    "                netG.zero_grad()\n",
    "                label.data.fill_(real_label) # fake labels are real for generator cost\n",
    "                output = netD(fake)\n",
    "                errG = criterion(output.squeeze(), label2)\n",
    "                errG.backward(retain_graph = False) # True if backward through the graph for the second time\n",
    "                #errG.backward() # True if backward through the graph for the second time\n",
    "\n",
    "                '''if model_option == 2: # with z predictor\n",
    "                    errG_z = criterion_MSE(z_prediction, noise)\n",
    "                    errG_z.backward()'''\n",
    "                \n",
    "                D_G_z2 += output.data.mean()\n",
    "                errG_acum += errG.data[0]\n",
    "                optimizerG.step()\n",
    "\n",
    "        print('epoch = ',epoch)\n",
    "\n",
    "        end_iter = time.time()        \n",
    "\n",
    "        print('[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f Elapsed %.2f s'\n",
    "              % (epoch, num_epochs, errD_acum/D_steps, errG_acum/G_steps, D_x, D_G_z1, D_G_z2, end_iter-start_iter))\n",
    "\n",
    "        #Save a grid with the pictures from the dataset, up until 64\n",
    "        save_images(netG = netG, noise = fixed_noise, outputDir = outputDir, epoch = epoch)\n",
    "\n",
    "        if epoch % epoch_interval == 0:\n",
    "            # do checkpointing\n",
    "            save_models(netG = netG, netD = netD, outputDir = outputDir, epoch = epoch)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_WGAN(num_epochs, dataloader, netD, netG, outputDir, D_iters):\n",
    "    gen_iterations = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        data_iter = iter(dataloader)\n",
    "        i = 0\n",
    "        self.D_iters = D_iters\n",
    "        while i < len(dataloader):\n",
    "            ############################\n",
    "            # (1) Update D network\n",
    "            ###########################\n",
    "            for p in netD.parameters(): # reset requires_grad\n",
    "                p.requires_grad = True # they are set to False below in netG update\n",
    "\n",
    "            # train the discriminator D_iters times\n",
    "            if gen_iterations < 25 or gen_iterations % 500 == 0:\n",
    "                D_iters = 100\n",
    "            else:\n",
    "                D_iters = self.D_iters\n",
    "            j = 0\n",
    "            while j < D_iters and i < len(dataloader):\n",
    "                j += 1\n",
    "\n",
    "                # clamp parameters to a cube\n",
    "                for p in netD.parameters():\n",
    "                    p.data.clamp_(clamp_lower, clamp_upper)\n",
    "\n",
    "                data = data_iter.next()\n",
    "                i += 1\n",
    "\n",
    "                # train with real\n",
    "                real_cpu, _ = data\n",
    "                netD.zero_grad()\n",
    "                batch_size = real_cpu.size(0)\n",
    "\n",
    "                if use_cuda:\n",
    "                    real_cpu = real_cpu.cuda()\n",
    "                input.resize_as_(real_cpu).copy_(real_cpu)\n",
    "                inputv = Variable(input)\n",
    "\n",
    "                errD_real = netD(inputv)\n",
    "                errD_real.backward(one)\n",
    "\n",
    "                # train with fake\n",
    "                noise.resize_(opt.batchSize, nz, 1, 1).normal_(0, 1)\n",
    "                noisev = Variable(noise, volatile = True) # totally freeze netG\n",
    "                fake = Variable(netG(noisev).data)\n",
    "                inputv = fake\n",
    "                errD_fake = netD(inputv)\n",
    "                errD_fake.backward(mone)\n",
    "                errD = errD_real - errD_fake\n",
    "                optimizerD.step()\n",
    "\n",
    "            ############################\n",
    "            # (2) Update G network\n",
    "            ###########################\n",
    "            for p in netD.parameters():\n",
    "                p.requires_grad = False # to avoid computation\n",
    "            netG.zero_grad()\n",
    "            # in case our last batch was the tail batch of the dataloader,\n",
    "            # make sure we feed a full batch of noise\n",
    "            noise.resize_(batch_size, nz, 1, 1).normal_(0, 1)\n",
    "            noisev = Variable(noise)\n",
    "            fake = netG(noisev)\n",
    "            errG = netD(fake)\n",
    "            errG.backward(one)\n",
    "            optimizerG.step()\n",
    "            gen_iterations += 1\n",
    "\n",
    "            print('[%d/%d][%d/%d][%d] Loss_D: %f Loss_G: %f Loss_D_real: %f Loss_D_fake %f'\n",
    "                % (epoch, num_epochs, i, len(dataloader), gen_iterations,\n",
    "                errD.data[0], errG.data[0], errD_real.data[0], errD_fake.data[0]))\n",
    "            if gen_iterations % 500 == 0:\n",
    "                real_cpu = real_cpu.mul(0.5).add(0.5)\n",
    "                vutils.save_image(real_cpu, '{0}/real_samples.png'.format(outputDir))\n",
    "                fake = netG(Variable(fixed_noise, volatile=True))\n",
    "                fake.data = fake.data.mul(0.5).add(0.5)\n",
    "                vutils.save_image(fake.data, '{0}/fake_samples_{1}.png'.format(outputDir, gen_iterations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets train!\n",
      "epoch =  0\n",
      "[0/100] Loss_D: 175.1227 Loss_G: 401.2646 D(x): 62.1774 D(G(z)): 11.2965 / 7.1651 Elapsed 347.27 s\n",
      "epoch =  1\n",
      "[1/100] Loss_D: 135.9184 Loss_G: 486.9321 D(x): 62.9956 D(G(z)): 7.8007 / 4.3787 Elapsed 462.62 s\n",
      "epoch =  2\n",
      "[2/100] Loss_D: 118.9677 Loss_G: 504.4207 D(x): 61.8220 D(G(z)): 8.9303 / 5.5620 Elapsed 462.47 s\n",
      "epoch =  3\n",
      "[3/100] Loss_D: 106.3372 Loss_G: 530.0243 D(x): 61.9986 D(G(z)): 8.7394 / 5.5370 Elapsed 462.43 s\n",
      "epoch =  4\n",
      "[4/100] Loss_D: 93.3501 Loss_G: 559.6893 D(x): 63.0682 D(G(z)): 7.6923 / 4.8354 Elapsed 462.46 s\n",
      "epoch =  5\n",
      "[5/100] Loss_D: 82.7167 Loss_G: 595.5511 D(x): 63.6585 D(G(z)): 7.1837 / 4.2380 Elapsed 461.83 s\n",
      "epoch =  6\n",
      "[6/100] Loss_D: 74.9327 Loss_G: 616.8739 D(x): 63.5913 D(G(z)): 7.2211 / 4.1723 Elapsed 462.33 s\n",
      "epoch =  7\n",
      "[7/100] Loss_D: 67.3900 Loss_G: 639.7911 D(x): 63.4693 D(G(z)): 7.3892 / 4.0358 Elapsed 461.92 s\n",
      "epoch =  8\n",
      "[8/100] Loss_D: 60.4419 Loss_G: 666.1385 D(x): 63.5175 D(G(z)): 7.3082 / 3.7780 Elapsed 460.35 s\n",
      "epoch =  9\n",
      "[9/100] Loss_D: 54.0030 Loss_G: 699.5561 D(x): 63.8311 D(G(z)): 7.0351 / 3.3528 Elapsed 461.63 s\n",
      "epoch =  10\n",
      "[10/100] Loss_D: 47.3674 Loss_G: 733.8062 D(x): 64.2878 D(G(z)): 6.5769 / 2.9570 Elapsed 460.80 s\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "d_labelSmooth = 0.2\n",
    "\n",
    "train_gan(num_epochs, dataloader, netD,netG,d_labelSmooth, outputDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
