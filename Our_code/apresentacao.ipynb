{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para baixar todos os nossos experimentos, use estes links:\n",
    "\n",
    "https://drive.google.com/open?id=1WiyXsCDwH1Cm_0_bGHuywHPqj4GmI4l4\n",
    "\n",
    "https://drive.google.com/open?id=1371AETlvjBL5BYs5qc9TaYhx6iVNBOoT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setando corretamente as GPU's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_cuda(TARGET_GPU=None):\n",
    "    '''\n",
    "    Prompts relevant package versions.\n",
    "    Verifies if system has GPU enabled and returns this status.\n",
    "    Can be used to set what GPUs are visible by current process.\n",
    "    '''\n",
    "    print('__Python VERSION:', sys.version)\n",
    "    print('__pyTorch VERSION:', torch.__version__)\n",
    "    print('__CUDA VERSION')\n",
    "    print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "    print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "    print('__Devices')\n",
    "    print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
    "    \n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    if torch.cuda.device_count() > 1 and TARGET_GPU is not None:\n",
    "        os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(TARGET_GPU)\n",
    "        print(\"You have manually set configured the visible GPUs. Now only GPUs {} will be visible. Make sure you know what you are doing.\".format(TARGET_GPU))\n",
    "        \n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    if use_gpu:\n",
    "        print(\"You are using CUDA. If it is not what you want, manually set this as False!\")\n",
    "        \n",
    "    return(use_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo o Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset definition and hyperparameter setting\n",
    "- Changing dataset name alters network architecture parameters\n",
    "- Currently supporting few datasets\n",
    "- Hyperparameters defined according to Radford et al. (2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_dataset(chosen_dataset):\n",
    "    datasets = {\n",
    "        'MNIST': torchvision.datasets.MNIST,\n",
    "        'CIFAR10': torchvision.datasets.CIFAR10,\n",
    "        'ANIME': '/home/gabriel/Redes Neurais/Projeto_Final_GANS/Tutorial_2/dataset/min_anime-faces',\n",
    "    }\n",
    "    dataset = datasets[chosen_dataset]\n",
    "\n",
    "    possible_parameters = {\n",
    "        'MNIST': {\n",
    "            'ndf': 64,\n",
    "            'ngf': 64,\n",
    "            'nz': 100,\n",
    "            'nc': 1,\n",
    "            'imageSize': 64,\n",
    "            'n_classes': 10,\n",
    "        },\n",
    "        'CIFAR10': {\n",
    "            'ndf': 64,\n",
    "            'ngf': 64,\n",
    "            'nz': 100,\n",
    "            'nc': 3,\n",
    "            'imageSize': 64,\n",
    "            'n_classes': 10,\n",
    "        },\n",
    "        'ANIME': {\n",
    "            'nc': 3,\n",
    "            'nz': 100,\n",
    "            'ngf': 64,\n",
    "            'ndf': 64,\n",
    "            'imageSize': 64,\n",
    "            'n_classes': 1\n",
    "        }\n",
    "    }\n",
    "\n",
    "    ngf = possible_parameters[chosen_dataset]['ngf']\n",
    "    ndf = possible_parameters[chosen_dataset]['ndf']\n",
    "    nz = possible_parameters[chosen_dataset]['nz']\n",
    "    nc = possible_parameters[chosen_dataset]['nc']\n",
    "    imageSize = possible_parameters[chosen_dataset]['imageSize']\n",
    "    n_classes = possible_parameters[chosen_dataset]['n_classes']\n",
    "\n",
    "    if dataset == 'ANIME':\n",
    "        dataset = torchvision.datasets.ImageFolder(\n",
    "            root='/home/gabriel/Redes Neurais/Projeto_Final_GANS/Tutorial_2/dataset/min_anime-faces',\n",
    "            transform=transforms.Compose([\n",
    "                transforms.Scale((imageSize, imageSize)),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "        )\n",
    "    else:\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Scale((imageSize, imageSize)),\n",
    "            transforms.ToTensor(),\n",
    "            # bring images to (-1,1)\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "        dataset_done = dataset('./datasets', train=True, download=True, transform=transform)\n",
    "        \n",
    "    return(dataset_done, ngf, ndf, nz, nc, imageSize, n_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo o Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_dataloader(dataset_done, batch_size):\n",
    "    dataloader = torch.utils.data.DataLoader(dataset_done, batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "    \n",
    "    print(\"Dataset:\", dataloader.dataset)\n",
    "    print('Dataloader length:', len(dataloader))\n",
    "    return(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definição da rede classificadora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netD_DCGAN(nn.Module):\n",
    "    def __init__(self, nz, nc, ndf, n_classes):\n",
    "        super(_netD_DCGAN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=nc, out_channels=ndf,\n",
    "                               kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(in_channels=ndf, out_channels=ndf * 2,\n",
    "                               kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch2 = nn.BatchNorm2d(ndf * 2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=ndf * 2, out_channels=ndf * 4,\n",
    "                               kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch3 = nn.BatchNorm2d(ndf * 4)\n",
    "        self.conv4 = nn.Conv2d(in_channels=ndf * 4, out_channels=ndf * 8,\n",
    "                               kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch4 = nn.BatchNorm2d(ndf * 8)\n",
    "\n",
    "        self.final_conv = nn.Conv2d(\n",
    "            in_channels=ndf * 8, out_channels=n_classes + 1, kernel_size=4, stride=1, padding=0, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch2(self.conv2(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch3(self.conv3(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch4(self.conv4(x)), 0.2, inplace=True)\n",
    "\n",
    "        x = self.final_conv(x)\n",
    "        return(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definição da rede geradora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netG_DCGAN(nn.Module):\n",
    "    def __init__(self, nz, nc, ngf):\n",
    "        super(_netG_DCGAN, self).__init__()\n",
    "        self.convt1 = nn.ConvTranspose2d(\n",
    "            in_channels=nz, out_channels=ngf * 8, kernel_size=4, stride=1, padding=0, bias=False)\n",
    "        self.batch1 = nn.BatchNorm2d(ngf * 8)\n",
    "        self.convt2 = nn.ConvTranspose2d(\n",
    "            in_channels=ngf * 8, out_channels=ngf * 4, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch2 = nn.BatchNorm2d(ngf * 4)\n",
    "        self.convt3 = nn.ConvTranspose2d(\n",
    "            in_channels=ngf * 4, out_channels=ngf * 2, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch3 = nn.BatchNorm2d(ngf * 2)\n",
    "        self.convt4 = nn.ConvTranspose2d(\n",
    "            in_channels=ngf * 2, out_channels=ngf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch4 = nn.BatchNorm2d(ngf)\n",
    "\n",
    "        self.final_convt = nn.ConvTranspose2d(\n",
    "            in_channels=ngf, out_channels=nc, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.batch1(self.convt1(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch2(self.convt2(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch3(self.convt3(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch4(self.convt4(x)), 0.2, inplace=True)\n",
    "\n",
    "        x = self.final_convt(x)\n",
    "        x = F.tanh(x)\n",
    "        return (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicializador de pesos\n",
    "- Pesos de camadas convolucionais são inicializados com gaussiana de média 0 e desvio padrão 0.02\n",
    "- Pesos de camadas BatchNorm são inicializados com gaussiana de média 1 e desvio padrão 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicializador de tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_tensors(batch_size, nc, imageSize, nz, n_classes):\n",
    "    input = torch.FloatTensor(batch_size, nc, imageSize, imageSize)\n",
    "    print('Input images size:', input.size())\n",
    "    \n",
    "    noise = torch.FloatTensor(batch_size, nz, 1, 1)\n",
    "    fixed_noise = torch.FloatTensor(batch_size, nz, 1, 1).normal_(0, 1)\n",
    "    print('Code size:', noise.size())\n",
    "\n",
    "    label = torch.LongTensor(batch_size, n_classes)\n",
    "    print('Label size:', label.size())\n",
    "    fake_label = 10\n",
    "    return(input, noise, fixed_noise, label, fake_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fazendo Broadcast para a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def broadcast_to_gpu(use_gpu, netD, netG, label, input, criterion, fixed_noise, noise):\n",
    "    if use_gpu:\n",
    "        print('Broadcasting to the GPU...')\n",
    "        netD.cuda()\n",
    "        netG.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "        input, label = input.cuda(), label.cuda()\n",
    "        noise, fixed_noise = noise.cuda(), fixed_noise.cuda()\n",
    "    else:\n",
    "        print(\"GPU isn't available \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo as propriedades do otimizador e função de custo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimization_properties(netD, netG, lr, beta1, beta2):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "    return(optimizerG, optimizerD, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função para salvar as imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_images(netG, fixed_noise, epoch, imageSize, outputDir):\n",
    "    fixed_noise = Variable(fixed_noise)\n",
    "    netG.eval()\n",
    "    fake_data = netG(fixed_noise.cuda())\n",
    "    netG.train()\n",
    "    fig = plot_samples(fake_data.data.cpu().numpy(), imageSize)\n",
    "    plt.savefig(\n",
    "        outputDir + '/dcgan_img_{:04d}.png'.format(epoch, bbox_inches='tight'))\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função para plotar as imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_samples(samples, imageSize):\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    gs = gridspec.GridSpec(5, 5)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "    for i, sample in enumerate(samples[:25]):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(imageSize, imageSize), cmap='Greys_r')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função que salva os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_models(netG, netD, outputDir, epoch):\n",
    "    '''\n",
    "    Saves model state dictionary for generator and discriminator networks.\n",
    "    Inputs are the networks (netG, netD), the system path in which to save(outputDir) and the current 'epoch'.\n",
    "    '''\n",
    "    torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (outputDir, epoch))\n",
    "    torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (outputDir, epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função que define o diretório de saída\n",
    "- Cria diretório onde imagens serão salvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_outputDir(outputDir):\n",
    "    try:\n",
    "        os.makedirs(outputDir)\n",
    "        print('Directory created!')\n",
    "    except OSError as err:\n",
    "        print(\"OS error: {0}\".format(err))\n",
    "    return(outputDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função que carrega os modelos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_models(netG, netD, outputDir, epoch):\n",
    "    '''\n",
    "    Saves( model state dictionary for generator and discriminator networks.\n",
    "    Inputs are the networks (netG, netD), the system path in which to save(outputDir) and the current 'epoch'.\n",
    "    '''\n",
    "    #model.load_state_dict(torch.load('mytraining.pt'))\n",
    "    netG.load_state_dict(torch.load('%s/netG_epoch_%d.pth' % (outputDir, epoch)))\n",
    "    netD.load_state_dict(torch.load('%s/netD_epoch_%d.pth' % (outputDir, epoch)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função de treinamento e algoritmo da nossa aplicação\n",
    "- Modelo DCGAN. WGAN requer algumas pequenas modificações no laço de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_gan(num_epochs, dataloader, netD, optimizerD, netG, optimizerG, criterion, nz, outputDir, noise, fixed_noise, imageSize,\n",
    "              real_labelSmooth=0, epoch_interval=100, D_steps=1, G_steps=1, fake_label=0, n_classes=10, LS_decay=0.05):\n",
    "\n",
    "    # This validation is subjective. WGAN-GP uses 100 steps on the critic (netD).\n",
    "    assert D_steps < 5, \"Keep it low, D_steps is too high.\"\n",
    "    assert G_steps < 3, \"Keep it low, G_steps is too high.\"\n",
    "    #assert batch_size % D_steps == 0, \"Use batch_size multiple of D_steps.\"\n",
    "    real_label = 1\n",
    "    print('Lets train!')\n",
    "    for epoch in range(num_epochs):\n",
    "        start_iter = time.time()\n",
    "        D_x = 0\n",
    "        D_G_z1 = 0\n",
    "        D_G_z2 = 0\n",
    "        errD_acum = 0\n",
    "        errG_acum = 0\n",
    "\n",
    "        real_labelSmooth = np.maximum(real_labelSmooth * (1 - LS_decay * epoch), 0)\n",
    "        \n",
    "        print('In epoch = ', epoch, 'real_label_smooth = ', real_labelSmooth)\n",
    "        for batch, data in enumerate(dataloader, 0):\n",
    "            if (epoch == 0 and batch == 0):\n",
    "                fig = plot_samples(data[0][0:data[0].size(0), :, :, :].cpu().numpy(), imageSize=imageSize)\n",
    "                plt.savefig(outputDir + '/real_samples.png'.format(epoch, bbox_inches='tight'))\n",
    "                plt.close(fig)\n",
    "                \n",
    "            for step in range(D_steps):\n",
    "                #############################################################\n",
    "                # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "                # 1A - Train the detective network in the Real Dataset\n",
    "                #############################################################\n",
    "                netD.zero_grad()\n",
    "                start = step * (int(data[0].size()[0] / D_steps))\n",
    "                end = (step + 1) * int(data[0].size()[0] / D_steps)\n",
    "\n",
    "                real_cpu = data[0][start:end]\n",
    "                real_cpu = real_cpu.cuda()\n",
    "                batch_size = real_cpu.size(0)\n",
    "                \n",
    "                if np.random.random_sample() > real_labelSmooth:\n",
    "                    target = data[1][start:end].long().cuda()\n",
    "                else:\n",
    "                    target = torch.from_numpy(np.random.randint(0, n_classes, batch_size)).type(torch.LongTensor).cuda()\n",
    "\n",
    "                input, label = Variable(real_cpu), Variable(target)\n",
    "\n",
    "                output = netD(input)\n",
    "                errD_real = criterion(output.squeeze(), label)\n",
    "                errD_real.backward()\n",
    "\n",
    "                D_x += output.data.mean()\n",
    "\n",
    "                #######################################################\n",
    "                # 1B - Train the detective network in the False Dataset\n",
    "                #######################################################\n",
    "\n",
    "                noise = Variable(torch.FloatTensor(batch_size, nz, 1, 1).normal_(0, 1).cuda())\n",
    "                fake = netG(noise)\n",
    "                label = Variable(torch.ones(batch_size).long().fill_(fake_label).cuda())\n",
    "                # \".detach()\" to avoid backprop through G\n",
    "                output = netD(fake.detach())\n",
    "                errD_fake = criterion(output.squeeze(), label)\n",
    "                errD_fake.backward()  # gradients for fake and real data will be accumulated\n",
    "\n",
    "                D_G_z1 += output.data.mean()\n",
    "                errD_acum += errD_real.data[0] + errD_fake.data[0]\n",
    "                optimizerD.step()\n",
    "\n",
    "            for step in range(G_steps):\n",
    "                ####################################################################################\n",
    "                # (2) Update G network: maximize log(D(G(z)))\n",
    "                # Train the faker with the output from the Detective (but don't train the Detective)\n",
    "                ####################################################################################\n",
    "\n",
    "                netG.zero_grad()\n",
    "                label = Variable(torch.from_numpy(np.random.randint(0, n_classes, batch_size)).type(torch.LongTensor).cuda())\n",
    "                output = netD(fake)\n",
    "                errG = criterion(output.squeeze(), label)\n",
    "                errG.backward()\n",
    "\n",
    "                D_G_z2 += output.data.mean()\n",
    "                errG_acum += errG.data[0]\n",
    "                optimizerG.step()\n",
    "\n",
    "        print('epoch = ', epoch)\n",
    "\n",
    "        end_iter = time.time()\n",
    "\n",
    "        print('[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f Elapsed %.2f s'\n",
    "              % (epoch, num_epochs, errD_acum / D_steps, errG_acum / G_steps, D_x, D_G_z1, D_G_z2, end_iter - start_iter))\n",
    "\n",
    "        # Save a grid with the pictures from the dataset, up until 64\n",
    "        save_images(netG, fixed_noise, epoch,\n",
    "                    imageSize=imageSize, outputDir=outputDir)\n",
    "\n",
    "        if epoch % epoch_interval == 0:\n",
    "            # do checkpointing\n",
    "            save_models(netG=netG, netD=netD, outputDir=outputDir, epoch=epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Afinal, o que são GANs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Framework de geração adversarial proposto em [Goodfellow et. al., 2014](https://arxiv.org/abs/1406.2661) não especifica qual o tipo do gerador e do discriminador.\n",
    "- Usar redes neurais para as duas partes desse problema é conveniente: backpropagation e algoritmos de otimização viabilizam treinamento das duas redes simultaneamente. Esse caso especial recebe o nome de Generative Adversarial Nets.\n",
    "- Esse caso especial apresenta a vantagem de que todos os desenvolvimentos dos campos de Deep Learning podem ser explorados sem grandes impedimentos (BN, Dropout, otimizadores, ativações, arquiteturas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qual a cara desse framework?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='apresentacao_imagens/gan_layout0.png', width=750pt>\n",
    "<img src='apresentacao_imagens/gan_layout1.png', width=750pt>\n",
    "<img src='apresentacao_imagens/gan_layout2.png', width=750pt>\n",
    "<img src='apresentacao_imagens/gan_layout3.png', width=750pt>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encoder-Decoder GANs [[ref]](https://arxiv.org/abs/1511.06434)\n",
    "- Arquiteturas GAN + VAE [[ref]](https://arxiv.org/abs/1703.00848v4)\n",
    "- Arquiteturas com 3 blocos funcionais [[ref]](https://arxiv.org/abs/1703.02291)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problemas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convergência não é garantida (e é muito díficil em algumas condições)\n",
    "\n",
    "    1. Modelos são muito sensíveis aos hiperparâmetros utilizados (alto custo de busca por hiperparâmetros dificulta o treinamento de GANs tradicionais);\n",
    "\n",
    "    2. Técnicas para facilitar convergência geram problemas secundários e ainda não há um padrão bem definido quanto a boas práticas;\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "- Mesmo quando modelo converge, podem acontecer problemas...\n",
    "\n",
    "    1. Mode Collapse\n",
    "\n",
    "    2. Convergência para mínimos locais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensibilidade\n",
    "- Resultados abaixo são para LS_decay=0.025, epoch=40, variando labelSmooth em 0.05 [0.1, 0.15, 0.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "    <td><img src='apresentacao_imagens/smooth_0d10_decay_0d025_epoch_40.jpeg', width=330pt></td>\n",
    "    <td><img src='apresentacao_imagens/smooth_0d15_decay_0d025_epoch_40.jpeg', width=330pt></td>\n",
    "    <td><img src='apresentacao_imagens/smooth_0d20_decay_0d025_epoch_40.jpeg', width=330pt></td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divergência"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "    <td><img src='apresentacao_imagens/smooth_0d10_decay_0d05_epoch_1.png', width=330pt></td>\n",
    "    <td><img src='apresentacao_imagens/smooth_0d10_decay_0d05_epoch_10.png', width=330pt></td>\n",
    "    <td><img src='apresentacao_imagens/smooth_0d10_decay_0d05_epoch_25.png', width=330pt></td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode Collapse?\n",
    "Modos mal representados, dataset pequeno ou hiperparâmetros longe do ideal podem gerar condições em que grande parte do código é traduzida para uma mesma imagem que engana bastante o discriminador, mas é longe do desejado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "    <td><img src='apresentacao_imagens/smooth_0d25_decay_0d04_epoch39.png', width=330pt></td>\n",
    "    <td><img src='apresentacao_imagens/smooth_0d25_decay_0d04_epoch41.png', width=330pt></td>\n",
    "    <td><img src='apresentacao_imagens/smooth_0d25_decay_0d04_epoch43.png', width=330pt></td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estabilização em mínimos locais\n",
    "Pode fazer imagens geradas estabilizarem em estados ruins: verossimilhança cai."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### add image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passos em direção à convergência"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) DC-GAN\n",
    "\n",
    "2) Label Smoothing para os rótulos reais\n",
    "\n",
    "3) Utilização de rótulos de classes\n",
    "\n",
    "4) Alteração das funções de custo \n",
    "\n",
    "    a) EBGAN, WGAN, CramerGAN, WGAN-GP, WGAN-LP…\n",
    "\n",
    "    b) Feature Selection Strikes Back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Proposta em [Radford et. al., 2015](https://arxiv.org/abs/1511.06434), trata-se de uma arquitetura de rede totalmente convolucional cuidadosamente escolhida \n",
    "\n",
    "2) Apresenta convergência mais garantida e menor sensibilidade a hiperparâmetros\n",
    "\n",
    "3) Proporciona um modelo base sobre o qual iterar e uma boa referência de desempenho: quase todas as arquiteturas são comparadas a essa, mesmo já sendo um pouco \"antiga\"\n",
    "\n",
    "4) Incorpora conceitos fundamentais do DL às GANs\n",
    "\n",
    "    a) Batch-Norm\n",
    "\n",
    "    b) Dropout\n",
    "\n",
    "    c) ReLU, Leaky-ReLU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Smoothing unilateral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tipicamente...\n",
    "                        amostras reais => label 1 \n",
    "\n",
    "                        amostras falsas => label 0\n",
    "\n",
    "##### Mas…\n",
    "\n",
    "Suavizar os rótulos das imagens reais facilita a convergência e aumenta a qualidade das imagens geradas (Salimans et. al., 2016)\n",
    "\n",
    "A ideia (geralmente) é somar um número aleatório entre -0.3 e 0.2 ao rótulo real. Esse número pode decair ao longo do treinamento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rótulos de classe e Classificador (redes G-C)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se os dados possuem rótulos, é possível treinar classificadores com o auxílio de GANs? Se sim, como?\n",
    "\n",
    "   1) Em [Springenberg, 2015](https://arxiv.org/abs/1511.06390), [Salimans et. al., 2016]( www.google.com ) são propostos métodos para treinar classificadores semisupervisionados com o auxílio de GANs;\n",
    "\n",
    "   2) O uso de classificadores ao invés de discriminadores melhora o desempenho das redes na geração de imagens;\n",
    "\n",
    "   3) É possível gerar bons classificadores com poucos dados! O problema é que isso geralmente implica na geração de imagens artificiais ruins.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Smoothing com classe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível fazer Label Smoothing também com os rótulos de classe.\n",
    "\n",
    "    1) Define-se uma probabilidade de suavização [0,1)\n",
    "    \n",
    "    2) Caso decida-se trocar os rótulos, coloca-se rótulos aleatórios para as imagens reais!\n",
    "    \n",
    "    3) O último rótulo (N+1) é usado apenas para as imagens falsas\n",
    "    \n",
    "    \n",
    "        if np.random.random_sample() > real_labelSmooth:\n",
    "            target = data[1][start:end].long().cuda()\n",
    "        else:\n",
    "            target = torch.from_numpy(np.random.randint(0, n_classes, batch_size)).type(torch.LongTensor).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções de custo alternativas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diversos trabalhos focam em propor funções de custo que proporcionam convergência mais fácil e cujo valor tem mais relação com a evolução do treino.\n",
    "\n",
    "- [WGAN](https://arxiv.org/pdf/1701.07875.pdf): Usa distância Wasserstein-1 (Earth-Mover)\n",
    "\n",
    "- [EBGAN](https://arxiv.org/pdf/1609.03126.pdf): Discriminador estruturado como um Auto-Codificador\n",
    "\n",
    "- [CramerGAN](https://arxiv.org/pdf/1705.10743.pdf): Propõe uma função de custo com propriedades similares à W_1, baseada na distância de Cramer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções de custo alternativas: downsides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A escolha cuidadosa de melhores funções de custo se assemelha muito à prática de feature selection, que o Deep Learning prometia evitar.\n",
    "\n",
    "- Muito trabalho tem sido dedicado a encontrar funções que apresentam resultados incrementalmente melhores\n",
    "\n",
    "    - Esses trabalhos são geralmente difíceis de entender e de empregar rapidamente.\n",
    "    \n",
    "    \n",
    "\n",
    "- Ainda que se possa reutilizar o framework, este precisa ser constantemente atualizado para dar suporte às novas abordagens\n",
    "\n",
    "    - Gradient-penalty, Energy Based e Cramer, por exemplo, não são implementações simples\n",
    "    - Mesmo as WGANs, mais fáceis de implementar, causam alguns problemas e confusões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nossa implementação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DC-GAN com label smoothing e classificador\n",
    "\n",
    "    - Não conseguimos imagens de boa qualidade visual com modelos mais simples, mesmo para datasets como MNIST (1)\n",
    "    - Implementação não é muito complexa e é fácil de treinar\n",
    "    - Laço de treinamento é genérico o suficiente para ser usado para a maioria dos outros modelos propostos para GANs, com poucas modificações\n",
    "\n",
    "- DC-GAN com distância de Wasserstein\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1: DC-GAN tradicional gera imagens boas, mas diverge facilmente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apresentação geral do framework (função main)\n",
    "- Fluxo do programa de forma generalizada. A maioria das GANs podem ser implementadas sem alterar esse fluxo de informação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    ####### Hyper Parameters ####\n",
    "    num_epochs = 40\n",
    "    batch_size = 128\n",
    "    \n",
    "    lr = 2.0e-4\n",
    "    beta1, beta2 = 0.5, 0.999\n",
    "        \n",
    "    real_labelSmooth = 0.25\n",
    "    LS_decay = 0.05\n",
    "    \n",
    "    outputDir = 'outputdir_apresentacao'\n",
    "    ##############################################################\n",
    "    \n",
    "    # Definição de utilização de GPU e, se desejado, qual GPU utilizar \n",
    "    use_gpu = set_cuda()\n",
    "    \n",
    "    # Definição do dataset, tamanhos de imagem, tamanho do código, nº de classes a usar, etc.\n",
    "    dataset_chosen, ngf, ndf, nz, nc, imageSize, n_classes = define_dataset(\"MNIST\")\n",
    "    \n",
    "    # Definição do dataloader\n",
    "    dataloader = define_dataloader(dataset_chosen, batch_size)\n",
    "    \n",
    "    # Criação das redes, sendo G a rede geradora e D a classificadora\n",
    "    netG = _netG_DCGAN(nz, nc, ngf)\n",
    "    netD = _netD_DCGAN(nz, nc, ndf, n_classes)\n",
    "    \n",
    "    # Inicialização dos pesos com uma distribuição apropriada, quando necessário\n",
    "    netG.apply(weights_init)\n",
    "    netD.apply(weights_init)\n",
    "    \n",
    "    # Criação dos tensores fora do loop\n",
    "    input, noise, fixed_noise, label, fake_label = initialize_tensors(batch_size, nc, imageSize, nz, n_classes)\n",
    "    \n",
    "    # Definição dos otimizadores e da função de custo a ser utilizada\n",
    "    optimizerG, optimizerD, criterion = optimization_properties(netD, netG, lr, beta1, beta2)\n",
    "    \n",
    "    # Alocação dos dados na GPU\n",
    "    broadcast_to_gpu(use_gpu, netD, netG, label, input, criterion, fixed_noise, noise)\n",
    "    \n",
    "    # Definição do diretório onde serão salvas as figuras\n",
    "    outputDir = define_outputDir(outputDir)\n",
    "\n",
    "    # Laço principal de treinamento\n",
    "    train_gan(num_epochs, dataloader, netD, optimizerD, netG, optimizerG,\n",
    "              criterion, nz, outputDir, noise=noise, fixed_noise=fixed_noise,\n",
    "              imageSize=imageSize, real_labelSmooth=real_labelSmooth,\n",
    "              fake_label=fake_label, n_classes=n_classes, LS_decay=LS_decay)\n",
    "    \n",
    "    print('Training finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essa parte demora... muito. Fica pra depois! :)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Essa parte demora... muito. Fica pra depois! :)\")\n",
    "    #main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imagens Geradas com o modelo DC-GAN\n",
    "- Qual dos quadrantes contém imagens geradas artificialmente?\n",
    "- Por que?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='apresentacao_imagens/cherrypick_DCGAN.png', width=500pt>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Com grid search (não exaustivo, mas considerável) usando parâmetros de label smoothing, obtivemos convergência em poucos modelos. \n",
    "- Quase todos os modelos entram em Mode Collapse\n",
    "- Para os que convergiram, qualidade das imagens foi boa!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previsões usando um modelo já treinado\n",
    "- Parâmetros de treinamento são os mesmos do modelo no qual as imagens obtidas foram de melhor qualidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO LOAD model state dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
