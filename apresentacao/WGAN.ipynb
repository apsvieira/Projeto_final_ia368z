{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System properties and libs currently in use\n",
    "- We have developed using python 3.5.x, pytorch 0.2.1\n",
    "- No significant attention was given to backwards compatibility\n",
    "- Or forwards, for that matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__Python VERSION: 3.6.3 (default, Oct 31 2017, 12:34:50) \n",
      "[GCC 5.4.0 20160609]\n",
      "__pyTorch VERSION: 0.2.0_3\n",
      "__CUDA VERSION\n",
      "__CUDNN VERSION: 6021\n",
      "__Number CUDA Devices: 4\n",
      "__Devices\n",
      "Active CUDA Device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "print('Active CUDA Device: GPU', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities\n",
    "- Saving images and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(netG, fixed_noise, outputDir,epoch):\n",
    "    '''\n",
    "    Generates a batch of images from the given 'noise'.\n",
    "    Saves 64 of the generated samples to 'outputDir' system path.\n",
    "    Inputs are the network (netG), a 'noise' input, system path to which images will be saved (outputDir) and current 'epoch'.\n",
    "    '''\n",
    "    noise = Variable(fixed_noise)\n",
    "    netG.eval()\n",
    "    fake = netG(noise)\n",
    "    netG.train()\n",
    "    vutils.save_image(fake.data[0:64,:,:,:],'%s/fake_samples_epoch_%03d.png' % (outputDir, epoch), nrow=8)\n",
    "\n",
    "def save_models(netG, netD, outputDir, epoch):\n",
    "    '''\n",
    "    Saves model state dictionary for generator and discriminator networks.\n",
    "    Inputs are the networks (netG, netD), the system path in which to save(outputDir) and the current 'epoch'.\n",
    "    '''\n",
    "    torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (outputDir, epoch))\n",
    "    torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (outputDir, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using CUDA. If it is not what you want, manually set this as False!\n"
     ]
    }
   ],
   "source": [
    "cudnn.benchmark = True\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"You are using CUDA. If it is not what you want, manually set this as False!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Directory\n",
    "This is where images will be saved to.\n",
    "\n",
    "If directory does not exist, it is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputDir = 'output_WGAN_4'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outputDir)\n",
    "except OSError as err:\n",
    "    print(\"OS error: {0}\".format(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset definition and hyperparameter setting\n",
    "- Changing dataset name alters network architecture parameters\n",
    "- Currently supporting few datasets\n",
    "- Hyperparameters defined according to Radford et al. (2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "chosen_dataset = 'MNIST'\n",
    "\n",
    "datasets = {\n",
    "    'MNIST': torchvision.datasets.MNIST,\n",
    "    'CIFAR10': torchvision.datasets.CIFAR10,\n",
    "    'ANIME': '/home/gabriel/Redes Neurais/Projeto_Final_GANS/Tutorial_2/dataset/min_anime-faces',\n",
    "}\n",
    "\n",
    "dataset = datasets[chosen_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_parameters = {\n",
    "    'MNIST': {\n",
    "        'ndf': 64,\n",
    "        'ngf': 64,\n",
    "        'nz': 100,\n",
    "        'nc': 1,\n",
    "        'imageSize': 64,\n",
    "        'n_classes' : 10,\n",
    "        'ngpu': 1,\n",
    "    },\n",
    "    'CIFAR10': {\n",
    "        'ndf': 64,\n",
    "        'ngf': 64,\n",
    "        'nz': 100,\n",
    "        'nc': 3,\n",
    "        'imageSize' : 64,\n",
    "        'n_classes' : 10,\n",
    "        'ngpu' : 1,\n",
    "    },\n",
    "    'ANIME': {\n",
    "        'nc' : 3,\n",
    "        'ngpu' : 1,\n",
    "        'nz' : 100,\n",
    "        'ngf' : 64,\n",
    "        'ndf' : 64,\n",
    "        'imageSize' : 64,\n",
    "        'n_classes' : 1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngf = possible_parameters[chosen_dataset]['ngf']\n",
    "ndf = possible_parameters[chosen_dataset]['ndf']\n",
    "nz = possible_parameters[chosen_dataset]['nz']\n",
    "nc = possible_parameters[chosen_dataset]['nc']\n",
    "imageSize = possible_parameters[chosen_dataset]['imageSize']\n",
    "n_classes = possible_parameters[chosen_dataset]['n_classes']\n",
    "ngpu = possible_parameters[chosen_dataset]['ngpu']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'ANIME':\n",
    "    dataset = torchvision.datasets.ImageFolder(\n",
    "        root='/home/gabriel/Redes Neurais/Projeto_Final_GANS/Tutorial_2/dataset/min_anime-faces',\n",
    "        transform=transforms.Compose([\n",
    "                transforms.Scale((imageSize, imageSize)),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "    )\n",
    "else:\n",
    "    transform = transforms.Compose([\n",
    "                    transforms.Scale((imageSize, imageSize)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)), # bring images to (-1,1)\n",
    "                ]) \n",
    "    dataset_done = dataset('./datasets', train=True, download=True, transform=transform)\n",
    "    #dataloader = torch.utils.data.DataLoader(dataset_done, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "#print('Dataloader length:', len(dataloader))\n",
    "#print(\"Dataset:\", dataloader.dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição dos modelos\n",
    "- Model is a DCGAN\n",
    "- Images are sized (nc, 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _netD_DCGAN(nn.Module):\n",
    "    def __init__(self, ngpu, nz, nc, ndf, n_classes):\n",
    "        super(_netD_DCGAN, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.conv1 = nn.Conv2d(in_channels = nc, out_channels = ndf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(in_channels = ndf, out_channels = ndf*2, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch2 = nn.BatchNorm2d(ndf * 2)\n",
    "        self.conv3 = nn.Conv2d(in_channels = ndf*2, out_channels = ndf*4, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch3 = nn.BatchNorm2d(ndf * 4)\n",
    "        self.conv4 = nn.Conv2d(in_channels = ndf*4, out_channels = ndf*8, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch4 = nn.BatchNorm2d(ndf * 8)\n",
    "        \n",
    "        self.final_conv = nn.Conv2d(in_channels=ndf*8, out_channels=1,kernel_size=4,stride=1,padding=0,bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch2(self.conv2(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch3(self.conv3(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch4(self.conv4(x)), 0.2, inplace=True)\n",
    "        \n",
    "        x = self.final_conv(x)\n",
    "        x = x.mean(0)\n",
    "        \n",
    "        return(x.view(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _netG_DCGAN(nn.Module):\n",
    "    def __init__(self, ngpu, nz, nc , ngf):\n",
    "        super(_netG_DCGAN, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.convt1 = nn.ConvTranspose2d(in_channels=nz, out_channels=ngf * 8, kernel_size=4, stride=1, padding=0, bias=False)\n",
    "        self.batch1 = nn.BatchNorm2d(ngf*8)\n",
    "        self.convt2 = nn.ConvTranspose2d(in_channels=ngf * 8, out_channels=ngf * 4, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch2 = nn.BatchNorm2d(ngf*4)\n",
    "        self.convt3 = nn.ConvTranspose2d(in_channels=ngf * 4, out_channels=ngf * 2, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch3 = nn.BatchNorm2d(ngf*2)\n",
    "        self.convt4 = nn.ConvTranspose2d(in_channels=ngf*2, out_channels=ngf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.batch4 = nn.BatchNorm2d(ngf)\n",
    "        \n",
    "        self.final_convt = nn.ConvTranspose2d(in_channels=ngf, out_channels=nc, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.batch1(self.convt1(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch2(self.convt2(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch3(self.convt3(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.batch4(self.convt4(x)), 0.2, inplace=True)\n",
    "        \n",
    "        x = self.final_convt(x)\n",
    "        x = F.tanh(x)\n",
    "        return (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = _netG_DCGAN(ngpu, nz, nc, ngf)\n",
    "netD = _netD_DCGAN(ngpu, nz, nc, ndf, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializador de pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_netG_DCGAN (\n",
      "  (convt1): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "  (batch1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (convt2): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (convt3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (convt4): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (final_convt): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      ") \n",
      " _netD_DCGAN (\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (conv3): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (conv4): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (final_conv): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)\n",
    "print(netG, '\\n', netD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses\n",
    "- Binary Cross-Entropy is used to differentiate real and fake images\n",
    "- Class loss should be Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sizes of the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input images size: torch.Size([64, 1, 64, 64])\n",
      "Code size: torch.Size([64, 100, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "input = torch.FloatTensor(batch_size, nc, imageSize, imageSize)\n",
    "print('Input images size:', input.size())\n",
    "noise = torch.FloatTensor(batch_size, nz, 1, 1)\n",
    "fixed_noise = torch.FloatTensor(batch_size, nz, 1, 1).normal_(0, 1)\n",
    "print('Code size:', noise.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = torch.LongTensor(batch_size, 1)\n",
    "fake_label = 0\n",
    "real_label = 1\n",
    "\n",
    "one = torch.FloatTensor([1]).cuda()\n",
    "mone = -1 * one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcast to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    netD = netD.cuda()\n",
    "    netG = netG.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    input,label = input.cuda(), label.cuda()\n",
    "    noise, fixed_noise = noise.cuda(), fixed_noise.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer Parameters\n",
    "- Following the lead of [WGAN](https://arxiv.org/pdf/1701.07875.pdf):\n",
    "\n",
    "    <b>\n",
    "    1. Optimizer is RMSprop\n",
    "    2. lr = 0.00005\n",
    "    </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "\n",
    "optimizerD = optim.RMSprop(netD.parameters(), lr = lr)\n",
    "optimizerG = optim.RMSprop(netG.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(num_epochs, dataloader, netD, netG, outputDir,\n",
    "              real_labelSmooth=0, epoch_interval=100, D_steps=5, G_steps=1, atenuation_epochs=25):\n",
    "    \n",
    "    # This validation is subjective. WGAN-GP uses 100 steps on the critic (netD).\n",
    "    #assert D_steps < 5, \"Keep it low, D_steps is too high.\"\n",
    "    #assert G_steps < 3, \"Keep it low, G_steps is too high.\"\n",
    "    #assert batch_size % D_steps == 0, \"Use batch_size multiple of D_steps.\"\n",
    "    print('Lets train!')\n",
    "    for epoch in range(num_epochs):\n",
    "        start_iter = time.time()\n",
    "\n",
    "        for batch, data in enumerate(dataloader, 0):\n",
    "            if (epoch == 0 and batch == 0):\n",
    "                    vutils.save_image(data[0][0:64,:,:,:], '%s/real_samples.png' % outputDir, nrow=8)\n",
    "            \n",
    "            for p in netD.parameters():\n",
    "                p.requires_grad = True\n",
    "            \n",
    "            for step in range(D_steps):\n",
    "                for p in netD.parameters():\n",
    "                    p.data.clamp_(-0.01, 0.01)\n",
    "                    \n",
    "                #############################################################\n",
    "                # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "                # 1A - Train the detective network in the Real Dataset\n",
    "                #############################################################\n",
    "                netD.zero_grad()\n",
    "                start = step*(int(data[0].size()[0]/D_steps))\n",
    "                end = (step+1)*int(data[0].size()[0]/D_steps)\n",
    "                \n",
    "                real_cpu = data[0][start:end]\n",
    "                real_cpu = real_cpu.cuda()\n",
    "                batch_size = real_cpu.size(0)\n",
    "                target = torch.LongTensor(batch_size).fill_(real_label).cuda()\n",
    "                \n",
    "                input, label = Variable(real_cpu), Variable(target)\n",
    "\n",
    "                errD_real = netD(input)\n",
    "                errD_real.backward(one)\n",
    "                \n",
    "                #######################################################\n",
    "                # 1B - Train the detective network in the False Dataset\n",
    "                #######################################################\n",
    "                \n",
    "                noise = Variable(torch.FloatTensor(batch_size, nz, 1, 1).normal_(0,1).cuda())\n",
    "                fake = netG(noise)\n",
    "                label = Variable(torch.ones(batch_size).long().fill_(fake_label).cuda())\n",
    "\n",
    "                errD_fake = netD(fake.detach())\n",
    "                errD_fake.backward(mone)\n",
    "                errD = errD_real - errD_fake\n",
    "                optimizerD.step()\n",
    "\n",
    "            for p in netD.parameters():\n",
    "                p.requires_grad = False\n",
    "                \n",
    "            for step in range(G_steps):\n",
    "                ####################################################################################\n",
    "                # (2) Update G network: maximize log(D(G(z)))\n",
    "                # Train the faker with the output from the Detective (but don't train the Detective)\n",
    "                ####################################################################################\n",
    "                \n",
    "                netG.zero_grad()\n",
    "                label = Variable(torch.LongTensor(batch_size).fill_(real_label).cuda())\n",
    "                errG = netD(fake)\n",
    "                \n",
    "                errG.backward(one)\n",
    "                optimizerG.step()\n",
    "                \n",
    "        print('epoch = ',epoch)\n",
    "\n",
    "        end_iter = time.time()        \n",
    "\n",
    "        print('[%d/%d] ErrD: %.2f, ErrG: %.2f, ErrD_real: %.2f, ErrD_fake: %.2f, Time Elapsed %.2f s'\n",
    "              % (epoch, num_epochs, errD.data[0], errG.data[0], errD_real.data[0], errD_fake.data[0], end_iter-start_iter))\n",
    "\n",
    "        #Save a grid with the pictures from the dataset, up until 64\n",
    "        save_images(netG = netG, fixed_noise=  fixed_noise, outputDir = outputDir, epoch = epoch)\n",
    "\n",
    "        if epoch % epoch_interval == 0:\n",
    "            # do checkpointing\n",
    "            save_models(netG = netG, netD = netD, outputDir = outputDir, epoch = epoch)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets train!\n",
      "epoch =  0\n",
      "[0/100] ErrD: -1.08, ErrG: 0.61, ErrD_real: -0.58, ErrD_fake: 0.50, Time Elapsed 170.15 s\n",
      "epoch =  1\n",
      "[1/100] ErrD: -0.35, ErrG: 0.24, ErrD_real: 0.31, ErrD_fake: 0.66, Time Elapsed 181.94 s\n",
      "epoch =  2\n",
      "[2/100] ErrD: -1.11, ErrG: 0.60, ErrD_real: -0.61, ErrD_fake: 0.50, Time Elapsed 173.64 s\n",
      "epoch =  3\n",
      "[3/100] ErrD: -1.14, ErrG: 0.56, ErrD_real: -0.54, ErrD_fake: 0.60, Time Elapsed 183.79 s\n",
      "epoch =  4\n",
      "[4/100] ErrD: -0.88, ErrG: 0.66, ErrD_real: -0.62, ErrD_fake: 0.26, Time Elapsed 274.28 s\n",
      "epoch =  5\n",
      "[5/100] ErrD: -1.01, ErrG: 0.62, ErrD_real: -0.62, ErrD_fake: 0.39, Time Elapsed 274.34 s\n",
      "epoch =  6\n",
      "[6/100] ErrD: -1.06, ErrG: 0.40, ErrD_real: -0.49, ErrD_fake: 0.57, Time Elapsed 274.51 s\n",
      "epoch =  7\n",
      "[7/100] ErrD: -1.00, ErrG: 0.60, ErrD_real: -0.62, ErrD_fake: 0.38, Time Elapsed 272.48 s\n",
      "epoch =  8\n",
      "[8/100] ErrD: -1.09, ErrG: 0.58, ErrD_real: -0.54, ErrD_fake: 0.55, Time Elapsed 274.84 s\n",
      "epoch =  9\n",
      "[9/100] ErrD: -1.21, ErrG: 0.67, ErrD_real: -0.64, ErrD_fake: 0.57, Time Elapsed 274.60 s\n",
      "epoch =  10\n",
      "[10/100] ErrD: -0.38, ErrG: 0.23, ErrD_real: 0.29, ErrD_fake: 0.67, Time Elapsed 274.53 s\n",
      "epoch =  11\n",
      "[11/100] ErrD: -0.96, ErrG: 0.43, ErrD_real: -0.44, ErrD_fake: 0.52, Time Elapsed 274.59 s\n",
      "epoch =  12\n",
      "[12/100] ErrD: -0.92, ErrG: 0.18, ErrD_real: -0.30, ErrD_fake: 0.62, Time Elapsed 273.54 s\n",
      "epoch =  13\n",
      "[13/100] ErrD: -1.33, ErrG: 0.68, ErrD_real: -0.67, ErrD_fake: 0.66, Time Elapsed 272.73 s\n",
      "epoch =  14\n",
      "[14/100] ErrD: -1.22, ErrG: 0.64, ErrD_real: -0.61, ErrD_fake: 0.61, Time Elapsed 274.01 s\n",
      "epoch =  15\n",
      "[15/100] ErrD: -1.21, ErrG: 0.64, ErrD_real: -0.63, ErrD_fake: 0.58, Time Elapsed 275.01 s\n",
      "epoch =  16\n",
      "[16/100] ErrD: -1.29, ErrG: 0.67, ErrD_real: -0.65, ErrD_fake: 0.64, Time Elapsed 273.95 s\n",
      "epoch =  17\n",
      "[17/100] ErrD: -0.82, ErrG: 0.64, ErrD_real: -0.65, ErrD_fake: 0.17, Time Elapsed 274.76 s\n",
      "epoch =  18\n",
      "[18/100] ErrD: -1.14, ErrG: 0.54, ErrD_real: -0.53, ErrD_fake: 0.61, Time Elapsed 271.36 s\n",
      "epoch =  19\n",
      "[19/100] ErrD: -0.91, ErrG: 0.26, ErrD_real: -0.33, ErrD_fake: 0.58, Time Elapsed 218.18 s\n",
      "epoch =  20\n",
      "[20/100] ErrD: -0.80, ErrG: 0.64, ErrD_real: -0.65, ErrD_fake: 0.14, Time Elapsed 129.22 s\n",
      "epoch =  21\n",
      "[21/100] ErrD: -1.02, ErrG: 0.31, ErrD_real: -0.41, ErrD_fake: 0.61, Time Elapsed 127.32 s\n",
      "epoch =  22\n",
      "[22/100] ErrD: -0.78, ErrG: 0.68, ErrD_real: -0.65, ErrD_fake: 0.13, Time Elapsed 128.00 s\n",
      "epoch =  23\n",
      "[23/100] ErrD: -1.10, ErrG: 0.49, ErrD_real: -0.49, ErrD_fake: 0.61, Time Elapsed 127.58 s\n",
      "epoch =  24\n",
      "[24/100] ErrD: -1.16, ErrG: 0.60, ErrD_real: -0.59, ErrD_fake: 0.57, Time Elapsed 127.82 s\n",
      "epoch =  25\n",
      "[25/100] ErrD: -1.07, ErrG: 0.65, ErrD_real: -0.64, ErrD_fake: 0.43, Time Elapsed 127.43 s\n",
      "epoch =  26\n",
      "[26/100] ErrD: -1.15, ErrG: 0.65, ErrD_real: -0.62, ErrD_fake: 0.53, Time Elapsed 127.61 s\n",
      "epoch =  27\n",
      "[27/100] ErrD: -1.17, ErrG: 0.63, ErrD_real: -0.60, ErrD_fake: 0.57, Time Elapsed 127.75 s\n",
      "epoch =  28\n",
      "[28/100] ErrD: -1.11, ErrG: 0.51, ErrD_real: -0.50, ErrD_fake: 0.60, Time Elapsed 127.38 s\n",
      "epoch =  29\n",
      "[29/100] ErrD: -0.99, ErrG: 0.64, ErrD_real: -0.60, ErrD_fake: 0.39, Time Elapsed 127.88 s\n",
      "epoch =  30\n",
      "[30/100] ErrD: -0.79, ErrG: 0.64, ErrD_real: -0.62, ErrD_fake: 0.17, Time Elapsed 127.40 s\n",
      "epoch =  31\n",
      "[31/100] ErrD: -1.28, ErrG: 0.66, ErrD_real: -0.65, ErrD_fake: 0.64, Time Elapsed 170.79 s\n",
      "epoch =  32\n",
      "[32/100] ErrD: -0.77, ErrG: 0.14, ErrD_real: -0.12, ErrD_fake: 0.66, Time Elapsed 193.35 s\n",
      "epoch =  33\n",
      "[33/100] ErrD: -0.81, ErrG: 0.67, ErrD_real: -0.61, ErrD_fake: 0.20, Time Elapsed 192.75 s\n",
      "epoch =  34\n",
      "[34/100] ErrD: -0.93, ErrG: 0.31, ErrD_real: -0.30, ErrD_fake: 0.63, Time Elapsed 193.57 s\n",
      "epoch =  35\n",
      "[35/100] ErrD: -1.09, ErrG: 0.64, ErrD_real: -0.62, ErrD_fake: 0.47, Time Elapsed 192.86 s\n",
      "epoch =  36\n",
      "[36/100] ErrD: -1.14, ErrG: 0.65, ErrD_real: -0.61, ErrD_fake: 0.53, Time Elapsed 193.04 s\n",
      "epoch =  37\n",
      "[37/100] ErrD: -1.11, ErrG: 0.59, ErrD_real: -0.57, ErrD_fake: 0.54, Time Elapsed 193.33 s\n",
      "epoch =  38\n",
      "[38/100] ErrD: -1.31, ErrG: 0.68, ErrD_real: -0.66, ErrD_fake: 0.65, Time Elapsed 192.59 s\n",
      "epoch =  39\n",
      "[39/100] ErrD: -1.07, ErrG: 0.61, ErrD_real: -0.59, ErrD_fake: 0.48, Time Elapsed 192.88 s\n",
      "epoch =  40\n",
      "[40/100] ErrD: -0.80, ErrG: 0.65, ErrD_real: -0.62, ErrD_fake: 0.17, Time Elapsed 192.83 s\n",
      "epoch =  41\n",
      "[41/100] ErrD: -1.13, ErrG: 0.59, ErrD_real: -0.56, ErrD_fake: 0.57, Time Elapsed 192.93 s\n",
      "epoch =  42\n",
      "[42/100] ErrD: -1.08, ErrG: 0.63, ErrD_real: -0.60, ErrD_fake: 0.48, Time Elapsed 193.33 s\n",
      "epoch =  43\n",
      "[43/100] ErrD: -0.72, ErrG: 0.12, ErrD_real: -0.17, ErrD_fake: 0.54, Time Elapsed 193.83 s\n",
      "epoch =  44\n",
      "[44/100] ErrD: -0.84, ErrG: 0.16, ErrD_real: -0.25, ErrD_fake: 0.58, Time Elapsed 193.19 s\n",
      "epoch =  45\n",
      "[45/100] ErrD: -0.72, ErrG: 0.17, ErrD_real: -0.15, ErrD_fake: 0.57, Time Elapsed 159.09 s\n",
      "epoch =  46\n",
      "[46/100] ErrD: -1.22, ErrG: 0.64, ErrD_real: -0.61, ErrD_fake: 0.61, Time Elapsed 127.32 s\n",
      "epoch =  47\n",
      "[47/100] ErrD: -0.92, ErrG: 0.20, ErrD_real: -0.31, ErrD_fake: 0.61, Time Elapsed 128.20 s\n",
      "epoch =  48\n",
      "[48/100] ErrD: -0.97, ErrG: 0.65, ErrD_real: -0.62, ErrD_fake: 0.35, Time Elapsed 127.29 s\n",
      "epoch =  49\n",
      "[49/100] ErrD: -1.09, ErrG: 0.51, ErrD_real: -0.49, ErrD_fake: 0.60, Time Elapsed 127.76 s\n",
      "epoch =  50\n",
      "[50/100] ErrD: -0.85, ErrG: 0.19, ErrD_real: -0.26, ErrD_fake: 0.59, Time Elapsed 128.64 s\n",
      "epoch =  51\n",
      "[51/100] ErrD: -0.98, ErrG: 0.62, ErrD_real: -0.60, ErrD_fake: 0.38, Time Elapsed 127.79 s\n",
      "epoch =  52\n",
      "[52/100] ErrD: -0.91, ErrG: 0.39, ErrD_real: -0.37, ErrD_fake: 0.54, Time Elapsed 128.12 s\n",
      "epoch =  53\n",
      "[53/100] ErrD: -0.95, ErrG: 0.31, ErrD_real: -0.37, ErrD_fake: 0.58, Time Elapsed 127.78 s\n",
      "epoch =  54\n",
      "[54/100] ErrD: -0.81, ErrG: 0.65, ErrD_real: -0.65, ErrD_fake: 0.16, Time Elapsed 127.96 s\n",
      "epoch =  55\n",
      "[55/100] ErrD: -1.14, ErrG: 0.62, ErrD_real: -0.60, ErrD_fake: 0.54, Time Elapsed 127.61 s\n",
      "epoch =  56\n",
      "[56/100] ErrD: -0.57, ErrG: -0.09, ErrD_real: -0.09, ErrD_fake: 0.49, Time Elapsed 127.42 s\n",
      "epoch =  57\n",
      "[57/100] ErrD: -1.14, ErrG: 0.63, ErrD_real: -0.60, ErrD_fake: 0.54, Time Elapsed 127.43 s\n",
      "epoch =  58\n",
      "[58/100] ErrD: -0.87, ErrG: 0.27, ErrD_real: -0.35, ErrD_fake: 0.52, Time Elapsed 127.18 s\n",
      "epoch =  59\n",
      "[59/100] ErrD: -1.00, ErrG: 0.47, ErrD_real: -0.47, ErrD_fake: 0.53, Time Elapsed 127.56 s\n",
      "epoch =  60\n",
      "[60/100] ErrD: -1.18, ErrG: 0.63, ErrD_real: -0.62, ErrD_fake: 0.57, Time Elapsed 127.48 s\n",
      "epoch =  61\n",
      "[61/100] ErrD: -0.84, ErrG: 0.61, ErrD_real: -0.59, ErrD_fake: 0.25, Time Elapsed 126.93 s\n",
      "epoch =  62\n",
      "[62/100] ErrD: -0.55, ErrG: 0.57, ErrD_real: -0.60, ErrD_fake: -0.05, Time Elapsed 127.40 s\n",
      "epoch =  63\n",
      "[63/100] ErrD: -0.78, ErrG: 0.63, ErrD_real: -0.61, ErrD_fake: 0.17, Time Elapsed 127.99 s\n",
      "epoch =  64\n",
      "[64/100] ErrD: -0.98, ErrG: 0.39, ErrD_real: -0.43, ErrD_fake: 0.56, Time Elapsed 127.52 s\n",
      "epoch =  65\n",
      "[65/100] ErrD: -0.87, ErrG: 0.62, ErrD_real: -0.60, ErrD_fake: 0.27, Time Elapsed 127.76 s\n",
      "epoch =  66\n",
      "[66/100] ErrD: -0.72, ErrG: 0.63, ErrD_real: -0.57, ErrD_fake: 0.15, Time Elapsed 127.71 s\n",
      "epoch =  67\n",
      "[67/100] ErrD: -1.07, ErrG: 0.61, ErrD_real: -0.59, ErrD_fake: 0.48, Time Elapsed 128.02 s\n",
      "epoch =  68\n",
      "[68/100] ErrD: -0.79, ErrG: 0.25, ErrD_real: -0.20, ErrD_fake: 0.59, Time Elapsed 127.65 s\n",
      "epoch =  69\n",
      "[69/100] ErrD: -0.66, ErrG: 0.01, ErrD_real: -0.08, ErrD_fake: 0.57, Time Elapsed 128.28 s\n",
      "epoch =  70\n",
      "[70/100] ErrD: -0.71, ErrG: -0.01, ErrD_real: -0.12, ErrD_fake: 0.58, Time Elapsed 128.19 s\n",
      "epoch =  71\n",
      "[71/100] ErrD: -1.04, ErrG: 0.62, ErrD_real: -0.58, ErrD_fake: 0.46, Time Elapsed 127.92 s\n",
      "epoch =  72\n",
      "[72/100] ErrD: -0.80, ErrG: 0.20, ErrD_real: -0.26, ErrD_fake: 0.55, Time Elapsed 240.85 s\n",
      "epoch =  73\n",
      "[73/100] ErrD: -0.87, ErrG: 0.31, ErrD_real: -0.29, ErrD_fake: 0.58, Time Elapsed 282.30 s\n",
      "epoch =  74\n",
      "[74/100] ErrD: -0.58, ErrG: 0.53, ErrD_real: -0.54, ErrD_fake: 0.04, Time Elapsed 271.56 s\n",
      "epoch =  75\n",
      "[75/100] ErrD: -0.96, ErrG: 0.63, ErrD_real: -0.61, ErrD_fake: 0.35, Time Elapsed 136.62 s\n",
      "epoch =  76\n",
      "[76/100] ErrD: -0.76, ErrG: 0.24, ErrD_real: -0.24, ErrD_fake: 0.52, Time Elapsed 140.59 s\n",
      "epoch =  77\n",
      "[77/100] ErrD: -0.66, ErrG: 0.60, ErrD_real: -0.58, ErrD_fake: 0.08, Time Elapsed 141.14 s\n",
      "epoch =  78\n",
      "[78/100] ErrD: -1.07, ErrG: 0.61, ErrD_real: -0.59, ErrD_fake: 0.47, Time Elapsed 143.57 s\n",
      "epoch =  79\n",
      "[79/100] ErrD: -0.71, ErrG: 0.59, ErrD_real: -0.55, ErrD_fake: 0.16, Time Elapsed 141.51 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  80\n",
      "[80/100] ErrD: -1.05, ErrG: 0.56, ErrD_real: -0.53, ErrD_fake: 0.52, Time Elapsed 140.62 s\n",
      "epoch =  81\n",
      "[81/100] ErrD: -0.79, ErrG: 0.24, ErrD_real: -0.25, ErrD_fake: 0.55, Time Elapsed 133.94 s\n",
      "epoch =  82\n",
      "[82/100] ErrD: -0.80, ErrG: 0.61, ErrD_real: -0.58, ErrD_fake: 0.22, Time Elapsed 138.44 s\n",
      "epoch =  83\n",
      "[83/100] ErrD: -0.92, ErrG: 0.39, ErrD_real: -0.40, ErrD_fake: 0.52, Time Elapsed 145.66 s\n",
      "epoch =  84\n",
      "[84/100] ErrD: -0.97, ErrG: 0.57, ErrD_real: -0.53, ErrD_fake: 0.44, Time Elapsed 140.70 s\n",
      "epoch =  85\n",
      "[85/100] ErrD: -0.68, ErrG: 0.11, ErrD_real: -0.16, ErrD_fake: 0.52, Time Elapsed 139.96 s\n",
      "epoch =  86\n",
      "[86/100] ErrD: -0.93, ErrG: 0.61, ErrD_real: -0.59, ErrD_fake: 0.34, Time Elapsed 140.34 s\n",
      "epoch =  87\n",
      "[87/100] ErrD: -0.59, ErrG: 0.59, ErrD_real: -0.56, ErrD_fake: 0.03, Time Elapsed 147.54 s\n",
      "epoch =  88\n",
      "[88/100] ErrD: -0.92, ErrG: 0.39, ErrD_real: -0.38, ErrD_fake: 0.54, Time Elapsed 139.79 s\n",
      "epoch =  89\n",
      "[89/100] ErrD: -0.84, ErrG: 0.54, ErrD_real: -0.50, ErrD_fake: 0.33, Time Elapsed 161.97 s\n",
      "epoch =  90\n",
      "[90/100] ErrD: -0.94, ErrG: 0.27, ErrD_real: -0.38, ErrD_fake: 0.56, Time Elapsed 195.78 s\n",
      "epoch =  91\n",
      "[91/100] ErrD: -0.75, ErrG: 0.62, ErrD_real: -0.57, ErrD_fake: 0.18, Time Elapsed 195.54 s\n",
      "epoch =  92\n",
      "[92/100] ErrD: -0.70, ErrG: 0.56, ErrD_real: -0.54, ErrD_fake: 0.16, Time Elapsed 195.61 s\n",
      "epoch =  93\n",
      "[93/100] ErrD: -0.85, ErrG: 0.31, ErrD_real: -0.34, ErrD_fake: 0.51, Time Elapsed 201.80 s\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "real_labelSmooth = 0\n",
    "smoothing_epochs = 25\n",
    "D_steps = 5\n",
    "dataloader = torch.utils.data.DataLoader(dataset_done, batch_size=batch_size*D_steps, shuffle=True, num_workers=4)\n",
    "train_gan(num_epochs, dataloader, netD,netG, outputDir, real_labelSmooth, D_steps = D_steps, atenuation_epochs=smoothing_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = dataset('./datasets', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
